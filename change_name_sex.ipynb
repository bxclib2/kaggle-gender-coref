{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('gap-coreference-master/gap-validation.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation-1</td>\n",
       "      <td>He admitted making four trips to China and pla...</td>\n",
       "      <td>him</td>\n",
       "      <td>256</td>\n",
       "      <td>Jose de Venecia Jr</td>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>Abalos</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation-2</td>\n",
       "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
       "      <td>She</td>\n",
       "      <td>185</td>\n",
       "      <td>Ellen</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation-3</td>\n",
       "      <td>When she returns to her hotel room, a Liberian...</td>\n",
       "      <td>his</td>\n",
       "      <td>435</td>\n",
       "      <td>Jason Scott Lee</td>\n",
       "      <td>383</td>\n",
       "      <td>False</td>\n",
       "      <td>Danny</td>\n",
       "      <td>406</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validation-4</td>\n",
       "      <td>On 19 March 2007, during a campaign appearance...</td>\n",
       "      <td>he</td>\n",
       "      <td>333</td>\n",
       "      <td>Reucassel</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>Debnam</td>\n",
       "      <td>325</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Craig_Reucassel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation-5</td>\n",
       "      <td>By this time, Karen Blixen had separated from ...</td>\n",
       "      <td>she</td>\n",
       "      <td>427</td>\n",
       "      <td>Finch Hatton</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>Beryl Markham</td>\n",
       "      <td>328</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Denys_Finch_Hatton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Pronoun  \\\n",
       "0  validation-1  He admitted making four trips to China and pla...     him   \n",
       "1  validation-2  Kathleen Nott was born in Camberwell, London. ...     She   \n",
       "2  validation-3  When she returns to her hotel room, a Liberian...     his   \n",
       "3  validation-4  On 19 March 2007, during a campaign appearance...      he   \n",
       "4  validation-5  By this time, Karen Blixen had separated from ...     she   \n",
       "\n",
       "   Pronoun-offset                   A  A-offset  A-coref              B  \\\n",
       "0             256  Jose de Venecia Jr       208    False         Abalos   \n",
       "1             185               Ellen       110    False       Kathleen   \n",
       "2             435     Jason Scott Lee       383    False          Danny   \n",
       "3             333           Reucassel       300     True         Debnam   \n",
       "4             427        Finch Hatton       290    False  Beryl Markham   \n",
       "\n",
       "   B-offset  B-coref                                                URL  \n",
       "0       241    False  http://en.wikipedia.org/wiki/Commission_on_Ele...  \n",
       "1       150     True         http://en.wikipedia.org/wiki/Kathleen_Nott  \n",
       "2       406     True  http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...  \n",
       "3       325    False       http://en.wikipedia.org/wiki/Craig_Reucassel  \n",
       "4       328     True    http://en.wikipedia.org/wiki/Denys_Finch_Hatton  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'pronoun' column in text to 'placeholder'\n",
    "test['Text'] = test.apply(lambda x: x['Text'][0:x['Pronoun-offset']] +' placeholder '+ \\\n",
    "                          x['Text'][(x['Pronoun-offset']+len(x['Pronoun'])):], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name to 'Bob', 'Jim', 'Susan' and 'Jane'\n",
    "def change_name(df):\n",
    "    if df['Pronoun'] in ['He', 'His','he','his','him']:\n",
    "        return df['Text'].replace(df['A'], ' Bob ').replace(df['B'], ' Jim ')\n",
    "    else:\n",
    "        return df['Text'].replace(df['A'], ' Susan ').replace(df['B'], ' Jane ')\n",
    "test['Text'] = test.apply(lambda x: change_name(x),axis=1)\n",
    "\n",
    "def change_A(df):\n",
    "    if df['Pronoun'] in ['He', 'His','he','his','him']:\n",
    "        return 'Bob'\n",
    "    else:\n",
    "        return 'Susan'\n",
    "test['A'] = test.apply(lambda x: change_A(x), axis=1)\n",
    "\n",
    "def change_B(df):\n",
    "    if df['Pronoun'] in ['He', 'His','he','his','him']:\n",
    "        return 'Jim'\n",
    "    else:\n",
    "        return 'Jane'\n",
    "test['B'] = test.apply(lambda x: change_B(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Jane  Nott was born in Camberwell, London. Her father, Philip, was a lithographic printer, and her mother,  Susan , ran a boarding house in Brixton;  Jane  was their third daughter.  placeholder  was educated at Mary Datchelor Girls' School (now closed), London, before attending King's College, London.\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and get index of pronoun, A, B\n",
    "test['token_list'] = test['Text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "test['Pronoun-index'] = test['token_list'].apply(lambda x: x.index('placeholder'))\n",
    "test['A-index'] = test.apply(lambda x: x['token_list'].index(x['A']) if x['A'] in x['token_list'] else 0, axis=1)\n",
    "test['B-index'] = test.apply(lambda x: x['token_list'].index(x['B']) if x['B'] in x['token_list'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change placeholder to original pronoun\n",
    "test['token_list'] = test.apply(lambda x: [x['Pronoun'] if i == 'placeholder' else i for i in x['token_list']],axis=1)\n",
    "test['token_list'] = test['token_list'].apply(lambda x: ' '.join(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gap-coreference-master/name_changed/gap-validation-new.tsv', 'w') as write_tsv:\n",
    "    write_tsv.write(test.to_csv(sep='\\t', index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Text', 'Pronoun', 'Pronoun-offset', 'A', 'A-offset', 'A-coref',\n",
       "       'B', 'B-offset', 'B-coref', 'URL', 'token_list', 'Pronoun-index',\n",
       "       'A-index', 'B-index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('gap-coreference-master/name_changed/gap-test-new.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "      <th>token_list</th>\n",
       "      <th>Pronoun-index</th>\n",
       "      <th>A-index</th>\n",
       "      <th>B-index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pronoun</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>He</th>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Her</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>His</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>She</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hers</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Text  Pronoun-offset    A  A-offset  A-coref    B  B-offset  \\\n",
       "Pronoun                                                                     \n",
       "He       127   127             127  127       127      127  127       127   \n",
       "Her       37    37              37   37        37       37   37        37   \n",
       "His       28    28              28   28        28       28   28        28   \n",
       "She      159   159             159  159       159      159  159       159   \n",
       "he       221   221             221  221       221      221  221       221   \n",
       "her      566   566             566  566       566      566  566       566   \n",
       "hers       1     1               1    1         1        1    1         1   \n",
       "him       96    96              96   96        96       96   96        96   \n",
       "his      528   528             528  528       528      528  528       528   \n",
       "she      237   237             237  237       237      237  237       237   \n",
       "\n",
       "         B-coref  URL  token_list  Pronoun-index  A-index  B-index  \n",
       "Pronoun                                                             \n",
       "He           127  127         127            127      127      127  \n",
       "Her           37   37          37             37       37       37  \n",
       "His           28   28          28             28       28       28  \n",
       "She          159  159         159            159      159      159  \n",
       "he           221  221         221            221      221      221  \n",
       "her          566  566         566            566      566      566  \n",
       "hers           1    1           1              1        1        1  \n",
       "him           96   96          96             96       96       96  \n",
       "his          528  528         528            528      528      528  \n",
       "she          237  237         237            237      237      237  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(['Pronoun']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['token_list'] = test['token_list'].apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jane',\n",
       " 'Nott',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Camberwell',\n",
       " ',',\n",
       " 'London',\n",
       " '.',\n",
       " 'Her',\n",
       " 'father',\n",
       " ',',\n",
       " 'Philip',\n",
       " ',',\n",
       " 'was',\n",
       " 'a',\n",
       " 'lithographic',\n",
       " 'printer',\n",
       " ',',\n",
       " 'and',\n",
       " 'her',\n",
       " 'mother',\n",
       " ',',\n",
       " 'Susan',\n",
       " ',',\n",
       " 'ran',\n",
       " 'a',\n",
       " 'boarding',\n",
       " 'house',\n",
       " 'in',\n",
       " 'Brixton',\n",
       " ';',\n",
       " 'Jane',\n",
       " 'was',\n",
       " 'their',\n",
       " 'third',\n",
       " 'daughter',\n",
       " '.',\n",
       " 'She',\n",
       " 'was',\n",
       " 'educated',\n",
       " 'at',\n",
       " 'Mary',\n",
       " 'Datchelor',\n",
       " 'Girls',\n",
       " \"'\",\n",
       " 'School',\n",
       " '(',\n",
       " 'now',\n",
       " 'closed',\n",
       " ')',\n",
       " ',',\n",
       " 'London',\n",
       " ',',\n",
       " 'before',\n",
       " 'attending',\n",
       " 'King',\n",
       " \"'s\",\n",
       " 'College',\n",
       " ',',\n",
       " 'London',\n",
       " '.']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[1,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'her' to 'her1' and 'her2'\n",
    "def check_her(tokens):\n",
    "    model = 'gap-coreference-master/english-bidirectional-distsim.tagger'\n",
    "    jar = 'gap-coreference-master/stanford-postagger.jar'\n",
    "    st = StanfordPOSTagger(model,path_to_jar=jar)\n",
    "    t = st.tag(tokens)\n",
    "    # her1 宾语 her2 所有格\n",
    "    for idx, word in enumerate(tokens):\n",
    "        if word == 'her':\n",
    "            tokens[idx] = 'her1' if t[idx][1] == 'PRP' else 'her2'\n",
    "    return tokens\n",
    "\n",
    "test['token_list'] = test['token_list'].apply(lambda x: check_her(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They',\n",
       " 'have',\n",
       " 'a',\n",
       " 'stormy',\n",
       " 'marriage',\n",
       " ',',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'his',\n",
       " 'hot',\n",
       " 'temper',\n",
       " 'and',\n",
       " 'her2',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'playing',\n",
       " 'away',\n",
       " '.',\n",
       " 'Soon',\n",
       " 'after',\n",
       " 'arriving',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Street',\n",
       " ',',\n",
       " 'Jane',\n",
       " 'makes',\n",
       " 'friends',\n",
       " 'with',\n",
       " 'Deirdre',\n",
       " 'Barlow',\n",
       " '(',\n",
       " 'Anne',\n",
       " 'Kirkbride',\n",
       " ')',\n",
       " ',',\n",
       " 'whose',\n",
       " 'daughter',\n",
       " 'Tracy',\n",
       " '(',\n",
       " 'Dawn',\n",
       " 'Acton',\n",
       " ')',\n",
       " 'is',\n",
       " 'slightly',\n",
       " 'younger',\n",
       " 'than',\n",
       " 'the',\n",
       " 'twins',\n",
       " '.',\n",
       " 'When',\n",
       " 'asked',\n",
       " 'in',\n",
       " 'a',\n",
       " '2010',\n",
       " 'interview',\n",
       " 'with',\n",
       " 'The',\n",
       " 'Mirror',\n",
       " 'what',\n",
       " 'her2',\n",
       " 'favourite',\n",
       " 'scenes',\n",
       " 'were',\n",
       " ',',\n",
       " 'Susan',\n",
       " 'replied',\n",
       " ',',\n",
       " '``',\n",
       " 'when',\n",
       " 'Jim',\n",
       " 'beat',\n",
       " 'up',\n",
       " 'Jane',\n",
       " '.']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[9,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change sex\n",
    "def replace_sex(tokens):\n",
    "    sentence = ' '.join(tokens)\n",
    "    sentence = sentence.replace('She','He1').replace('she','he1').replace('hers','his1').replace('Her','His1').replace('He ','She ').replace('His ','Her ').replace(' he ',' she ').replace(' him ',' her ').replace(' his ' ,' her ')\n",
    "    sentence = sentence.replace('He1','He').replace('he1','he').replace('his1','his').replace('His1','His').replace('her1','him').replace('her2','his')\n",
    "    return sentence.split(' ')\n",
    "test['token_list2'] = test['token_list'].apply(lambda x: replace_sex(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change pronoun sex\n",
    "test['Pronoun'] = test.apply(lambda x: x['token_list2'][x['Pronoun-index']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gap-coreference-master/gap-validation-new.tsv', 'w') as write_tsv:\n",
    "    write_tsv.write(test.to_csv(sep='\\t', index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
