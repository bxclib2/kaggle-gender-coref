{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first do some dimension reduction of the word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train= pd.read_pickle('./temp_result/train_kaggle_processed')\n",
    "gap_test= pd.read_pickle('./temp_result/test_kaggle_processed')\n",
    "gap_valid= pd.read_pickle('./temp_result/valid_kaggle_processed')\n",
    "answer = pd.read_csv(\"https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-development.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里是我的错,当时没考虑到这里没有标签不方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_test[\"A-coref\"] = answer[\"A-coref\"]\n",
    "gap_test[\"B-coref\"] = answer[\"B-coref\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>URL</th>\n",
       "      <th>vector</th>\n",
       "      <th>...</th>\n",
       "      <th>B_pos</th>\n",
       "      <th>pron_pos</th>\n",
       "      <th>A_idx</th>\n",
       "      <th>B_idx</th>\n",
       "      <th>pron_idx</th>\n",
       "      <th>A_vector</th>\n",
       "      <th>B_vector</th>\n",
       "      <th>pron_vector</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "      <td>[[-0.30144718, -0.08635384, -0.20015159, -0.25...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>[54, 55, 56, 57, 58, 59]</td>\n",
       "      <td>[61, 62, 63]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>[[0.14136104, -0.38602263, -0.19260919, 0.4973...</td>\n",
       "      <td>[[0.6761073, -0.45650303, -0.27585956, -0.3139...</td>\n",
       "      <td>[[-0.1408648, -0.009012785, -0.58574224, -0.96...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "      <td>[[0.34895068, 0.6811254, 0.92398053, -0.417637...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>[63, 64, 65]</td>\n",
       "      <td>[68, 69, 70, 71, 72]</td>\n",
       "      <td>[78]</td>\n",
       "      <td>[[-0.75297713, -0.91880596, -0.31332776, 0.235...</td>\n",
       "      <td>[[-0.014572581, 0.3896196, -0.4235178, -0.2201...</td>\n",
       "      <td>[[-0.5127397, 0.38019675, -0.19245711, -0.6960...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "      <td>[[-0.3016174, 0.06391026, -0.15569207, -0.1670...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505155</td>\n",
       "      <td>0.556701</td>\n",
       "      <td>[43, 44]</td>\n",
       "      <td>[59, 60, 61, 62]</td>\n",
       "      <td>[65]</td>\n",
       "      <td>[[-0.44509542, -0.38031942, 0.01635306, 0.1235...</td>\n",
       "      <td>[[0.06467356, 0.14759275, 0.38993636, -0.09622...</td>\n",
       "      <td>[[-0.40798748, 0.8667205, -0.14823496, 0.31704...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "      <td>[[0.31311065, -0.4944703, 0.44825977, -0.12736...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[75, 76, 77, 78, 79, 80]</td>\n",
       "      <td>[71]</td>\n",
       "      <td>[[0.043780833, 0.44859782, 0.566811, -0.007530...</td>\n",
       "      <td>[[-0.40079117, 0.6081313, 0.008237168, -0.2687...</td>\n",
       "      <td>[[-0.23520903, -0.029176882, -0.047637727, 0.0...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "      <td>[[0.1210996, 0.19799706, 0.4914001, -0.4640768...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>[59, 60, 61, 62, 63]</td>\n",
       "      <td>[78, 79]</td>\n",
       "      <td>[116]</td>\n",
       "      <td>[[0.31352907, 0.8938127, -0.27805957, 0.610802...</td>\n",
       "      <td>[[0.60271496, 0.43095493, -0.86851233, 0.58121...</td>\n",
       "      <td>[[-0.7814366, -0.24526855, 0.24610633, -0.3730...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text Pronoun  \\\n",
       "0  development-1  Zoe Telford -- played the police officer girlf...     her   \n",
       "1  development-2  He grew up in Evanston, Illinois the second ol...     His   \n",
       "2  development-3  He had been reelected to Congress, but resigne...     his   \n",
       "3  development-4  The current members of Crime have also perform...     his   \n",
       "4  development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...     She   \n",
       "\n",
       "   Pronoun-offset                  A  A-offset                B  B-offset  \\\n",
       "0             274     Cheryl Cassidy       191          Pauline       207   \n",
       "1             284          MacKenzie       228    Bernard Leach       251   \n",
       "2             265            Angeloz       173       De la Sota       246   \n",
       "3             321               Hell       174  Henry Rosenthal       336   \n",
       "4             437  Kitty Oppenheimer       219           Rivera       294   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  http://en.wikipedia.org/wiki/List_of_Teachers_...   \n",
       "1      http://en.wikipedia.org/wiki/Warren_MacKenzie   \n",
       "2  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...   \n",
       "3          http://en.wikipedia.org/wiki/Crime_(band)   \n",
       "4        http://en.wikipedia.org/wiki/Jessica_Rivera   \n",
       "\n",
       "                                              vector  ...     B_pos  pron_pos  \\\n",
       "0  [[-0.30144718, -0.08635384, -0.20015159, -0.25...  ...  0.608696  0.826087   \n",
       "1  [[0.34895068, 0.6811254, 0.92398053, -0.417637...  ...  0.333333  0.380952   \n",
       "2  [[-0.3016174, 0.06391026, -0.15569207, -0.1670...  ...  0.505155  0.556701   \n",
       "3  [[0.31311065, -0.4944703, 0.44825977, -0.12736...  ...  0.657143  0.619048   \n",
       "4  [[0.1210996, 0.19799706, 0.4914001, -0.4640768...  ...  0.619565  0.923913   \n",
       "\n",
       "                      A_idx                     B_idx  pron_idx  \\\n",
       "0  [54, 55, 56, 57, 58, 59]              [61, 62, 63]      [81]   \n",
       "1              [63, 64, 65]      [68, 69, 70, 71, 72]      [78]   \n",
       "2                  [43, 44]          [59, 60, 61, 62]      [65]   \n",
       "3                      [40]  [75, 76, 77, 78, 79, 80]      [71]   \n",
       "4      [59, 60, 61, 62, 63]                  [78, 79]     [116]   \n",
       "\n",
       "                                            A_vector  \\\n",
       "0  [[0.14136104, -0.38602263, -0.19260919, 0.4973...   \n",
       "1  [[-0.75297713, -0.91880596, -0.31332776, 0.235...   \n",
       "2  [[-0.44509542, -0.38031942, 0.01635306, 0.1235...   \n",
       "3  [[0.043780833, 0.44859782, 0.566811, -0.007530...   \n",
       "4  [[0.31352907, 0.8938127, -0.27805957, 0.610802...   \n",
       "\n",
       "                                            B_vector  \\\n",
       "0  [[0.6761073, -0.45650303, -0.27585956, -0.3139...   \n",
       "1  [[-0.014572581, 0.3896196, -0.4235178, -0.2201...   \n",
       "2  [[0.06467356, 0.14759275, 0.38993636, -0.09622...   \n",
       "3  [[-0.40079117, 0.6081313, 0.008237168, -0.2687...   \n",
       "4  [[0.60271496, 0.43095493, -0.86851233, 0.58121...   \n",
       "\n",
       "                                         pron_vector A-coref B-coref  \n",
       "0  [[-0.1408648, -0.009012785, -0.58574224, -0.96...    True   False  \n",
       "1  [[-0.5127397, 0.38019675, -0.19245711, -0.6960...    True   False  \n",
       "2  [[-0.40798748, 0.8667205, -0.14823496, 0.31704...   False    True  \n",
       "3  [[-0.23520903, -0.029176882, -0.047637727, 0.0...   False    True  \n",
       "4  [[-0.7814366, -0.24526855, 0.24610633, -0.3730...   False    True  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector_ = np.concatenate(gap_train.vector,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = train_vector_.mean(axis = 0)\n",
    "train_vector = train_vector_ - mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223174, 1024)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "dim = 1024\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(dim, 128,bias = False)\n",
    "        self.decoder = nn.Linear(128, dim,bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        x_ = self.decoder(h)\n",
    "        return x_,h,x-x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [1/5000], loss:0.3948\n",
      "steps [2/5000], loss:0.3439\n",
      "steps [3/5000], loss:0.3521\n",
      "steps [4/5000], loss:0.3698\n",
      "steps [5/5000], loss:0.3549\n",
      "steps [6/5000], loss:0.3455\n",
      "steps [7/5000], loss:0.3429\n",
      "steps [8/5000], loss:0.3194\n",
      "steps [9/5000], loss:0.3220\n",
      "steps [10/5000], loss:0.3847\n",
      "steps [11/5000], loss:0.3524\n",
      "steps [12/5000], loss:0.3212\n",
      "steps [13/5000], loss:0.3294\n",
      "steps [14/5000], loss:0.3153\n",
      "steps [15/5000], loss:0.3732\n",
      "steps [16/5000], loss:0.3087\n",
      "steps [17/5000], loss:0.2915\n",
      "steps [18/5000], loss:0.3046\n",
      "steps [19/5000], loss:0.3427\n",
      "steps [20/5000], loss:0.3459\n",
      "steps [21/5000], loss:0.3268\n",
      "steps [22/5000], loss:0.3029\n",
      "steps [23/5000], loss:0.2993\n",
      "steps [24/5000], loss:0.3176\n",
      "steps [25/5000], loss:0.3150\n",
      "steps [26/5000], loss:0.3166\n",
      "steps [27/5000], loss:0.3005\n",
      "steps [28/5000], loss:0.2724\n",
      "steps [29/5000], loss:0.2827\n",
      "steps [30/5000], loss:0.2973\n",
      "steps [31/5000], loss:0.3043\n",
      "steps [32/5000], loss:0.2791\n",
      "steps [33/5000], loss:0.2662\n",
      "steps [34/5000], loss:0.2557\n",
      "steps [35/5000], loss:0.2756\n",
      "steps [36/5000], loss:0.2855\n",
      "steps [37/5000], loss:0.2587\n",
      "steps [38/5000], loss:0.2440\n",
      "steps [39/5000], loss:0.2731\n",
      "steps [40/5000], loss:0.2406\n",
      "steps [41/5000], loss:0.2671\n",
      "steps [42/5000], loss:0.2760\n",
      "steps [43/5000], loss:0.2750\n",
      "steps [44/5000], loss:0.2584\n",
      "steps [45/5000], loss:0.2594\n",
      "steps [46/5000], loss:0.2483\n",
      "steps [47/5000], loss:0.2627\n",
      "steps [48/5000], loss:0.2530\n",
      "steps [49/5000], loss:0.2922\n",
      "steps [50/5000], loss:0.3172\n",
      "steps [51/5000], loss:0.2625\n",
      "steps [52/5000], loss:0.2344\n",
      "steps [53/5000], loss:0.2376\n",
      "steps [54/5000], loss:0.2387\n",
      "steps [55/5000], loss:0.2231\n",
      "steps [56/5000], loss:0.2273\n",
      "steps [57/5000], loss:0.2470\n",
      "steps [58/5000], loss:0.2599\n",
      "steps [59/5000], loss:0.2122\n",
      "steps [60/5000], loss:0.2450\n",
      "steps [61/5000], loss:0.2090\n",
      "steps [62/5000], loss:0.2175\n",
      "steps [63/5000], loss:0.2107\n",
      "steps [64/5000], loss:0.2515\n",
      "steps [65/5000], loss:0.2368\n",
      "steps [66/5000], loss:0.2205\n",
      "steps [67/5000], loss:0.2088\n",
      "steps [68/5000], loss:0.2340\n",
      "steps [69/5000], loss:0.2293\n",
      "steps [70/5000], loss:0.2277\n",
      "steps [71/5000], loss:0.2264\n",
      "steps [72/5000], loss:0.2138\n",
      "steps [73/5000], loss:0.2383\n",
      "steps [74/5000], loss:0.2220\n",
      "steps [75/5000], loss:0.2157\n",
      "steps [76/5000], loss:0.2095\n",
      "steps [77/5000], loss:0.2472\n",
      "steps [78/5000], loss:0.2132\n",
      "steps [79/5000], loss:0.2034\n",
      "steps [80/5000], loss:0.2443\n",
      "steps [81/5000], loss:0.2066\n",
      "steps [82/5000], loss:0.1943\n",
      "steps [83/5000], loss:0.2041\n",
      "steps [84/5000], loss:0.1893\n",
      "steps [85/5000], loss:0.2095\n",
      "steps [86/5000], loss:0.2340\n",
      "steps [87/5000], loss:0.1858\n",
      "steps [88/5000], loss:0.1847\n",
      "steps [89/5000], loss:0.2235\n",
      "steps [90/5000], loss:0.1978\n",
      "steps [91/5000], loss:0.2117\n",
      "steps [92/5000], loss:0.1765\n",
      "steps [93/5000], loss:0.1975\n",
      "steps [94/5000], loss:0.2127\n",
      "steps [95/5000], loss:0.1890\n",
      "steps [96/5000], loss:0.1908\n",
      "steps [97/5000], loss:0.2098\n",
      "steps [98/5000], loss:0.2070\n",
      "steps [99/5000], loss:0.2377\n",
      "steps [100/5000], loss:0.1818\n",
      "steps [101/5000], loss:0.1922\n",
      "steps [102/5000], loss:0.1898\n",
      "steps [103/5000], loss:0.2324\n",
      "steps [104/5000], loss:0.1989\n",
      "steps [105/5000], loss:0.2012\n",
      "steps [106/5000], loss:0.2195\n",
      "steps [107/5000], loss:0.1923\n",
      "steps [108/5000], loss:0.1805\n",
      "steps [109/5000], loss:0.2497\n",
      "steps [110/5000], loss:0.2191\n",
      "steps [111/5000], loss:0.2001\n",
      "steps [112/5000], loss:0.1735\n",
      "steps [113/5000], loss:0.2060\n",
      "steps [114/5000], loss:0.1973\n",
      "steps [115/5000], loss:0.2094\n",
      "steps [116/5000], loss:0.1964\n",
      "steps [117/5000], loss:0.1876\n",
      "steps [118/5000], loss:0.1858\n",
      "steps [119/5000], loss:0.2050\n",
      "steps [120/5000], loss:0.2278\n",
      "steps [121/5000], loss:0.2045\n",
      "steps [122/5000], loss:0.1946\n",
      "steps [123/5000], loss:0.2124\n",
      "steps [124/5000], loss:0.2116\n",
      "steps [125/5000], loss:0.1971\n",
      "steps [126/5000], loss:0.1802\n",
      "steps [127/5000], loss:0.2027\n",
      "steps [128/5000], loss:0.2140\n",
      "steps [129/5000], loss:0.2090\n",
      "steps [130/5000], loss:0.2009\n",
      "steps [131/5000], loss:0.2314\n",
      "steps [132/5000], loss:0.1875\n",
      "steps [133/5000], loss:0.1911\n",
      "steps [134/5000], loss:0.1770\n",
      "steps [135/5000], loss:0.1798\n",
      "steps [136/5000], loss:0.1812\n",
      "steps [137/5000], loss:0.1934\n",
      "steps [138/5000], loss:0.1729\n",
      "steps [139/5000], loss:0.1893\n",
      "steps [140/5000], loss:0.1835\n",
      "steps [141/5000], loss:0.1734\n",
      "steps [142/5000], loss:0.2074\n",
      "steps [143/5000], loss:0.2173\n",
      "steps [144/5000], loss:0.1727\n",
      "steps [145/5000], loss:0.1724\n",
      "steps [146/5000], loss:0.1892\n",
      "steps [147/5000], loss:0.1908\n",
      "steps [148/5000], loss:0.1947\n",
      "steps [149/5000], loss:0.1719\n",
      "steps [150/5000], loss:0.1789\n",
      "steps [151/5000], loss:0.1877\n",
      "steps [152/5000], loss:0.1977\n",
      "steps [153/5000], loss:0.1795\n",
      "steps [154/5000], loss:0.1783\n",
      "steps [155/5000], loss:0.1961\n",
      "steps [156/5000], loss:0.1474\n",
      "steps [157/5000], loss:0.1883\n",
      "steps [158/5000], loss:0.1808\n",
      "steps [159/5000], loss:0.1745\n",
      "steps [160/5000], loss:0.1903\n",
      "steps [161/5000], loss:0.2023\n",
      "steps [162/5000], loss:0.1832\n",
      "steps [163/5000], loss:0.1507\n",
      "steps [164/5000], loss:0.1546\n",
      "steps [165/5000], loss:0.1729\n",
      "steps [166/5000], loss:0.1711\n",
      "steps [167/5000], loss:0.1945\n",
      "steps [168/5000], loss:0.1926\n",
      "steps [169/5000], loss:0.1636\n",
      "steps [170/5000], loss:0.1761\n",
      "steps [171/5000], loss:0.1760\n",
      "steps [172/5000], loss:0.1722\n",
      "steps [173/5000], loss:0.1947\n",
      "steps [174/5000], loss:0.1824\n",
      "steps [175/5000], loss:0.1785\n",
      "steps [176/5000], loss:0.1730\n",
      "steps [177/5000], loss:0.1607\n",
      "steps [178/5000], loss:0.2020\n",
      "steps [179/5000], loss:0.1700\n",
      "steps [180/5000], loss:0.1688\n",
      "steps [181/5000], loss:0.1719\n",
      "steps [182/5000], loss:0.1755\n",
      "steps [183/5000], loss:0.1759\n",
      "steps [184/5000], loss:0.1748\n",
      "steps [185/5000], loss:0.1707\n",
      "steps [186/5000], loss:0.1788\n",
      "steps [187/5000], loss:0.1896\n",
      "steps [188/5000], loss:0.1646\n",
      "steps [189/5000], loss:0.1625\n",
      "steps [190/5000], loss:0.1920\n",
      "steps [191/5000], loss:0.2166\n",
      "steps [192/5000], loss:0.1855\n",
      "steps [193/5000], loss:0.1665\n",
      "steps [194/5000], loss:0.1730\n",
      "steps [195/5000], loss:0.1671\n",
      "steps [196/5000], loss:0.1897\n",
      "steps [197/5000], loss:0.1658\n",
      "steps [198/5000], loss:0.1977\n",
      "steps [199/5000], loss:0.2030\n",
      "steps [200/5000], loss:0.1779\n",
      "steps [201/5000], loss:0.2107\n",
      "steps [202/5000], loss:0.1961\n",
      "steps [203/5000], loss:0.1812\n",
      "steps [204/5000], loss:0.1854\n",
      "steps [205/5000], loss:0.1654\n",
      "steps [206/5000], loss:0.1769\n",
      "steps [207/5000], loss:0.1721\n",
      "steps [208/5000], loss:0.1763\n",
      "steps [209/5000], loss:0.1737\n",
      "steps [210/5000], loss:0.1959\n",
      "steps [211/5000], loss:0.1516\n",
      "steps [212/5000], loss:0.2137\n",
      "steps [213/5000], loss:0.1579\n",
      "steps [214/5000], loss:0.1948\n",
      "steps [215/5000], loss:0.1811\n",
      "steps [216/5000], loss:0.2037\n",
      "steps [217/5000], loss:0.1717\n",
      "steps [218/5000], loss:0.1731\n",
      "steps [219/5000], loss:0.1793\n",
      "steps [220/5000], loss:0.1776\n",
      "steps [221/5000], loss:0.1861\n",
      "steps [222/5000], loss:0.1740\n",
      "steps [223/5000], loss:0.1687\n",
      "steps [224/5000], loss:0.1920\n",
      "steps [225/5000], loss:0.1704\n",
      "steps [226/5000], loss:0.1811\n",
      "steps [227/5000], loss:0.1716\n",
      "steps [228/5000], loss:0.1985\n",
      "steps [229/5000], loss:0.1707\n",
      "steps [230/5000], loss:0.1878\n",
      "steps [231/5000], loss:0.1676\n",
      "steps [232/5000], loss:0.1702\n",
      "steps [233/5000], loss:0.1750\n",
      "steps [234/5000], loss:0.1633\n",
      "steps [235/5000], loss:0.1856\n",
      "steps [236/5000], loss:0.1960\n",
      "steps [237/5000], loss:0.1638\n",
      "steps [238/5000], loss:0.1652\n",
      "steps [239/5000], loss:0.1809\n",
      "steps [240/5000], loss:0.1654\n",
      "steps [241/5000], loss:0.1804\n",
      "steps [242/5000], loss:0.1760\n",
      "steps [243/5000], loss:0.1891\n",
      "steps [244/5000], loss:0.1490\n",
      "steps [245/5000], loss:0.1725\n",
      "steps [246/5000], loss:0.1894\n",
      "steps [247/5000], loss:0.1626\n",
      "steps [248/5000], loss:0.1642\n",
      "steps [249/5000], loss:0.1735\n",
      "steps [250/5000], loss:0.1617\n",
      "steps [251/5000], loss:0.1624\n",
      "steps [252/5000], loss:0.1556\n",
      "steps [253/5000], loss:0.1627\n",
      "steps [254/5000], loss:0.1443\n",
      "steps [255/5000], loss:0.1718\n",
      "steps [256/5000], loss:0.1597\n",
      "steps [257/5000], loss:0.1624\n",
      "steps [258/5000], loss:0.1510\n",
      "steps [259/5000], loss:0.1737\n",
      "steps [260/5000], loss:0.1804\n",
      "steps [261/5000], loss:0.1578\n",
      "steps [262/5000], loss:0.1696\n",
      "steps [263/5000], loss:0.1643\n",
      "steps [264/5000], loss:0.1575\n",
      "steps [265/5000], loss:0.1870\n",
      "steps [266/5000], loss:0.1645\n",
      "steps [267/5000], loss:0.1456\n",
      "steps [268/5000], loss:0.1878\n",
      "steps [269/5000], loss:0.1696\n",
      "steps [270/5000], loss:0.1739\n",
      "steps [271/5000], loss:0.1980\n",
      "steps [272/5000], loss:0.1570\n",
      "steps [273/5000], loss:0.1883\n",
      "steps [274/5000], loss:0.1657\n",
      "steps [275/5000], loss:0.1699\n",
      "steps [276/5000], loss:0.1590\n",
      "steps [277/5000], loss:0.1748\n",
      "steps [278/5000], loss:0.1512\n",
      "steps [279/5000], loss:0.1545\n",
      "steps [280/5000], loss:0.1622\n",
      "steps [281/5000], loss:0.1565\n",
      "steps [282/5000], loss:0.1597\n",
      "steps [283/5000], loss:0.1728\n",
      "steps [284/5000], loss:0.1604\n",
      "steps [285/5000], loss:0.1737\n",
      "steps [286/5000], loss:0.1693\n",
      "steps [287/5000], loss:0.1700\n",
      "steps [288/5000], loss:0.1655\n",
      "steps [289/5000], loss:0.1613\n",
      "steps [290/5000], loss:0.1638\n",
      "steps [291/5000], loss:0.1464\n",
      "steps [292/5000], loss:0.1532\n",
      "steps [293/5000], loss:0.1852\n",
      "steps [294/5000], loss:0.1818\n",
      "steps [295/5000], loss:0.1530\n",
      "steps [296/5000], loss:0.1667\n",
      "steps [297/5000], loss:0.1683\n",
      "steps [298/5000], loss:0.1489\n",
      "steps [299/5000], loss:0.1604\n",
      "steps [300/5000], loss:0.1609\n",
      "steps [301/5000], loss:0.1710\n",
      "steps [302/5000], loss:0.1571\n",
      "steps [303/5000], loss:0.1358\n",
      "steps [304/5000], loss:0.1572\n",
      "steps [305/5000], loss:0.1751\n",
      "steps [306/5000], loss:0.1689\n",
      "steps [307/5000], loss:0.1489\n",
      "steps [308/5000], loss:0.1565\n",
      "steps [309/5000], loss:0.1442\n",
      "steps [310/5000], loss:0.1476\n",
      "steps [311/5000], loss:0.1715\n",
      "steps [312/5000], loss:0.1851\n",
      "steps [313/5000], loss:0.1617\n",
      "steps [314/5000], loss:0.1712\n",
      "steps [315/5000], loss:0.1550\n",
      "steps [316/5000], loss:0.1835\n",
      "steps [317/5000], loss:0.1557\n",
      "steps [318/5000], loss:0.1389\n",
      "steps [319/5000], loss:0.1578\n",
      "steps [320/5000], loss:0.1666\n",
      "steps [321/5000], loss:0.1438\n",
      "steps [322/5000], loss:0.1541\n",
      "steps [323/5000], loss:0.1577\n",
      "steps [324/5000], loss:0.1671\n",
      "steps [325/5000], loss:0.1678\n",
      "steps [326/5000], loss:0.1573\n",
      "steps [327/5000], loss:0.1521\n",
      "steps [328/5000], loss:0.1575\n",
      "steps [329/5000], loss:0.1549\n",
      "steps [330/5000], loss:0.1669\n",
      "steps [331/5000], loss:0.1669\n",
      "steps [332/5000], loss:0.1680\n",
      "steps [333/5000], loss:0.1469\n",
      "steps [334/5000], loss:0.1476\n",
      "steps [335/5000], loss:0.1410\n",
      "steps [336/5000], loss:0.1727\n",
      "steps [337/5000], loss:0.1686\n",
      "steps [338/5000], loss:0.1801\n",
      "steps [339/5000], loss:0.1587\n",
      "steps [340/5000], loss:0.1472\n",
      "steps [341/5000], loss:0.1436\n",
      "steps [342/5000], loss:0.1614\n",
      "steps [343/5000], loss:0.1412\n",
      "steps [344/5000], loss:0.1688\n",
      "steps [345/5000], loss:0.1528\n",
      "steps [346/5000], loss:0.1264\n",
      "steps [347/5000], loss:0.1639\n",
      "steps [348/5000], loss:0.1639\n",
      "steps [349/5000], loss:0.1492\n",
      "steps [350/5000], loss:0.1489\n",
      "steps [351/5000], loss:0.1654\n",
      "steps [352/5000], loss:0.1343\n",
      "steps [353/5000], loss:0.1498\n",
      "steps [354/5000], loss:0.1584\n",
      "steps [355/5000], loss:0.1565\n",
      "steps [356/5000], loss:0.1512\n",
      "steps [357/5000], loss:0.1545\n",
      "steps [358/5000], loss:0.1400\n",
      "steps [359/5000], loss:0.1640\n",
      "steps [360/5000], loss:0.1474\n",
      "steps [361/5000], loss:0.1434\n",
      "steps [362/5000], loss:0.1676\n",
      "steps [363/5000], loss:0.1581\n",
      "steps [364/5000], loss:0.1362\n",
      "steps [365/5000], loss:0.1683\n",
      "steps [366/5000], loss:0.1534\n",
      "steps [367/5000], loss:0.1435\n",
      "steps [368/5000], loss:0.1553\n",
      "steps [369/5000], loss:0.1454\n",
      "steps [370/5000], loss:0.1654\n",
      "steps [371/5000], loss:0.1471\n",
      "steps [372/5000], loss:0.1426\n",
      "steps [373/5000], loss:0.1737\n",
      "steps [374/5000], loss:0.1510\n",
      "steps [375/5000], loss:0.1820\n",
      "steps [376/5000], loss:0.1567\n",
      "steps [377/5000], loss:0.1544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [378/5000], loss:0.1604\n",
      "steps [379/5000], loss:0.1394\n",
      "steps [380/5000], loss:0.1759\n",
      "steps [381/5000], loss:0.1591\n",
      "steps [382/5000], loss:0.1375\n",
      "steps [383/5000], loss:0.1519\n",
      "steps [384/5000], loss:0.1642\n",
      "steps [385/5000], loss:0.1442\n",
      "steps [386/5000], loss:0.1598\n",
      "steps [387/5000], loss:0.1619\n",
      "steps [388/5000], loss:0.1540\n",
      "steps [389/5000], loss:0.1630\n",
      "steps [390/5000], loss:0.1558\n",
      "steps [391/5000], loss:0.1505\n",
      "steps [392/5000], loss:0.1565\n",
      "steps [393/5000], loss:0.1627\n",
      "steps [394/5000], loss:0.1511\n",
      "steps [395/5000], loss:0.1745\n",
      "steps [396/5000], loss:0.1485\n",
      "steps [397/5000], loss:0.1642\n",
      "steps [398/5000], loss:0.1725\n",
      "steps [399/5000], loss:0.1529\n",
      "steps [400/5000], loss:0.1363\n",
      "steps [401/5000], loss:0.1405\n",
      "steps [402/5000], loss:0.1708\n",
      "steps [403/5000], loss:0.1574\n",
      "steps [404/5000], loss:0.1451\n",
      "steps [405/5000], loss:0.1505\n",
      "steps [406/5000], loss:0.1459\n",
      "steps [407/5000], loss:0.1458\n",
      "steps [408/5000], loss:0.1494\n",
      "steps [409/5000], loss:0.1585\n",
      "steps [410/5000], loss:0.1427\n",
      "steps [411/5000], loss:0.1687\n",
      "steps [412/5000], loss:0.1533\n",
      "steps [413/5000], loss:0.1551\n",
      "steps [414/5000], loss:0.1938\n",
      "steps [415/5000], loss:0.1656\n",
      "steps [416/5000], loss:0.1493\n",
      "steps [417/5000], loss:0.1585\n",
      "steps [418/5000], loss:0.1536\n",
      "steps [419/5000], loss:0.1535\n",
      "steps [420/5000], loss:0.1478\n",
      "steps [421/5000], loss:0.1391\n",
      "steps [422/5000], loss:0.1478\n",
      "steps [423/5000], loss:0.1659\n",
      "steps [424/5000], loss:0.1455\n",
      "steps [425/5000], loss:0.1873\n",
      "steps [426/5000], loss:0.1696\n",
      "steps [427/5000], loss:0.1555\n",
      "steps [428/5000], loss:0.1496\n",
      "steps [429/5000], loss:0.1650\n",
      "steps [430/5000], loss:0.1487\n",
      "steps [431/5000], loss:0.1648\n",
      "steps [432/5000], loss:0.1466\n",
      "steps [433/5000], loss:0.1485\n",
      "steps [434/5000], loss:0.1442\n",
      "steps [435/5000], loss:0.1628\n",
      "steps [436/5000], loss:0.1465\n",
      "steps [437/5000], loss:0.1483\n",
      "steps [438/5000], loss:0.1498\n",
      "steps [439/5000], loss:0.1447\n",
      "steps [440/5000], loss:0.1415\n",
      "steps [441/5000], loss:0.1630\n",
      "steps [442/5000], loss:0.1604\n",
      "steps [443/5000], loss:0.1514\n",
      "steps [444/5000], loss:0.1407\n",
      "steps [445/5000], loss:0.1489\n",
      "steps [446/5000], loss:0.1555\n",
      "steps [447/5000], loss:0.1459\n",
      "steps [448/5000], loss:0.1485\n",
      "steps [449/5000], loss:0.1532\n",
      "steps [450/5000], loss:0.1612\n",
      "steps [451/5000], loss:0.1486\n",
      "steps [452/5000], loss:0.1548\n",
      "steps [453/5000], loss:0.1380\n",
      "steps [454/5000], loss:0.1331\n",
      "steps [455/5000], loss:0.1445\n",
      "steps [456/5000], loss:0.1535\n",
      "steps [457/5000], loss:0.1612\n",
      "steps [458/5000], loss:0.1614\n",
      "steps [459/5000], loss:0.1449\n",
      "steps [460/5000], loss:0.1509\n",
      "steps [461/5000], loss:0.1871\n",
      "steps [462/5000], loss:0.1527\n",
      "steps [463/5000], loss:0.1579\n",
      "steps [464/5000], loss:0.1500\n",
      "steps [465/5000], loss:0.1439\n",
      "steps [466/5000], loss:0.1412\n",
      "steps [467/5000], loss:0.1628\n",
      "steps [468/5000], loss:0.1450\n",
      "steps [469/5000], loss:0.1514\n",
      "steps [470/5000], loss:0.1454\n",
      "steps [471/5000], loss:0.1603\n",
      "steps [472/5000], loss:0.1519\n",
      "steps [473/5000], loss:0.1820\n",
      "steps [474/5000], loss:0.1694\n",
      "steps [475/5000], loss:0.1652\n",
      "steps [476/5000], loss:0.1400\n",
      "steps [477/5000], loss:0.1625\n",
      "steps [478/5000], loss:0.1621\n",
      "steps [479/5000], loss:0.1529\n",
      "steps [480/5000], loss:0.1537\n",
      "steps [481/5000], loss:0.1643\n",
      "steps [482/5000], loss:0.1502\n",
      "steps [483/5000], loss:0.1446\n",
      "steps [484/5000], loss:0.1441\n",
      "steps [485/5000], loss:0.1531\n",
      "steps [486/5000], loss:0.1447\n",
      "steps [487/5000], loss:0.1775\n",
      "steps [488/5000], loss:0.1490\n",
      "steps [489/5000], loss:0.1319\n",
      "steps [490/5000], loss:0.1884\n",
      "steps [491/5000], loss:0.1698\n",
      "steps [492/5000], loss:0.1335\n",
      "steps [493/5000], loss:0.1393\n",
      "steps [494/5000], loss:0.1449\n",
      "steps [495/5000], loss:0.1563\n",
      "steps [496/5000], loss:0.1526\n",
      "steps [497/5000], loss:0.1385\n",
      "steps [498/5000], loss:0.1482\n",
      "steps [499/5000], loss:0.1452\n",
      "steps [500/5000], loss:0.1451\n",
      "steps [501/5000], loss:0.1418\n",
      "steps [502/5000], loss:0.1470\n",
      "steps [503/5000], loss:0.1438\n",
      "steps [504/5000], loss:0.1374\n",
      "steps [505/5000], loss:0.1552\n",
      "steps [506/5000], loss:0.1493\n",
      "steps [507/5000], loss:0.1517\n",
      "steps [508/5000], loss:0.1546\n",
      "steps [509/5000], loss:0.1383\n",
      "steps [510/5000], loss:0.1682\n",
      "steps [511/5000], loss:0.1455\n",
      "steps [512/5000], loss:0.1387\n",
      "steps [513/5000], loss:0.1477\n",
      "steps [514/5000], loss:0.1395\n",
      "steps [515/5000], loss:0.1594\n",
      "steps [516/5000], loss:0.1749\n",
      "steps [517/5000], loss:0.1458\n",
      "steps [518/5000], loss:0.1430\n",
      "steps [519/5000], loss:0.1610\n",
      "steps [520/5000], loss:0.1494\n",
      "steps [521/5000], loss:0.1535\n",
      "steps [522/5000], loss:0.1599\n",
      "steps [523/5000], loss:0.1508\n",
      "steps [524/5000], loss:0.1427\n",
      "steps [525/5000], loss:0.1428\n",
      "steps [526/5000], loss:0.1517\n",
      "steps [527/5000], loss:0.1444\n",
      "steps [528/5000], loss:0.1445\n",
      "steps [529/5000], loss:0.1543\n",
      "steps [530/5000], loss:0.1363\n",
      "steps [531/5000], loss:0.1373\n",
      "steps [532/5000], loss:0.1309\n",
      "steps [533/5000], loss:0.1486\n",
      "steps [534/5000], loss:0.1358\n",
      "steps [535/5000], loss:0.1438\n",
      "steps [536/5000], loss:0.1738\n",
      "steps [537/5000], loss:0.1680\n",
      "steps [538/5000], loss:0.1492\n",
      "steps [539/5000], loss:0.1386\n",
      "steps [540/5000], loss:0.1480\n",
      "steps [541/5000], loss:0.1470\n",
      "steps [542/5000], loss:0.1875\n",
      "steps [543/5000], loss:0.1617\n",
      "steps [544/5000], loss:0.1657\n",
      "steps [545/5000], loss:0.1354\n",
      "steps [546/5000], loss:0.1427\n",
      "steps [547/5000], loss:0.1516\n",
      "steps [548/5000], loss:0.1396\n",
      "steps [549/5000], loss:0.1600\n",
      "steps [550/5000], loss:0.1417\n",
      "steps [551/5000], loss:0.1525\n",
      "steps [552/5000], loss:0.1558\n",
      "steps [553/5000], loss:0.1379\n",
      "steps [554/5000], loss:0.1435\n",
      "steps [555/5000], loss:0.1422\n",
      "steps [556/5000], loss:0.1416\n",
      "steps [557/5000], loss:0.1586\n",
      "steps [558/5000], loss:0.1423\n",
      "steps [559/5000], loss:0.1663\n",
      "steps [560/5000], loss:0.1685\n",
      "steps [561/5000], loss:0.1429\n",
      "steps [562/5000], loss:0.1462\n",
      "steps [563/5000], loss:0.1473\n",
      "steps [564/5000], loss:0.1529\n",
      "steps [565/5000], loss:0.1499\n",
      "steps [566/5000], loss:0.1427\n",
      "steps [567/5000], loss:0.1412\n",
      "steps [568/5000], loss:0.1339\n",
      "steps [569/5000], loss:0.1375\n",
      "steps [570/5000], loss:0.1551\n",
      "steps [571/5000], loss:0.1792\n",
      "steps [572/5000], loss:0.1686\n",
      "steps [573/5000], loss:0.1357\n",
      "steps [574/5000], loss:0.1606\n",
      "steps [575/5000], loss:0.1425\n",
      "steps [576/5000], loss:0.1261\n",
      "steps [577/5000], loss:0.1483\n",
      "steps [578/5000], loss:0.1457\n",
      "steps [579/5000], loss:0.1690\n",
      "steps [580/5000], loss:0.1373\n",
      "steps [581/5000], loss:0.1535\n",
      "steps [582/5000], loss:0.1703\n",
      "steps [583/5000], loss:0.1428\n",
      "steps [584/5000], loss:0.1293\n",
      "steps [585/5000], loss:0.1391\n",
      "steps [586/5000], loss:0.1455\n",
      "steps [587/5000], loss:0.1403\n",
      "steps [588/5000], loss:0.1517\n",
      "steps [589/5000], loss:0.1353\n",
      "steps [590/5000], loss:0.1457\n",
      "steps [591/5000], loss:0.1668\n",
      "steps [592/5000], loss:0.1505\n",
      "steps [593/5000], loss:0.1508\n",
      "steps [594/5000], loss:0.1432\n",
      "steps [595/5000], loss:0.1545\n",
      "steps [596/5000], loss:0.1466\n",
      "steps [597/5000], loss:0.1600\n",
      "steps [598/5000], loss:0.1718\n",
      "steps [599/5000], loss:0.1324\n",
      "steps [600/5000], loss:0.1445\n",
      "steps [601/5000], loss:0.1711\n",
      "steps [602/5000], loss:0.1582\n",
      "steps [603/5000], loss:0.1417\n",
      "steps [604/5000], loss:0.1455\n",
      "steps [605/5000], loss:0.1510\n",
      "steps [606/5000], loss:0.1493\n",
      "steps [607/5000], loss:0.1320\n",
      "steps [608/5000], loss:0.1657\n",
      "steps [609/5000], loss:0.1762\n",
      "steps [610/5000], loss:0.1578\n",
      "steps [611/5000], loss:0.1395\n",
      "steps [612/5000], loss:0.1558\n",
      "steps [613/5000], loss:0.1417\n",
      "steps [614/5000], loss:0.1233\n",
      "steps [615/5000], loss:0.1498\n",
      "steps [616/5000], loss:0.1417\n",
      "steps [617/5000], loss:0.1647\n",
      "steps [618/5000], loss:0.1511\n",
      "steps [619/5000], loss:0.1345\n",
      "steps [620/5000], loss:0.1376\n",
      "steps [621/5000], loss:0.1373\n",
      "steps [622/5000], loss:0.1621\n",
      "steps [623/5000], loss:0.1474\n",
      "steps [624/5000], loss:0.1482\n",
      "steps [625/5000], loss:0.1385\n",
      "steps [626/5000], loss:0.1518\n",
      "steps [627/5000], loss:0.1329\n",
      "steps [628/5000], loss:0.1603\n",
      "steps [629/5000], loss:0.1259\n",
      "steps [630/5000], loss:0.1318\n",
      "steps [631/5000], loss:0.1325\n",
      "steps [632/5000], loss:0.1380\n",
      "steps [633/5000], loss:0.1436\n",
      "steps [634/5000], loss:0.1560\n",
      "steps [635/5000], loss:0.1546\n",
      "steps [636/5000], loss:0.1380\n",
      "steps [637/5000], loss:0.1502\n",
      "steps [638/5000], loss:0.1461\n",
      "steps [639/5000], loss:0.1649\n",
      "steps [640/5000], loss:0.1374\n",
      "steps [641/5000], loss:0.1543\n",
      "steps [642/5000], loss:0.1630\n",
      "steps [643/5000], loss:0.1431\n",
      "steps [644/5000], loss:0.1446\n",
      "steps [645/5000], loss:0.1449\n",
      "steps [646/5000], loss:0.1505\n",
      "steps [647/5000], loss:0.1375\n",
      "steps [648/5000], loss:0.1426\n",
      "steps [649/5000], loss:0.1653\n",
      "steps [650/5000], loss:0.1544\n",
      "steps [651/5000], loss:0.1470\n",
      "steps [652/5000], loss:0.1422\n",
      "steps [653/5000], loss:0.1325\n",
      "steps [654/5000], loss:0.1711\n",
      "steps [655/5000], loss:0.1447\n",
      "steps [656/5000], loss:0.1554\n",
      "steps [657/5000], loss:0.1366\n",
      "steps [658/5000], loss:0.1472\n",
      "steps [659/5000], loss:0.1655\n",
      "steps [660/5000], loss:0.1517\n",
      "steps [661/5000], loss:0.1351\n",
      "steps [662/5000], loss:0.1419\n",
      "steps [663/5000], loss:0.1670\n",
      "steps [664/5000], loss:0.1560\n",
      "steps [665/5000], loss:0.1787\n",
      "steps [666/5000], loss:0.1470\n",
      "steps [667/5000], loss:0.1458\n",
      "steps [668/5000], loss:0.1479\n",
      "steps [669/5000], loss:0.1450\n",
      "steps [670/5000], loss:0.1396\n",
      "steps [671/5000], loss:0.1501\n",
      "steps [672/5000], loss:0.1446\n",
      "steps [673/5000], loss:0.1549\n",
      "steps [674/5000], loss:0.1563\n",
      "steps [675/5000], loss:0.1484\n",
      "steps [676/5000], loss:0.1307\n",
      "steps [677/5000], loss:0.1457\n",
      "steps [678/5000], loss:0.2371\n",
      "steps [679/5000], loss:0.1542\n",
      "steps [680/5000], loss:0.1578\n",
      "steps [681/5000], loss:0.1757\n",
      "steps [682/5000], loss:0.1540\n",
      "steps [683/5000], loss:0.1551\n",
      "steps [684/5000], loss:0.1590\n",
      "steps [685/5000], loss:0.1572\n",
      "steps [686/5000], loss:0.1444\n",
      "steps [687/5000], loss:0.1427\n",
      "steps [688/5000], loss:0.1652\n",
      "steps [689/5000], loss:0.1626\n",
      "steps [690/5000], loss:0.1330\n",
      "steps [691/5000], loss:0.1456\n",
      "steps [692/5000], loss:0.1680\n",
      "steps [693/5000], loss:0.1428\n",
      "steps [694/5000], loss:0.1488\n",
      "steps [695/5000], loss:0.1378\n",
      "steps [696/5000], loss:0.1511\n",
      "steps [697/5000], loss:0.1390\n",
      "steps [698/5000], loss:0.1489\n",
      "steps [699/5000], loss:0.1433\n",
      "steps [700/5000], loss:0.1345\n",
      "steps [701/5000], loss:0.1569\n",
      "steps [702/5000], loss:0.1463\n",
      "steps [703/5000], loss:0.1449\n",
      "steps [704/5000], loss:0.1490\n",
      "steps [705/5000], loss:0.1307\n",
      "steps [706/5000], loss:0.1496\n",
      "steps [707/5000], loss:0.1451\n",
      "steps [708/5000], loss:0.1530\n",
      "steps [709/5000], loss:0.1741\n",
      "steps [710/5000], loss:0.1440\n",
      "steps [711/5000], loss:0.1309\n",
      "steps [712/5000], loss:0.1537\n",
      "steps [713/5000], loss:0.1485\n",
      "steps [714/5000], loss:0.1732\n",
      "steps [715/5000], loss:0.1480\n",
      "steps [716/5000], loss:0.1668\n",
      "steps [717/5000], loss:0.1309\n",
      "steps [718/5000], loss:0.1550\n",
      "steps [719/5000], loss:0.1330\n",
      "steps [720/5000], loss:0.1532\n",
      "steps [721/5000], loss:0.1613\n",
      "steps [722/5000], loss:0.1481\n",
      "steps [723/5000], loss:0.1448\n",
      "steps [724/5000], loss:0.1436\n",
      "steps [725/5000], loss:0.1451\n",
      "steps [726/5000], loss:0.1389\n",
      "steps [727/5000], loss:0.1395\n",
      "steps [728/5000], loss:0.1478\n",
      "steps [729/5000], loss:0.1606\n",
      "steps [730/5000], loss:0.1330\n",
      "steps [731/5000], loss:0.1313\n",
      "steps [732/5000], loss:0.1499\n",
      "steps [733/5000], loss:0.1628\n",
      "steps [734/5000], loss:0.1383\n",
      "steps [735/5000], loss:0.1570\n",
      "steps [736/5000], loss:0.1739\n",
      "steps [737/5000], loss:0.1701\n",
      "steps [738/5000], loss:0.1760\n",
      "steps [739/5000], loss:0.1361\n",
      "steps [740/5000], loss:0.1733\n",
      "steps [741/5000], loss:0.1390\n",
      "steps [742/5000], loss:0.1483\n",
      "steps [743/5000], loss:0.1428\n",
      "steps [744/5000], loss:0.1584\n",
      "steps [745/5000], loss:0.1605\n",
      "steps [746/5000], loss:0.1462\n",
      "steps [747/5000], loss:0.1552\n",
      "steps [748/5000], loss:0.1485\n",
      "steps [749/5000], loss:0.1338\n",
      "steps [750/5000], loss:0.1464\n",
      "steps [751/5000], loss:0.1898\n",
      "steps [752/5000], loss:0.1824\n",
      "steps [753/5000], loss:0.1620\n",
      "steps [754/5000], loss:0.1497\n",
      "steps [755/5000], loss:0.1799\n",
      "steps [756/5000], loss:0.1627\n",
      "steps [757/5000], loss:0.1512\n",
      "steps [758/5000], loss:0.1525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [759/5000], loss:0.1522\n",
      "steps [760/5000], loss:0.1594\n",
      "steps [761/5000], loss:0.1601\n",
      "steps [762/5000], loss:0.1843\n",
      "steps [763/5000], loss:0.1493\n",
      "steps [764/5000], loss:0.1675\n",
      "steps [765/5000], loss:0.1527\n",
      "steps [766/5000], loss:0.1413\n",
      "steps [767/5000], loss:0.1704\n",
      "steps [768/5000], loss:0.1360\n",
      "steps [769/5000], loss:0.1504\n",
      "steps [770/5000], loss:0.1555\n",
      "steps [771/5000], loss:0.1449\n",
      "steps [772/5000], loss:0.1728\n",
      "steps [773/5000], loss:0.1566\n",
      "steps [774/5000], loss:0.1499\n",
      "steps [775/5000], loss:0.1396\n",
      "steps [776/5000], loss:0.1482\n",
      "steps [777/5000], loss:0.1462\n",
      "steps [778/5000], loss:0.1399\n",
      "steps [779/5000], loss:0.1371\n",
      "steps [780/5000], loss:0.1662\n",
      "steps [781/5000], loss:0.1471\n",
      "steps [782/5000], loss:0.1584\n",
      "steps [783/5000], loss:0.1671\n",
      "steps [784/5000], loss:0.1594\n",
      "steps [785/5000], loss:0.1423\n",
      "steps [786/5000], loss:0.1455\n",
      "steps [787/5000], loss:0.1993\n",
      "steps [788/5000], loss:0.1463\n",
      "steps [789/5000], loss:0.1444\n",
      "steps [790/5000], loss:0.1378\n",
      "steps [791/5000], loss:0.1611\n",
      "steps [792/5000], loss:0.1467\n",
      "steps [793/5000], loss:0.1698\n",
      "steps [794/5000], loss:0.1479\n",
      "steps [795/5000], loss:0.1487\n",
      "steps [796/5000], loss:0.1687\n",
      "steps [797/5000], loss:0.1468\n",
      "steps [798/5000], loss:0.1532\n",
      "steps [799/5000], loss:0.1464\n",
      "steps [800/5000], loss:0.1346\n",
      "steps [801/5000], loss:0.1644\n",
      "steps [802/5000], loss:0.1468\n",
      "steps [803/5000], loss:0.1464\n",
      "steps [804/5000], loss:0.1454\n",
      "steps [805/5000], loss:0.1538\n",
      "steps [806/5000], loss:0.1499\n",
      "steps [807/5000], loss:0.1456\n",
      "steps [808/5000], loss:0.1849\n",
      "steps [809/5000], loss:0.1384\n",
      "steps [810/5000], loss:0.1547\n",
      "steps [811/5000], loss:0.1657\n",
      "steps [812/5000], loss:0.1566\n",
      "steps [813/5000], loss:0.1395\n",
      "steps [814/5000], loss:0.1736\n",
      "steps [815/5000], loss:0.1420\n",
      "steps [816/5000], loss:0.1591\n",
      "steps [817/5000], loss:0.1715\n",
      "steps [818/5000], loss:0.1500\n",
      "steps [819/5000], loss:0.1342\n",
      "steps [820/5000], loss:0.1459\n",
      "steps [821/5000], loss:0.1482\n",
      "steps [822/5000], loss:0.1455\n",
      "steps [823/5000], loss:0.1532\n",
      "steps [824/5000], loss:0.1535\n",
      "steps [825/5000], loss:0.1509\n",
      "steps [826/5000], loss:0.1392\n",
      "steps [827/5000], loss:0.1422\n",
      "steps [828/5000], loss:0.1424\n",
      "steps [829/5000], loss:0.1413\n",
      "steps [830/5000], loss:0.1446\n",
      "steps [831/5000], loss:0.1521\n",
      "steps [832/5000], loss:0.1252\n",
      "steps [833/5000], loss:0.1676\n",
      "steps [834/5000], loss:0.1222\n",
      "steps [835/5000], loss:0.1463\n",
      "steps [836/5000], loss:0.1658\n",
      "steps [837/5000], loss:0.1415\n",
      "steps [838/5000], loss:0.1433\n",
      "steps [839/5000], loss:0.1340\n",
      "steps [840/5000], loss:0.1611\n",
      "steps [841/5000], loss:0.1706\n",
      "steps [842/5000], loss:0.1494\n",
      "steps [843/5000], loss:0.1534\n",
      "steps [844/5000], loss:0.1619\n",
      "steps [845/5000], loss:0.1398\n",
      "steps [846/5000], loss:0.1552\n",
      "steps [847/5000], loss:0.1792\n",
      "steps [848/5000], loss:0.1486\n",
      "steps [849/5000], loss:0.1467\n",
      "steps [850/5000], loss:0.1342\n",
      "steps [851/5000], loss:0.1459\n",
      "steps [852/5000], loss:0.1422\n",
      "steps [853/5000], loss:0.1637\n",
      "steps [854/5000], loss:0.1748\n",
      "steps [855/5000], loss:0.1314\n",
      "steps [856/5000], loss:0.1716\n",
      "steps [857/5000], loss:0.1633\n",
      "steps [858/5000], loss:0.1489\n",
      "steps [859/5000], loss:0.1539\n",
      "steps [860/5000], loss:0.1627\n",
      "steps [861/5000], loss:0.1579\n",
      "steps [862/5000], loss:0.1390\n",
      "steps [863/5000], loss:0.1494\n",
      "steps [864/5000], loss:0.1265\n",
      "steps [865/5000], loss:0.1544\n",
      "steps [866/5000], loss:0.1408\n",
      "steps [867/5000], loss:0.1438\n",
      "steps [868/5000], loss:0.1283\n",
      "steps [869/5000], loss:0.1318\n",
      "steps [870/5000], loss:0.1504\n",
      "steps [871/5000], loss:0.1423\n",
      "steps [872/5000], loss:0.1460\n",
      "steps [873/5000], loss:0.1405\n",
      "steps [874/5000], loss:0.1668\n",
      "steps [875/5000], loss:0.1288\n",
      "steps [876/5000], loss:0.1270\n",
      "steps [877/5000], loss:0.1465\n",
      "steps [878/5000], loss:0.1435\n",
      "steps [879/5000], loss:0.1423\n",
      "steps [880/5000], loss:0.1449\n",
      "steps [881/5000], loss:0.1628\n",
      "steps [882/5000], loss:0.1562\n",
      "steps [883/5000], loss:0.1366\n",
      "steps [884/5000], loss:0.1619\n",
      "steps [885/5000], loss:0.1492\n",
      "steps [886/5000], loss:0.1382\n",
      "steps [887/5000], loss:0.1407\n",
      "steps [888/5000], loss:0.1453\n",
      "steps [889/5000], loss:0.1466\n",
      "steps [890/5000], loss:0.1330\n",
      "steps [891/5000], loss:0.1512\n",
      "steps [892/5000], loss:0.1386\n",
      "steps [893/5000], loss:0.1371\n",
      "steps [894/5000], loss:0.1534\n",
      "steps [895/5000], loss:0.1531\n",
      "steps [896/5000], loss:0.1699\n",
      "steps [897/5000], loss:0.1502\n",
      "steps [898/5000], loss:0.1313\n",
      "steps [899/5000], loss:0.1440\n",
      "steps [900/5000], loss:0.1479\n",
      "steps [901/5000], loss:0.1351\n",
      "steps [902/5000], loss:0.1392\n",
      "steps [903/5000], loss:0.1390\n",
      "steps [904/5000], loss:0.1576\n",
      "steps [905/5000], loss:0.1588\n",
      "steps [906/5000], loss:0.1343\n",
      "steps [907/5000], loss:0.1514\n",
      "steps [908/5000], loss:0.1412\n",
      "steps [909/5000], loss:0.1375\n",
      "steps [910/5000], loss:0.1441\n",
      "steps [911/5000], loss:0.1379\n",
      "steps [912/5000], loss:0.1486\n",
      "steps [913/5000], loss:0.1482\n",
      "steps [914/5000], loss:0.1465\n",
      "steps [915/5000], loss:0.1446\n",
      "steps [916/5000], loss:0.1516\n",
      "steps [917/5000], loss:0.1664\n",
      "steps [918/5000], loss:0.1305\n",
      "steps [919/5000], loss:0.1664\n",
      "steps [920/5000], loss:0.1470\n",
      "steps [921/5000], loss:0.1651\n",
      "steps [922/5000], loss:0.1423\n",
      "steps [923/5000], loss:0.1506\n",
      "steps [924/5000], loss:0.2048\n",
      "steps [925/5000], loss:0.1422\n",
      "steps [926/5000], loss:0.1358\n",
      "steps [927/5000], loss:0.1380\n",
      "steps [928/5000], loss:0.1505\n",
      "steps [929/5000], loss:0.1590\n",
      "steps [930/5000], loss:0.1428\n",
      "steps [931/5000], loss:0.1713\n",
      "steps [932/5000], loss:0.1506\n",
      "steps [933/5000], loss:0.1519\n",
      "steps [934/5000], loss:0.1400\n",
      "steps [935/5000], loss:0.1798\n",
      "steps [936/5000], loss:0.1395\n",
      "steps [937/5000], loss:0.1533\n",
      "steps [938/5000], loss:0.1372\n",
      "steps [939/5000], loss:0.1599\n",
      "steps [940/5000], loss:0.1501\n",
      "steps [941/5000], loss:0.1603\n",
      "steps [942/5000], loss:0.1487\n",
      "steps [943/5000], loss:0.1590\n",
      "steps [944/5000], loss:0.1476\n",
      "steps [945/5000], loss:0.1497\n",
      "steps [946/5000], loss:0.1685\n",
      "steps [947/5000], loss:0.1375\n",
      "steps [948/5000], loss:0.1365\n",
      "steps [949/5000], loss:0.1342\n",
      "steps [950/5000], loss:0.1290\n",
      "steps [951/5000], loss:0.1454\n",
      "steps [952/5000], loss:0.1445\n",
      "steps [953/5000], loss:0.1795\n",
      "steps [954/5000], loss:0.1378\n",
      "steps [955/5000], loss:0.1677\n",
      "steps [956/5000], loss:0.1580\n",
      "steps [957/5000], loss:0.1480\n",
      "steps [958/5000], loss:0.1459\n",
      "steps [959/5000], loss:0.1488\n",
      "steps [960/5000], loss:0.1430\n",
      "steps [961/5000], loss:0.1525\n",
      "steps [962/5000], loss:0.1414\n",
      "steps [963/5000], loss:0.1678\n",
      "steps [964/5000], loss:0.1411\n",
      "steps [965/5000], loss:0.1460\n",
      "steps [966/5000], loss:0.1616\n",
      "steps [967/5000], loss:0.1448\n",
      "steps [968/5000], loss:0.1370\n",
      "steps [969/5000], loss:0.1523\n",
      "steps [970/5000], loss:0.1421\n",
      "steps [971/5000], loss:0.1593\n",
      "steps [972/5000], loss:0.1443\n",
      "steps [973/5000], loss:0.1549\n",
      "steps [974/5000], loss:0.1336\n",
      "steps [975/5000], loss:0.1622\n",
      "steps [976/5000], loss:0.1473\n",
      "steps [977/5000], loss:0.1448\n",
      "steps [978/5000], loss:0.1342\n",
      "steps [979/5000], loss:0.1596\n",
      "steps [980/5000], loss:0.1474\n",
      "steps [981/5000], loss:0.1391\n",
      "steps [982/5000], loss:0.1396\n",
      "steps [983/5000], loss:0.1313\n",
      "steps [984/5000], loss:0.1419\n",
      "steps [985/5000], loss:0.1550\n",
      "steps [986/5000], loss:0.1393\n",
      "steps [987/5000], loss:0.1488\n",
      "steps [988/5000], loss:0.1455\n",
      "steps [989/5000], loss:0.1482\n",
      "steps [990/5000], loss:0.1588\n",
      "steps [991/5000], loss:0.1509\n",
      "steps [992/5000], loss:0.1486\n",
      "steps [993/5000], loss:0.1640\n",
      "steps [994/5000], loss:0.1526\n",
      "steps [995/5000], loss:0.1388\n",
      "steps [996/5000], loss:0.1512\n",
      "steps [997/5000], loss:0.1832\n",
      "steps [998/5000], loss:0.1422\n",
      "steps [999/5000], loss:0.1474\n",
      "steps [1000/5000], loss:0.1409\n",
      "steps [1001/5000], loss:0.1263\n",
      "steps [1002/5000], loss:0.1324\n",
      "steps [1003/5000], loss:0.1498\n",
      "steps [1004/5000], loss:0.1291\n",
      "steps [1005/5000], loss:0.1390\n",
      "steps [1006/5000], loss:0.1750\n",
      "steps [1007/5000], loss:0.1423\n",
      "steps [1008/5000], loss:0.1617\n",
      "steps [1009/5000], loss:0.1657\n",
      "steps [1010/5000], loss:0.1463\n",
      "steps [1011/5000], loss:0.1493\n",
      "steps [1012/5000], loss:0.1271\n",
      "steps [1013/5000], loss:0.1425\n",
      "steps [1014/5000], loss:0.1400\n",
      "steps [1015/5000], loss:0.1637\n",
      "steps [1016/5000], loss:0.1449\n",
      "steps [1017/5000], loss:0.1377\n",
      "steps [1018/5000], loss:0.1385\n",
      "steps [1019/5000], loss:0.1615\n",
      "steps [1020/5000], loss:0.1414\n",
      "steps [1021/5000], loss:0.1450\n",
      "steps [1022/5000], loss:0.1676\n",
      "steps [1023/5000], loss:0.1422\n",
      "steps [1024/5000], loss:0.1466\n",
      "steps [1025/5000], loss:0.1752\n",
      "steps [1026/5000], loss:0.1307\n",
      "steps [1027/5000], loss:0.1451\n",
      "steps [1028/5000], loss:0.1364\n",
      "steps [1029/5000], loss:0.1514\n",
      "steps [1030/5000], loss:0.1431\n",
      "steps [1031/5000], loss:0.1469\n",
      "steps [1032/5000], loss:0.1351\n",
      "steps [1033/5000], loss:0.1541\n",
      "steps [1034/5000], loss:0.1541\n",
      "steps [1035/5000], loss:0.1272\n",
      "steps [1036/5000], loss:0.1508\n",
      "steps [1037/5000], loss:0.1730\n",
      "steps [1038/5000], loss:0.1524\n",
      "steps [1039/5000], loss:0.1357\n",
      "steps [1040/5000], loss:0.1387\n",
      "steps [1041/5000], loss:0.1304\n",
      "steps [1042/5000], loss:0.1628\n",
      "steps [1043/5000], loss:0.1653\n",
      "steps [1044/5000], loss:0.1520\n",
      "steps [1045/5000], loss:0.1257\n",
      "steps [1046/5000], loss:0.1757\n",
      "steps [1047/5000], loss:0.1493\n",
      "steps [1048/5000], loss:0.1468\n",
      "steps [1049/5000], loss:0.1364\n",
      "steps [1050/5000], loss:0.1443\n",
      "steps [1051/5000], loss:0.1740\n",
      "steps [1052/5000], loss:0.1467\n",
      "steps [1053/5000], loss:0.1492\n",
      "steps [1054/5000], loss:0.1657\n",
      "steps [1055/5000], loss:0.1373\n",
      "steps [1056/5000], loss:0.1566\n",
      "steps [1057/5000], loss:0.1410\n",
      "steps [1058/5000], loss:0.1557\n",
      "steps [1059/5000], loss:0.1402\n",
      "steps [1060/5000], loss:0.1339\n",
      "steps [1061/5000], loss:0.1474\n",
      "steps [1062/5000], loss:0.1461\n",
      "steps [1063/5000], loss:0.1406\n",
      "steps [1064/5000], loss:0.1411\n",
      "steps [1065/5000], loss:0.1442\n",
      "steps [1066/5000], loss:0.1395\n",
      "steps [1067/5000], loss:0.1319\n",
      "steps [1068/5000], loss:0.1392\n",
      "steps [1069/5000], loss:0.1412\n",
      "steps [1070/5000], loss:0.1569\n",
      "steps [1071/5000], loss:0.1598\n",
      "steps [1072/5000], loss:0.1397\n",
      "steps [1073/5000], loss:0.1419\n",
      "steps [1074/5000], loss:0.1670\n",
      "steps [1075/5000], loss:0.1638\n",
      "steps [1076/5000], loss:0.1487\n",
      "steps [1077/5000], loss:0.1374\n",
      "steps [1078/5000], loss:0.1634\n",
      "steps [1079/5000], loss:0.1540\n",
      "steps [1080/5000], loss:0.1380\n",
      "steps [1081/5000], loss:0.1208\n",
      "steps [1082/5000], loss:0.1495\n",
      "steps [1083/5000], loss:0.1436\n",
      "steps [1084/5000], loss:0.1461\n",
      "steps [1085/5000], loss:0.1561\n",
      "steps [1086/5000], loss:0.1547\n",
      "steps [1087/5000], loss:0.1391\n",
      "steps [1088/5000], loss:0.1375\n",
      "steps [1089/5000], loss:0.1247\n",
      "steps [1090/5000], loss:0.1509\n",
      "steps [1091/5000], loss:0.1373\n",
      "steps [1092/5000], loss:0.1535\n",
      "steps [1093/5000], loss:0.1251\n",
      "steps [1094/5000], loss:0.1400\n",
      "steps [1095/5000], loss:0.1461\n",
      "steps [1096/5000], loss:0.1249\n",
      "steps [1097/5000], loss:0.1377\n",
      "steps [1098/5000], loss:0.1406\n",
      "steps [1099/5000], loss:0.1435\n",
      "steps [1100/5000], loss:0.1518\n",
      "steps [1101/5000], loss:0.1399\n",
      "steps [1102/5000], loss:0.1334\n",
      "steps [1103/5000], loss:0.1546\n",
      "steps [1104/5000], loss:0.1476\n",
      "steps [1105/5000], loss:0.1319\n",
      "steps [1106/5000], loss:0.1443\n",
      "steps [1107/5000], loss:0.1453\n",
      "steps [1108/5000], loss:0.1245\n",
      "steps [1109/5000], loss:0.1374\n",
      "steps [1110/5000], loss:0.1473\n",
      "steps [1111/5000], loss:0.1263\n",
      "steps [1112/5000], loss:0.1384\n",
      "steps [1113/5000], loss:0.1556\n",
      "steps [1114/5000], loss:0.1364\n",
      "steps [1115/5000], loss:0.1435\n",
      "steps [1116/5000], loss:0.1446\n",
      "steps [1117/5000], loss:0.1419\n",
      "steps [1118/5000], loss:0.1341\n",
      "steps [1119/5000], loss:0.1470\n",
      "steps [1120/5000], loss:0.1370\n",
      "steps [1121/5000], loss:0.1337\n",
      "steps [1122/5000], loss:0.1429\n",
      "steps [1123/5000], loss:0.1525\n",
      "steps [1124/5000], loss:0.1282\n",
      "steps [1125/5000], loss:0.1490\n",
      "steps [1126/5000], loss:0.1425\n",
      "steps [1127/5000], loss:0.1291\n",
      "steps [1128/5000], loss:0.1530\n",
      "steps [1129/5000], loss:0.1470\n",
      "steps [1130/5000], loss:0.1552\n",
      "steps [1131/5000], loss:0.1798\n",
      "steps [1132/5000], loss:0.1512\n",
      "steps [1133/5000], loss:0.1373\n",
      "steps [1134/5000], loss:0.1413\n",
      "steps [1135/5000], loss:0.1469\n",
      "steps [1136/5000], loss:0.1359\n",
      "steps [1137/5000], loss:0.1560\n",
      "steps [1138/5000], loss:0.1485\n",
      "steps [1139/5000], loss:0.1204\n",
      "steps [1140/5000], loss:0.1359\n",
      "steps [1141/5000], loss:0.1549\n",
      "steps [1142/5000], loss:0.1517\n",
      "steps [1143/5000], loss:0.1470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [1144/5000], loss:0.1456\n",
      "steps [1145/5000], loss:0.1593\n",
      "steps [1146/5000], loss:0.1396\n",
      "steps [1147/5000], loss:0.1588\n",
      "steps [1148/5000], loss:0.1450\n",
      "steps [1149/5000], loss:0.1588\n",
      "steps [1150/5000], loss:0.1524\n",
      "steps [1151/5000], loss:0.1641\n",
      "steps [1152/5000], loss:0.1455\n",
      "steps [1153/5000], loss:0.1463\n",
      "steps [1154/5000], loss:0.1356\n",
      "steps [1155/5000], loss:0.1571\n",
      "steps [1156/5000], loss:0.1548\n",
      "steps [1157/5000], loss:0.1559\n",
      "steps [1158/5000], loss:0.1579\n",
      "steps [1159/5000], loss:0.1531\n",
      "steps [1160/5000], loss:0.1490\n",
      "steps [1161/5000], loss:0.1393\n",
      "steps [1162/5000], loss:0.1355\n",
      "steps [1163/5000], loss:0.1264\n",
      "steps [1164/5000], loss:0.1419\n",
      "steps [1165/5000], loss:0.1464\n",
      "steps [1166/5000], loss:0.1434\n",
      "steps [1167/5000], loss:0.1435\n",
      "steps [1168/5000], loss:0.1619\n",
      "steps [1169/5000], loss:0.1498\n",
      "steps [1170/5000], loss:0.1627\n",
      "steps [1171/5000], loss:0.1451\n",
      "steps [1172/5000], loss:0.1572\n",
      "steps [1173/5000], loss:0.1478\n",
      "steps [1174/5000], loss:0.1613\n",
      "steps [1175/5000], loss:0.1462\n",
      "steps [1176/5000], loss:0.1557\n",
      "steps [1177/5000], loss:0.1596\n",
      "steps [1178/5000], loss:0.1435\n",
      "steps [1179/5000], loss:0.1463\n",
      "steps [1180/5000], loss:0.1452\n",
      "steps [1181/5000], loss:0.1677\n",
      "steps [1182/5000], loss:0.1431\n",
      "steps [1183/5000], loss:0.1314\n",
      "steps [1184/5000], loss:0.1605\n",
      "steps [1185/5000], loss:0.1354\n",
      "steps [1186/5000], loss:0.1486\n",
      "steps [1187/5000], loss:0.1514\n",
      "steps [1188/5000], loss:0.1428\n",
      "steps [1189/5000], loss:0.1310\n",
      "steps [1190/5000], loss:0.1438\n",
      "steps [1191/5000], loss:0.1419\n",
      "steps [1192/5000], loss:0.1646\n",
      "steps [1193/5000], loss:0.1428\n",
      "steps [1194/5000], loss:0.1285\n",
      "steps [1195/5000], loss:0.1586\n",
      "steps [1196/5000], loss:0.1324\n",
      "steps [1197/5000], loss:0.1558\n",
      "steps [1198/5000], loss:0.1511\n",
      "steps [1199/5000], loss:0.1345\n",
      "steps [1200/5000], loss:0.1438\n",
      "steps [1201/5000], loss:0.1431\n",
      "steps [1202/5000], loss:0.1441\n",
      "steps [1203/5000], loss:0.1416\n",
      "steps [1204/5000], loss:0.1355\n",
      "steps [1205/5000], loss:0.1369\n",
      "steps [1206/5000], loss:0.1335\n",
      "steps [1207/5000], loss:0.1427\n",
      "steps [1208/5000], loss:0.1459\n",
      "steps [1209/5000], loss:0.1495\n",
      "steps [1210/5000], loss:0.1699\n",
      "steps [1211/5000], loss:0.1371\n",
      "steps [1212/5000], loss:0.1299\n",
      "steps [1213/5000], loss:0.1482\n",
      "steps [1214/5000], loss:0.1390\n",
      "steps [1215/5000], loss:0.1460\n",
      "steps [1216/5000], loss:0.1433\n",
      "steps [1217/5000], loss:0.1378\n",
      "steps [1218/5000], loss:0.1598\n",
      "steps [1219/5000], loss:0.1828\n",
      "steps [1220/5000], loss:0.1417\n",
      "steps [1221/5000], loss:0.1423\n",
      "steps [1222/5000], loss:0.1372\n",
      "steps [1223/5000], loss:0.1475\n",
      "steps [1224/5000], loss:0.1552\n",
      "steps [1225/5000], loss:0.1252\n",
      "steps [1226/5000], loss:0.1480\n",
      "steps [1227/5000], loss:0.1445\n",
      "steps [1228/5000], loss:0.1469\n",
      "steps [1229/5000], loss:0.1331\n",
      "steps [1230/5000], loss:0.1405\n",
      "steps [1231/5000], loss:0.1450\n",
      "steps [1232/5000], loss:0.1430\n",
      "steps [1233/5000], loss:0.1414\n",
      "steps [1234/5000], loss:0.1517\n",
      "steps [1235/5000], loss:0.1595\n",
      "steps [1236/5000], loss:0.1417\n",
      "steps [1237/5000], loss:0.1372\n",
      "steps [1238/5000], loss:0.1367\n",
      "steps [1239/5000], loss:0.1617\n",
      "steps [1240/5000], loss:0.1496\n",
      "steps [1241/5000], loss:0.1372\n",
      "steps [1242/5000], loss:0.1469\n",
      "steps [1243/5000], loss:0.1355\n",
      "steps [1244/5000], loss:0.1475\n",
      "steps [1245/5000], loss:0.1466\n",
      "steps [1246/5000], loss:0.1590\n",
      "steps [1247/5000], loss:0.1596\n",
      "steps [1248/5000], loss:0.1308\n",
      "steps [1249/5000], loss:0.1452\n",
      "steps [1250/5000], loss:0.1325\n",
      "steps [1251/5000], loss:0.1578\n",
      "steps [1252/5000], loss:0.1268\n",
      "steps [1253/5000], loss:0.1621\n",
      "steps [1254/5000], loss:0.1440\n",
      "steps [1255/5000], loss:0.1720\n",
      "steps [1256/5000], loss:0.1647\n",
      "steps [1257/5000], loss:0.1457\n",
      "steps [1258/5000], loss:0.1475\n",
      "steps [1259/5000], loss:0.1379\n",
      "steps [1260/5000], loss:0.1513\n",
      "steps [1261/5000], loss:0.1564\n",
      "steps [1262/5000], loss:0.1545\n",
      "steps [1263/5000], loss:0.1500\n",
      "steps [1264/5000], loss:0.1431\n",
      "steps [1265/5000], loss:0.1547\n",
      "steps [1266/5000], loss:0.1493\n",
      "steps [1267/5000], loss:0.1472\n",
      "steps [1268/5000], loss:0.1392\n",
      "steps [1269/5000], loss:0.1636\n",
      "steps [1270/5000], loss:0.1440\n",
      "steps [1271/5000], loss:0.1598\n",
      "steps [1272/5000], loss:0.1614\n",
      "steps [1273/5000], loss:0.1562\n",
      "steps [1274/5000], loss:0.1491\n",
      "steps [1275/5000], loss:0.1467\n",
      "steps [1276/5000], loss:0.1363\n",
      "steps [1277/5000], loss:0.1515\n",
      "steps [1278/5000], loss:0.1429\n",
      "steps [1279/5000], loss:0.1599\n",
      "steps [1280/5000], loss:0.1582\n",
      "steps [1281/5000], loss:0.1437\n",
      "steps [1282/5000], loss:0.1510\n",
      "steps [1283/5000], loss:0.1370\n",
      "steps [1284/5000], loss:0.1329\n",
      "steps [1285/5000], loss:0.1401\n",
      "steps [1286/5000], loss:0.1520\n",
      "steps [1287/5000], loss:0.1542\n",
      "steps [1288/5000], loss:0.1549\n",
      "steps [1289/5000], loss:0.1200\n",
      "steps [1290/5000], loss:0.1432\n",
      "steps [1291/5000], loss:0.1528\n",
      "steps [1292/5000], loss:0.1442\n",
      "steps [1293/5000], loss:0.1326\n",
      "steps [1294/5000], loss:0.1281\n",
      "steps [1295/5000], loss:0.1359\n",
      "steps [1296/5000], loss:0.1554\n",
      "steps [1297/5000], loss:0.1335\n",
      "steps [1298/5000], loss:0.1538\n",
      "steps [1299/5000], loss:0.1205\n",
      "steps [1300/5000], loss:0.1449\n",
      "steps [1301/5000], loss:0.1491\n",
      "steps [1302/5000], loss:0.1431\n",
      "steps [1303/5000], loss:0.1452\n",
      "steps [1304/5000], loss:0.1573\n",
      "steps [1305/5000], loss:0.1225\n",
      "steps [1306/5000], loss:0.1309\n",
      "steps [1307/5000], loss:0.1465\n",
      "steps [1308/5000], loss:0.1399\n",
      "steps [1309/5000], loss:0.1514\n",
      "steps [1310/5000], loss:0.1259\n",
      "steps [1311/5000], loss:0.1540\n",
      "steps [1312/5000], loss:0.1345\n",
      "steps [1313/5000], loss:0.1846\n",
      "steps [1314/5000], loss:0.1589\n",
      "steps [1315/5000], loss:0.1391\n",
      "steps [1316/5000], loss:0.1618\n",
      "steps [1317/5000], loss:0.1445\n",
      "steps [1318/5000], loss:0.1732\n",
      "steps [1319/5000], loss:0.1421\n",
      "steps [1320/5000], loss:0.1442\n",
      "steps [1321/5000], loss:0.1291\n",
      "steps [1322/5000], loss:0.1410\n",
      "steps [1323/5000], loss:0.1663\n",
      "steps [1324/5000], loss:0.1455\n",
      "steps [1325/5000], loss:0.1609\n",
      "steps [1326/5000], loss:0.1714\n",
      "steps [1327/5000], loss:0.1563\n",
      "steps [1328/5000], loss:0.1563\n",
      "steps [1329/5000], loss:0.1589\n",
      "steps [1330/5000], loss:0.1666\n",
      "steps [1331/5000], loss:0.1459\n",
      "steps [1332/5000], loss:0.1403\n",
      "steps [1333/5000], loss:0.1392\n",
      "steps [1334/5000], loss:0.1386\n",
      "steps [1335/5000], loss:0.1395\n",
      "steps [1336/5000], loss:0.1552\n",
      "steps [1337/5000], loss:0.1753\n",
      "steps [1338/5000], loss:0.1458\n",
      "steps [1339/5000], loss:0.1467\n",
      "steps [1340/5000], loss:0.1533\n",
      "steps [1341/5000], loss:0.1467\n",
      "steps [1342/5000], loss:0.1327\n",
      "steps [1343/5000], loss:0.1268\n",
      "steps [1344/5000], loss:0.1524\n",
      "steps [1345/5000], loss:0.1494\n",
      "steps [1346/5000], loss:0.1349\n",
      "steps [1347/5000], loss:0.1429\n",
      "steps [1348/5000], loss:0.1657\n",
      "steps [1349/5000], loss:0.1643\n",
      "steps [1350/5000], loss:0.1475\n",
      "steps [1351/5000], loss:0.1596\n",
      "steps [1352/5000], loss:0.1493\n",
      "steps [1353/5000], loss:0.1803\n",
      "steps [1354/5000], loss:0.1386\n",
      "steps [1355/5000], loss:0.1770\n",
      "steps [1356/5000], loss:0.1344\n",
      "steps [1357/5000], loss:0.1587\n",
      "steps [1358/5000], loss:0.1607\n",
      "steps [1359/5000], loss:0.1419\n",
      "steps [1360/5000], loss:0.1353\n",
      "steps [1361/5000], loss:0.1488\n",
      "steps [1362/5000], loss:0.1355\n",
      "steps [1363/5000], loss:0.1313\n",
      "steps [1364/5000], loss:0.1434\n",
      "steps [1365/5000], loss:0.1333\n",
      "steps [1366/5000], loss:0.1563\n",
      "steps [1367/5000], loss:0.1471\n",
      "steps [1368/5000], loss:0.1586\n",
      "steps [1369/5000], loss:0.1455\n",
      "steps [1370/5000], loss:0.1380\n",
      "steps [1371/5000], loss:0.1622\n",
      "steps [1372/5000], loss:0.1277\n",
      "steps [1373/5000], loss:0.1326\n",
      "steps [1374/5000], loss:0.1541\n",
      "steps [1375/5000], loss:0.1632\n",
      "steps [1376/5000], loss:0.1478\n",
      "steps [1377/5000], loss:0.1366\n",
      "steps [1378/5000], loss:0.1396\n",
      "steps [1379/5000], loss:0.1392\n",
      "steps [1380/5000], loss:0.1695\n",
      "steps [1381/5000], loss:0.1481\n",
      "steps [1382/5000], loss:0.1457\n",
      "steps [1383/5000], loss:0.1647\n",
      "steps [1384/5000], loss:0.1419\n",
      "steps [1385/5000], loss:0.1533\n",
      "steps [1386/5000], loss:0.1501\n",
      "steps [1387/5000], loss:0.1581\n",
      "steps [1388/5000], loss:0.1348\n",
      "steps [1389/5000], loss:0.1530\n",
      "steps [1390/5000], loss:0.1469\n",
      "steps [1391/5000], loss:0.1453\n",
      "steps [1392/5000], loss:0.1481\n",
      "steps [1393/5000], loss:0.1423\n",
      "steps [1394/5000], loss:0.1529\n",
      "steps [1395/5000], loss:0.1505\n",
      "steps [1396/5000], loss:0.1268\n",
      "steps [1397/5000], loss:0.1345\n",
      "steps [1398/5000], loss:0.1531\n",
      "steps [1399/5000], loss:0.1502\n",
      "steps [1400/5000], loss:0.1650\n",
      "steps [1401/5000], loss:0.1649\n",
      "steps [1402/5000], loss:0.1331\n",
      "steps [1403/5000], loss:0.1311\n",
      "steps [1404/5000], loss:0.1488\n",
      "steps [1405/5000], loss:0.1493\n",
      "steps [1406/5000], loss:0.1523\n",
      "steps [1407/5000], loss:0.1685\n",
      "steps [1408/5000], loss:0.1390\n",
      "steps [1409/5000], loss:0.1412\n",
      "steps [1410/5000], loss:0.1362\n",
      "steps [1411/5000], loss:0.1627\n",
      "steps [1412/5000], loss:0.1596\n",
      "steps [1413/5000], loss:0.1429\n",
      "steps [1414/5000], loss:0.1555\n",
      "steps [1415/5000], loss:0.1372\n",
      "steps [1416/5000], loss:0.1431\n",
      "steps [1417/5000], loss:0.1610\n",
      "steps [1418/5000], loss:0.1608\n",
      "steps [1419/5000], loss:0.1403\n",
      "steps [1420/5000], loss:0.1540\n",
      "steps [1421/5000], loss:0.1290\n",
      "steps [1422/5000], loss:0.1710\n",
      "steps [1423/5000], loss:0.1390\n",
      "steps [1424/5000], loss:0.1326\n",
      "steps [1425/5000], loss:0.1422\n",
      "steps [1426/5000], loss:0.1411\n",
      "steps [1427/5000], loss:0.1495\n",
      "steps [1428/5000], loss:0.1537\n",
      "steps [1429/5000], loss:0.1454\n",
      "steps [1430/5000], loss:0.1455\n",
      "steps [1431/5000], loss:0.1363\n",
      "steps [1432/5000], loss:0.1348\n",
      "steps [1433/5000], loss:0.1358\n",
      "steps [1434/5000], loss:0.1320\n",
      "steps [1435/5000], loss:0.1540\n",
      "steps [1436/5000], loss:0.1603\n",
      "steps [1437/5000], loss:0.1474\n",
      "steps [1438/5000], loss:0.1248\n",
      "steps [1439/5000], loss:0.1647\n",
      "steps [1440/5000], loss:0.1352\n",
      "steps [1441/5000], loss:0.1498\n",
      "steps [1442/5000], loss:0.1506\n",
      "steps [1443/5000], loss:0.1249\n",
      "steps [1444/5000], loss:0.1489\n",
      "steps [1445/5000], loss:0.1474\n",
      "steps [1446/5000], loss:0.1549\n",
      "steps [1447/5000], loss:0.1393\n",
      "steps [1448/5000], loss:0.1716\n",
      "steps [1449/5000], loss:0.1330\n",
      "steps [1450/5000], loss:0.1464\n",
      "steps [1451/5000], loss:0.1407\n",
      "steps [1452/5000], loss:0.1705\n",
      "steps [1453/5000], loss:0.1381\n",
      "steps [1454/5000], loss:0.1534\n",
      "steps [1455/5000], loss:0.1409\n",
      "steps [1456/5000], loss:0.1604\n",
      "steps [1457/5000], loss:0.1409\n",
      "steps [1458/5000], loss:0.1464\n",
      "steps [1459/5000], loss:0.1507\n",
      "steps [1460/5000], loss:0.1387\n",
      "steps [1461/5000], loss:0.1571\n",
      "steps [1462/5000], loss:0.1366\n",
      "steps [1463/5000], loss:0.1359\n",
      "steps [1464/5000], loss:0.1399\n",
      "steps [1465/5000], loss:0.1698\n",
      "steps [1466/5000], loss:0.1329\n",
      "steps [1467/5000], loss:0.1584\n",
      "steps [1468/5000], loss:0.1434\n",
      "steps [1469/5000], loss:0.1327\n",
      "steps [1470/5000], loss:0.1370\n",
      "steps [1471/5000], loss:0.1386\n",
      "steps [1472/5000], loss:0.1403\n",
      "steps [1473/5000], loss:0.1475\n",
      "steps [1474/5000], loss:0.1716\n",
      "steps [1475/5000], loss:0.1258\n",
      "steps [1476/5000], loss:0.1361\n",
      "steps [1477/5000], loss:0.1482\n",
      "steps [1478/5000], loss:0.1350\n",
      "steps [1479/5000], loss:0.1559\n",
      "steps [1480/5000], loss:0.1626\n",
      "steps [1481/5000], loss:0.1308\n",
      "steps [1482/5000], loss:0.1524\n",
      "steps [1483/5000], loss:0.1400\n",
      "steps [1484/5000], loss:0.1438\n",
      "steps [1485/5000], loss:0.1451\n",
      "steps [1486/5000], loss:0.1405\n",
      "steps [1487/5000], loss:0.1560\n",
      "steps [1488/5000], loss:0.1402\n",
      "steps [1489/5000], loss:0.1445\n",
      "steps [1490/5000], loss:0.1410\n",
      "steps [1491/5000], loss:0.1584\n",
      "steps [1492/5000], loss:0.1329\n",
      "steps [1493/5000], loss:0.1487\n",
      "steps [1494/5000], loss:0.1706\n",
      "steps [1495/5000], loss:0.1476\n",
      "steps [1496/5000], loss:0.1413\n",
      "steps [1497/5000], loss:0.1465\n",
      "steps [1498/5000], loss:0.1355\n",
      "steps [1499/5000], loss:0.1412\n",
      "steps [1500/5000], loss:0.1319\n",
      "steps [1501/5000], loss:0.1721\n",
      "steps [1502/5000], loss:0.1292\n",
      "steps [1503/5000], loss:0.1328\n",
      "steps [1504/5000], loss:0.1441\n",
      "steps [1505/5000], loss:0.1498\n",
      "steps [1506/5000], loss:0.1772\n",
      "steps [1507/5000], loss:0.1408\n",
      "steps [1508/5000], loss:0.1377\n",
      "steps [1509/5000], loss:0.1383\n",
      "steps [1510/5000], loss:0.1618\n",
      "steps [1511/5000], loss:0.1485\n",
      "steps [1512/5000], loss:0.1389\n",
      "steps [1513/5000], loss:0.1389\n",
      "steps [1514/5000], loss:0.1378\n",
      "steps [1515/5000], loss:0.1388\n",
      "steps [1516/5000], loss:0.1442\n",
      "steps [1517/5000], loss:0.1284\n",
      "steps [1518/5000], loss:0.1451\n",
      "steps [1519/5000], loss:0.1288\n",
      "steps [1520/5000], loss:0.1342\n",
      "steps [1521/5000], loss:0.1256\n",
      "steps [1522/5000], loss:0.1282\n",
      "steps [1523/5000], loss:0.1802\n",
      "steps [1524/5000], loss:0.1423\n",
      "steps [1525/5000], loss:0.1291\n",
      "steps [1526/5000], loss:0.1442\n",
      "steps [1527/5000], loss:0.1519\n",
      "steps [1528/5000], loss:0.1526\n",
      "steps [1529/5000], loss:0.1484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [1530/5000], loss:0.1566\n",
      "steps [1531/5000], loss:0.1267\n",
      "steps [1532/5000], loss:0.1350\n",
      "steps [1533/5000], loss:0.1363\n",
      "steps [1534/5000], loss:0.1324\n",
      "steps [1535/5000], loss:0.1310\n",
      "steps [1536/5000], loss:0.1846\n",
      "steps [1537/5000], loss:0.1612\n",
      "steps [1538/5000], loss:0.1405\n",
      "steps [1539/5000], loss:0.1530\n",
      "steps [1540/5000], loss:0.1460\n",
      "steps [1541/5000], loss:0.1535\n",
      "steps [1542/5000], loss:0.1425\n",
      "steps [1543/5000], loss:0.1470\n",
      "steps [1544/5000], loss:0.1545\n",
      "steps [1545/5000], loss:0.1400\n",
      "steps [1546/5000], loss:0.1315\n",
      "steps [1547/5000], loss:0.1384\n",
      "steps [1548/5000], loss:0.1487\n",
      "steps [1549/5000], loss:0.1632\n",
      "steps [1550/5000], loss:0.1546\n",
      "steps [1551/5000], loss:0.1455\n",
      "steps [1552/5000], loss:0.1448\n",
      "steps [1553/5000], loss:0.1415\n",
      "steps [1554/5000], loss:0.1707\n",
      "steps [1555/5000], loss:0.1537\n",
      "steps [1556/5000], loss:0.1549\n",
      "steps [1557/5000], loss:0.1749\n",
      "steps [1558/5000], loss:0.1517\n",
      "steps [1559/5000], loss:0.1384\n",
      "steps [1560/5000], loss:0.1370\n",
      "steps [1561/5000], loss:0.1283\n",
      "steps [1562/5000], loss:0.1418\n",
      "steps [1563/5000], loss:0.1395\n",
      "steps [1564/5000], loss:0.1546\n",
      "steps [1565/5000], loss:0.1684\n",
      "steps [1566/5000], loss:0.1379\n",
      "steps [1567/5000], loss:0.1666\n",
      "steps [1568/5000], loss:0.1351\n",
      "steps [1569/5000], loss:0.1405\n",
      "steps [1570/5000], loss:0.1378\n",
      "steps [1571/5000], loss:0.1478\n",
      "steps [1572/5000], loss:0.1471\n",
      "steps [1573/5000], loss:0.1297\n",
      "steps [1574/5000], loss:0.1590\n",
      "steps [1575/5000], loss:0.1652\n",
      "steps [1576/5000], loss:0.1574\n",
      "steps [1577/5000], loss:0.1412\n",
      "steps [1578/5000], loss:0.1573\n",
      "steps [1579/5000], loss:0.1815\n",
      "steps [1580/5000], loss:0.1500\n",
      "steps [1581/5000], loss:0.1737\n",
      "steps [1582/5000], loss:0.1538\n",
      "steps [1583/5000], loss:0.1567\n",
      "steps [1584/5000], loss:0.1251\n",
      "steps [1585/5000], loss:0.1388\n",
      "steps [1586/5000], loss:0.1371\n",
      "steps [1587/5000], loss:0.1623\n",
      "steps [1588/5000], loss:0.1844\n",
      "steps [1589/5000], loss:0.1450\n",
      "steps [1590/5000], loss:0.1528\n",
      "steps [1591/5000], loss:0.1556\n",
      "steps [1592/5000], loss:0.1366\n",
      "steps [1593/5000], loss:0.1481\n",
      "steps [1594/5000], loss:0.1468\n",
      "steps [1595/5000], loss:0.1286\n",
      "steps [1596/5000], loss:0.1367\n",
      "steps [1597/5000], loss:0.1526\n",
      "steps [1598/5000], loss:0.1355\n",
      "steps [1599/5000], loss:0.1414\n",
      "steps [1600/5000], loss:0.1460\n",
      "steps [1601/5000], loss:0.1314\n",
      "steps [1602/5000], loss:0.1414\n",
      "steps [1603/5000], loss:0.1567\n",
      "steps [1604/5000], loss:0.1401\n",
      "steps [1605/5000], loss:0.1435\n",
      "steps [1606/5000], loss:0.1766\n",
      "steps [1607/5000], loss:0.1420\n",
      "steps [1608/5000], loss:0.1574\n",
      "steps [1609/5000], loss:0.1451\n",
      "steps [1610/5000], loss:0.1561\n",
      "steps [1611/5000], loss:0.1493\n",
      "steps [1612/5000], loss:0.1489\n",
      "steps [1613/5000], loss:0.1538\n",
      "steps [1614/5000], loss:0.1434\n",
      "steps [1615/5000], loss:0.1510\n",
      "steps [1616/5000], loss:0.1313\n",
      "steps [1617/5000], loss:0.1394\n",
      "steps [1618/5000], loss:0.1654\n",
      "steps [1619/5000], loss:0.1609\n",
      "steps [1620/5000], loss:0.1269\n",
      "steps [1621/5000], loss:0.1508\n",
      "steps [1622/5000], loss:0.1526\n",
      "steps [1623/5000], loss:0.1476\n",
      "steps [1624/5000], loss:0.1393\n",
      "steps [1625/5000], loss:0.1481\n",
      "steps [1626/5000], loss:0.1467\n",
      "steps [1627/5000], loss:0.1624\n",
      "steps [1628/5000], loss:0.1399\n",
      "steps [1629/5000], loss:0.1610\n",
      "steps [1630/5000], loss:0.1440\n",
      "steps [1631/5000], loss:0.1532\n",
      "steps [1632/5000], loss:0.1424\n",
      "steps [1633/5000], loss:0.1791\n",
      "steps [1634/5000], loss:0.1466\n",
      "steps [1635/5000], loss:0.1413\n",
      "steps [1636/5000], loss:0.1403\n",
      "steps [1637/5000], loss:0.1453\n",
      "steps [1638/5000], loss:0.1495\n",
      "steps [1639/5000], loss:0.1236\n",
      "steps [1640/5000], loss:0.1555\n",
      "steps [1641/5000], loss:0.1424\n",
      "steps [1642/5000], loss:0.1436\n",
      "steps [1643/5000], loss:0.1425\n",
      "steps [1644/5000], loss:0.1439\n",
      "steps [1645/5000], loss:0.1429\n",
      "steps [1646/5000], loss:0.1377\n",
      "steps [1647/5000], loss:0.1300\n",
      "steps [1648/5000], loss:0.1406\n",
      "steps [1649/5000], loss:0.1453\n",
      "steps [1650/5000], loss:0.1234\n",
      "steps [1651/5000], loss:0.1204\n",
      "steps [1652/5000], loss:0.1471\n",
      "steps [1653/5000], loss:0.1597\n",
      "steps [1654/5000], loss:0.1636\n",
      "steps [1655/5000], loss:0.1534\n",
      "steps [1656/5000], loss:0.1314\n",
      "steps [1657/5000], loss:0.1373\n",
      "steps [1658/5000], loss:0.1430\n",
      "steps [1659/5000], loss:0.1560\n",
      "steps [1660/5000], loss:0.1510\n",
      "steps [1661/5000], loss:0.1411\n",
      "steps [1662/5000], loss:0.1522\n",
      "steps [1663/5000], loss:0.1945\n",
      "steps [1664/5000], loss:0.1290\n",
      "steps [1665/5000], loss:0.1336\n",
      "steps [1666/5000], loss:0.1922\n",
      "steps [1667/5000], loss:0.1569\n",
      "steps [1668/5000], loss:0.1813\n",
      "steps [1669/5000], loss:0.1323\n",
      "steps [1670/5000], loss:0.1532\n",
      "steps [1671/5000], loss:0.1420\n",
      "steps [1672/5000], loss:0.1397\n",
      "steps [1673/5000], loss:0.1289\n",
      "steps [1674/5000], loss:0.1582\n",
      "steps [1675/5000], loss:0.1543\n",
      "steps [1676/5000], loss:0.1289\n",
      "steps [1677/5000], loss:0.1407\n",
      "steps [1678/5000], loss:0.1465\n",
      "steps [1679/5000], loss:0.1333\n",
      "steps [1680/5000], loss:0.1393\n",
      "steps [1681/5000], loss:0.1355\n",
      "steps [1682/5000], loss:0.1633\n",
      "steps [1683/5000], loss:0.1344\n",
      "steps [1684/5000], loss:0.1469\n",
      "steps [1685/5000], loss:0.1411\n",
      "steps [1686/5000], loss:0.1571\n",
      "steps [1687/5000], loss:0.1353\n",
      "steps [1688/5000], loss:0.1411\n",
      "steps [1689/5000], loss:0.1495\n",
      "steps [1690/5000], loss:0.1423\n",
      "steps [1691/5000], loss:0.1489\n",
      "steps [1692/5000], loss:0.1413\n",
      "steps [1693/5000], loss:0.1405\n",
      "steps [1694/5000], loss:0.1333\n",
      "steps [1695/5000], loss:0.1355\n",
      "steps [1696/5000], loss:0.1317\n",
      "steps [1697/5000], loss:0.1320\n",
      "steps [1698/5000], loss:0.1462\n",
      "steps [1699/5000], loss:0.1546\n",
      "steps [1700/5000], loss:0.1563\n",
      "steps [1701/5000], loss:0.1594\n",
      "steps [1702/5000], loss:0.1671\n",
      "steps [1703/5000], loss:0.1476\n",
      "steps [1704/5000], loss:0.1399\n",
      "steps [1705/5000], loss:0.1426\n",
      "steps [1706/5000], loss:0.1365\n",
      "steps [1707/5000], loss:0.1432\n",
      "steps [1708/5000], loss:0.1477\n",
      "steps [1709/5000], loss:0.1403\n",
      "steps [1710/5000], loss:0.1428\n",
      "steps [1711/5000], loss:0.1420\n",
      "steps [1712/5000], loss:0.1210\n",
      "steps [1713/5000], loss:0.1346\n",
      "steps [1714/5000], loss:0.1423\n",
      "steps [1715/5000], loss:0.1371\n",
      "steps [1716/5000], loss:0.1524\n",
      "steps [1717/5000], loss:0.1468\n",
      "steps [1718/5000], loss:0.1489\n",
      "steps [1719/5000], loss:0.1520\n",
      "steps [1720/5000], loss:0.1588\n",
      "steps [1721/5000], loss:0.1327\n",
      "steps [1722/5000], loss:0.1452\n",
      "steps [1723/5000], loss:0.1554\n",
      "steps [1724/5000], loss:0.1551\n",
      "steps [1725/5000], loss:0.1434\n",
      "steps [1726/5000], loss:0.1525\n",
      "steps [1727/5000], loss:0.1437\n",
      "steps [1728/5000], loss:0.1562\n",
      "steps [1729/5000], loss:0.1359\n",
      "steps [1730/5000], loss:0.1498\n",
      "steps [1731/5000], loss:0.1545\n",
      "steps [1732/5000], loss:0.1537\n",
      "steps [1733/5000], loss:0.1378\n",
      "steps [1734/5000], loss:0.1353\n",
      "steps [1735/5000], loss:0.1433\n",
      "steps [1736/5000], loss:0.1913\n",
      "steps [1737/5000], loss:0.1399\n",
      "steps [1738/5000], loss:0.1267\n",
      "steps [1739/5000], loss:0.1497\n",
      "steps [1740/5000], loss:0.1576\n",
      "steps [1741/5000], loss:0.1389\n",
      "steps [1742/5000], loss:0.1369\n",
      "steps [1743/5000], loss:0.1635\n",
      "steps [1744/5000], loss:0.1275\n",
      "steps [1745/5000], loss:0.1499\n",
      "steps [1746/5000], loss:0.1427\n",
      "steps [1747/5000], loss:0.1534\n",
      "steps [1748/5000], loss:0.1382\n",
      "steps [1749/5000], loss:0.1233\n",
      "steps [1750/5000], loss:0.1411\n",
      "steps [1751/5000], loss:0.1317\n",
      "steps [1752/5000], loss:0.1293\n",
      "steps [1753/5000], loss:0.1458\n",
      "steps [1754/5000], loss:0.1434\n",
      "steps [1755/5000], loss:0.1383\n",
      "steps [1756/5000], loss:0.1362\n",
      "steps [1757/5000], loss:0.1353\n",
      "steps [1758/5000], loss:0.1439\n",
      "steps [1759/5000], loss:0.1201\n",
      "steps [1760/5000], loss:0.1527\n",
      "steps [1761/5000], loss:0.1423\n",
      "steps [1762/5000], loss:0.1422\n",
      "steps [1763/5000], loss:0.1539\n",
      "steps [1764/5000], loss:0.1368\n",
      "steps [1765/5000], loss:0.1437\n",
      "steps [1766/5000], loss:0.1435\n",
      "steps [1767/5000], loss:0.1637\n",
      "steps [1768/5000], loss:0.1311\n",
      "steps [1769/5000], loss:0.1441\n",
      "steps [1770/5000], loss:0.1677\n",
      "steps [1771/5000], loss:0.1279\n",
      "steps [1772/5000], loss:0.1492\n",
      "steps [1773/5000], loss:0.1390\n",
      "steps [1774/5000], loss:0.1463\n",
      "steps [1775/5000], loss:0.1413\n",
      "steps [1776/5000], loss:0.1349\n",
      "steps [1777/5000], loss:0.1490\n",
      "steps [1778/5000], loss:0.1462\n",
      "steps [1779/5000], loss:0.1519\n",
      "steps [1780/5000], loss:0.1545\n",
      "steps [1781/5000], loss:0.1501\n",
      "steps [1782/5000], loss:0.1348\n",
      "steps [1783/5000], loss:0.1442\n",
      "steps [1784/5000], loss:0.1423\n",
      "steps [1785/5000], loss:0.1369\n",
      "steps [1786/5000], loss:0.1623\n",
      "steps [1787/5000], loss:0.1432\n",
      "steps [1788/5000], loss:0.1572\n",
      "steps [1789/5000], loss:0.1480\n",
      "steps [1790/5000], loss:0.1475\n",
      "steps [1791/5000], loss:0.1480\n",
      "steps [1792/5000], loss:0.1384\n",
      "steps [1793/5000], loss:0.1351\n",
      "steps [1794/5000], loss:0.1415\n",
      "steps [1795/5000], loss:0.1352\n",
      "steps [1796/5000], loss:0.1318\n",
      "steps [1797/5000], loss:0.1626\n",
      "steps [1798/5000], loss:0.1340\n",
      "steps [1799/5000], loss:0.1288\n",
      "steps [1800/5000], loss:0.1269\n",
      "steps [1801/5000], loss:0.1513\n",
      "steps [1802/5000], loss:0.1528\n",
      "steps [1803/5000], loss:0.1399\n",
      "steps [1804/5000], loss:0.1378\n",
      "steps [1805/5000], loss:0.1482\n",
      "steps [1806/5000], loss:0.1569\n",
      "steps [1807/5000], loss:0.1468\n",
      "steps [1808/5000], loss:0.1124\n",
      "steps [1809/5000], loss:0.1431\n",
      "steps [1810/5000], loss:0.1380\n",
      "steps [1811/5000], loss:0.1660\n",
      "steps [1812/5000], loss:0.1528\n",
      "steps [1813/5000], loss:0.1638\n",
      "steps [1814/5000], loss:0.1606\n",
      "steps [1815/5000], loss:0.1422\n",
      "steps [1816/5000], loss:0.1573\n",
      "steps [1817/5000], loss:0.1356\n",
      "steps [1818/5000], loss:0.1436\n",
      "steps [1819/5000], loss:0.1528\n",
      "steps [1820/5000], loss:0.1635\n",
      "steps [1821/5000], loss:0.1372\n",
      "steps [1822/5000], loss:0.1448\n",
      "steps [1823/5000], loss:0.1512\n",
      "steps [1824/5000], loss:0.1739\n",
      "steps [1825/5000], loss:0.1400\n",
      "steps [1826/5000], loss:0.1395\n",
      "steps [1827/5000], loss:0.1539\n",
      "steps [1828/5000], loss:0.1660\n",
      "steps [1829/5000], loss:0.1495\n",
      "steps [1830/5000], loss:0.1554\n",
      "steps [1831/5000], loss:0.1383\n",
      "steps [1832/5000], loss:0.1504\n",
      "steps [1833/5000], loss:0.1679\n",
      "steps [1834/5000], loss:0.1632\n",
      "steps [1835/5000], loss:0.1300\n",
      "steps [1836/5000], loss:0.1728\n",
      "steps [1837/5000], loss:0.1663\n",
      "steps [1838/5000], loss:0.1541\n",
      "steps [1839/5000], loss:0.1365\n",
      "steps [1840/5000], loss:0.1560\n",
      "steps [1841/5000], loss:0.1376\n",
      "steps [1842/5000], loss:0.1634\n",
      "steps [1843/5000], loss:0.1313\n",
      "steps [1844/5000], loss:0.1428\n",
      "steps [1845/5000], loss:0.1576\n",
      "steps [1846/5000], loss:0.1461\n",
      "steps [1847/5000], loss:0.1573\n",
      "steps [1848/5000], loss:0.1760\n",
      "steps [1849/5000], loss:0.1371\n",
      "steps [1850/5000], loss:0.1545\n",
      "steps [1851/5000], loss:0.1559\n",
      "steps [1852/5000], loss:0.1385\n",
      "steps [1853/5000], loss:0.1437\n",
      "steps [1854/5000], loss:0.1316\n",
      "steps [1855/5000], loss:0.1495\n",
      "steps [1856/5000], loss:0.1225\n",
      "steps [1857/5000], loss:0.1270\n",
      "steps [1858/5000], loss:0.1428\n",
      "steps [1859/5000], loss:0.1431\n",
      "steps [1860/5000], loss:0.1395\n",
      "steps [1861/5000], loss:0.1353\n",
      "steps [1862/5000], loss:0.1352\n",
      "steps [1863/5000], loss:0.1492\n",
      "steps [1864/5000], loss:0.1571\n",
      "steps [1865/5000], loss:0.1453\n",
      "steps [1866/5000], loss:0.1533\n",
      "steps [1867/5000], loss:0.1388\n",
      "steps [1868/5000], loss:0.1500\n",
      "steps [1869/5000], loss:0.1530\n",
      "steps [1870/5000], loss:0.1646\n",
      "steps [1871/5000], loss:0.1382\n",
      "steps [1872/5000], loss:0.1559\n",
      "steps [1873/5000], loss:0.1395\n",
      "steps [1874/5000], loss:0.1558\n",
      "steps [1875/5000], loss:0.1562\n",
      "steps [1876/5000], loss:0.1560\n",
      "steps [1877/5000], loss:0.1344\n",
      "steps [1878/5000], loss:0.1403\n",
      "steps [1879/5000], loss:0.1414\n",
      "steps [1880/5000], loss:0.1344\n",
      "steps [1881/5000], loss:0.1515\n",
      "steps [1882/5000], loss:0.1356\n",
      "steps [1883/5000], loss:0.1466\n",
      "steps [1884/5000], loss:0.1482\n",
      "steps [1885/5000], loss:0.1382\n",
      "steps [1886/5000], loss:0.1286\n",
      "steps [1887/5000], loss:0.1454\n",
      "steps [1888/5000], loss:0.1372\n",
      "steps [1889/5000], loss:0.1434\n",
      "steps [1890/5000], loss:0.1402\n",
      "steps [1891/5000], loss:0.1311\n",
      "steps [1892/5000], loss:0.1331\n",
      "steps [1893/5000], loss:0.1446\n",
      "steps [1894/5000], loss:0.1500\n",
      "steps [1895/5000], loss:0.1543\n",
      "steps [1896/5000], loss:0.1580\n",
      "steps [1897/5000], loss:0.1487\n",
      "steps [1898/5000], loss:0.1426\n",
      "steps [1899/5000], loss:0.1378\n",
      "steps [1900/5000], loss:0.1354\n",
      "steps [1901/5000], loss:0.1280\n",
      "steps [1902/5000], loss:0.1395\n",
      "steps [1903/5000], loss:0.1352\n",
      "steps [1904/5000], loss:0.1444\n",
      "steps [1905/5000], loss:0.1409\n",
      "steps [1906/5000], loss:0.1401\n",
      "steps [1907/5000], loss:0.1495\n",
      "steps [1908/5000], loss:0.1376\n",
      "steps [1909/5000], loss:0.1523\n",
      "steps [1910/5000], loss:0.1379\n",
      "steps [1911/5000], loss:0.1447\n",
      "steps [1912/5000], loss:0.1594\n",
      "steps [1913/5000], loss:0.1373\n",
      "steps [1914/5000], loss:0.1728\n",
      "steps [1915/5000], loss:0.1425\n",
      "steps [1916/5000], loss:0.1187\n",
      "steps [1917/5000], loss:0.1358\n",
      "steps [1918/5000], loss:0.1387\n",
      "steps [1919/5000], loss:0.1358\n",
      "steps [1920/5000], loss:0.1462\n",
      "steps [1921/5000], loss:0.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [1922/5000], loss:0.1372\n",
      "steps [1923/5000], loss:0.1309\n",
      "steps [1924/5000], loss:0.1521\n",
      "steps [1925/5000], loss:0.1460\n",
      "steps [1926/5000], loss:0.1662\n",
      "steps [1927/5000], loss:0.1427\n",
      "steps [1928/5000], loss:0.1451\n",
      "steps [1929/5000], loss:0.1341\n",
      "steps [1930/5000], loss:0.1528\n",
      "steps [1931/5000], loss:0.1436\n",
      "steps [1932/5000], loss:0.1328\n",
      "steps [1933/5000], loss:0.1280\n",
      "steps [1934/5000], loss:0.1333\n",
      "steps [1935/5000], loss:0.1683\n",
      "steps [1936/5000], loss:0.1283\n",
      "steps [1937/5000], loss:0.1515\n",
      "steps [1938/5000], loss:0.1360\n",
      "steps [1939/5000], loss:0.1346\n",
      "steps [1940/5000], loss:0.1528\n",
      "steps [1941/5000], loss:0.1346\n",
      "steps [1942/5000], loss:0.1489\n",
      "steps [1943/5000], loss:0.1371\n",
      "steps [1944/5000], loss:0.1408\n",
      "steps [1945/5000], loss:0.1373\n",
      "steps [1946/5000], loss:0.1754\n",
      "steps [1947/5000], loss:0.1365\n",
      "steps [1948/5000], loss:0.1440\n",
      "steps [1949/5000], loss:0.1281\n",
      "steps [1950/5000], loss:0.1420\n",
      "steps [1951/5000], loss:0.1449\n",
      "steps [1952/5000], loss:0.1265\n",
      "steps [1953/5000], loss:0.1557\n",
      "steps [1954/5000], loss:0.1477\n",
      "steps [1955/5000], loss:0.1435\n",
      "steps [1956/5000], loss:0.1387\n",
      "steps [1957/5000], loss:0.1325\n",
      "steps [1958/5000], loss:0.1432\n",
      "steps [1959/5000], loss:0.1324\n",
      "steps [1960/5000], loss:0.1351\n",
      "steps [1961/5000], loss:0.1329\n",
      "steps [1962/5000], loss:0.1323\n",
      "steps [1963/5000], loss:0.1400\n",
      "steps [1964/5000], loss:0.1416\n",
      "steps [1965/5000], loss:0.1577\n",
      "steps [1966/5000], loss:0.1441\n",
      "steps [1967/5000], loss:0.1384\n",
      "steps [1968/5000], loss:0.1426\n",
      "steps [1969/5000], loss:0.1560\n",
      "steps [1970/5000], loss:0.1518\n",
      "steps [1971/5000], loss:0.1561\n",
      "steps [1972/5000], loss:0.1409\n",
      "steps [1973/5000], loss:0.1332\n",
      "steps [1974/5000], loss:0.1560\n",
      "steps [1975/5000], loss:0.1552\n",
      "steps [1976/5000], loss:0.1416\n",
      "steps [1977/5000], loss:0.1258\n",
      "steps [1978/5000], loss:0.1519\n",
      "steps [1979/5000], loss:0.1305\n",
      "steps [1980/5000], loss:0.1781\n",
      "steps [1981/5000], loss:0.1278\n",
      "steps [1982/5000], loss:0.1482\n",
      "steps [1983/5000], loss:0.1467\n",
      "steps [1984/5000], loss:0.1365\n",
      "steps [1985/5000], loss:0.1503\n",
      "steps [1986/5000], loss:0.1593\n",
      "steps [1987/5000], loss:0.1486\n",
      "steps [1988/5000], loss:0.1384\n",
      "steps [1989/5000], loss:0.1511\n",
      "steps [1990/5000], loss:0.1403\n",
      "steps [1991/5000], loss:0.1436\n",
      "steps [1992/5000], loss:0.1392\n",
      "steps [1993/5000], loss:0.1434\n",
      "steps [1994/5000], loss:0.1628\n",
      "steps [1995/5000], loss:0.1390\n",
      "steps [1996/5000], loss:0.1502\n",
      "steps [1997/5000], loss:0.1346\n",
      "steps [1998/5000], loss:0.1261\n",
      "steps [1999/5000], loss:0.1529\n",
      "steps [2000/5000], loss:0.1529\n",
      "steps [2001/5000], loss:0.1454\n",
      "steps [2002/5000], loss:0.1556\n",
      "steps [2003/5000], loss:0.1612\n",
      "steps [2004/5000], loss:0.1408\n",
      "steps [2005/5000], loss:0.1316\n",
      "steps [2006/5000], loss:0.1648\n",
      "steps [2007/5000], loss:0.1497\n",
      "steps [2008/5000], loss:0.1591\n",
      "steps [2009/5000], loss:0.1490\n",
      "steps [2010/5000], loss:0.1348\n",
      "steps [2011/5000], loss:0.1510\n",
      "steps [2012/5000], loss:0.1206\n",
      "steps [2013/5000], loss:0.1334\n",
      "steps [2014/5000], loss:0.1414\n",
      "steps [2015/5000], loss:0.1465\n",
      "steps [2016/5000], loss:0.1306\n",
      "steps [2017/5000], loss:0.1397\n",
      "steps [2018/5000], loss:0.1358\n",
      "steps [2019/5000], loss:0.1541\n",
      "steps [2020/5000], loss:0.1430\n",
      "steps [2021/5000], loss:0.1401\n",
      "steps [2022/5000], loss:0.1500\n",
      "steps [2023/5000], loss:0.1647\n",
      "steps [2024/5000], loss:0.1559\n",
      "steps [2025/5000], loss:0.1839\n",
      "steps [2026/5000], loss:0.1343\n",
      "steps [2027/5000], loss:0.1450\n",
      "steps [2028/5000], loss:0.1326\n",
      "steps [2029/5000], loss:0.1285\n",
      "steps [2030/5000], loss:0.1546\n",
      "steps [2031/5000], loss:0.1469\n",
      "steps [2032/5000], loss:0.1548\n",
      "steps [2033/5000], loss:0.1371\n",
      "steps [2034/5000], loss:0.1723\n",
      "steps [2035/5000], loss:0.1543\n",
      "steps [2036/5000], loss:0.1386\n",
      "steps [2037/5000], loss:0.1412\n",
      "steps [2038/5000], loss:0.1464\n",
      "steps [2039/5000], loss:0.1435\n",
      "steps [2040/5000], loss:0.1549\n",
      "steps [2041/5000], loss:0.1422\n",
      "steps [2042/5000], loss:0.1398\n",
      "steps [2043/5000], loss:0.1382\n",
      "steps [2044/5000], loss:0.1482\n",
      "steps [2045/5000], loss:0.1296\n",
      "steps [2046/5000], loss:0.1683\n",
      "steps [2047/5000], loss:0.1670\n",
      "steps [2048/5000], loss:0.1248\n",
      "steps [2049/5000], loss:0.1483\n",
      "steps [2050/5000], loss:0.1473\n",
      "steps [2051/5000], loss:0.1273\n",
      "steps [2052/5000], loss:0.1394\n",
      "steps [2053/5000], loss:0.1502\n",
      "steps [2054/5000], loss:0.1422\n",
      "steps [2055/5000], loss:0.1485\n",
      "steps [2056/5000], loss:0.1471\n",
      "steps [2057/5000], loss:0.1889\n",
      "steps [2058/5000], loss:0.1365\n",
      "steps [2059/5000], loss:0.1366\n",
      "steps [2060/5000], loss:0.1542\n",
      "steps [2061/5000], loss:0.1423\n",
      "steps [2062/5000], loss:0.1440\n",
      "steps [2063/5000], loss:0.1324\n",
      "steps [2064/5000], loss:0.1518\n",
      "steps [2065/5000], loss:0.1540\n",
      "steps [2066/5000], loss:0.1531\n",
      "steps [2067/5000], loss:0.1362\n",
      "steps [2068/5000], loss:0.1356\n",
      "steps [2069/5000], loss:0.1484\n",
      "steps [2070/5000], loss:0.1420\n",
      "steps [2071/5000], loss:0.1320\n",
      "steps [2072/5000], loss:0.1384\n",
      "steps [2073/5000], loss:0.1484\n",
      "steps [2074/5000], loss:0.1234\n",
      "steps [2075/5000], loss:0.1360\n",
      "steps [2076/5000], loss:0.1455\n",
      "steps [2077/5000], loss:0.1433\n",
      "steps [2078/5000], loss:0.1496\n",
      "steps [2079/5000], loss:0.1373\n",
      "steps [2080/5000], loss:0.1483\n",
      "steps [2081/5000], loss:0.1478\n",
      "steps [2082/5000], loss:0.1886\n",
      "steps [2083/5000], loss:0.1330\n",
      "steps [2084/5000], loss:0.1368\n",
      "steps [2085/5000], loss:0.1540\n",
      "steps [2086/5000], loss:0.1394\n",
      "steps [2087/5000], loss:0.1343\n",
      "steps [2088/5000], loss:0.1479\n",
      "steps [2089/5000], loss:0.1556\n",
      "steps [2090/5000], loss:0.1559\n",
      "steps [2091/5000], loss:0.1439\n",
      "steps [2092/5000], loss:0.1486\n",
      "steps [2093/5000], loss:0.1384\n",
      "steps [2094/5000], loss:0.1691\n",
      "steps [2095/5000], loss:0.1442\n",
      "steps [2096/5000], loss:0.1324\n",
      "steps [2097/5000], loss:0.1382\n",
      "steps [2098/5000], loss:0.1351\n",
      "steps [2099/5000], loss:0.1478\n",
      "steps [2100/5000], loss:0.1364\n",
      "steps [2101/5000], loss:0.1332\n",
      "steps [2102/5000], loss:0.1352\n",
      "steps [2103/5000], loss:0.1513\n",
      "steps [2104/5000], loss:0.1470\n",
      "steps [2105/5000], loss:0.1758\n",
      "steps [2106/5000], loss:0.1330\n",
      "steps [2107/5000], loss:0.1267\n",
      "steps [2108/5000], loss:0.1487\n",
      "steps [2109/5000], loss:0.1542\n",
      "steps [2110/5000], loss:0.1353\n",
      "steps [2111/5000], loss:0.1553\n",
      "steps [2112/5000], loss:0.1544\n",
      "steps [2113/5000], loss:0.1434\n",
      "steps [2114/5000], loss:0.1376\n",
      "steps [2115/5000], loss:0.1256\n",
      "steps [2116/5000], loss:0.1433\n",
      "steps [2117/5000], loss:0.1428\n",
      "steps [2118/5000], loss:0.1448\n",
      "steps [2119/5000], loss:0.1376\n",
      "steps [2120/5000], loss:0.1405\n",
      "steps [2121/5000], loss:0.1653\n",
      "steps [2122/5000], loss:0.1378\n",
      "steps [2123/5000], loss:0.1206\n",
      "steps [2124/5000], loss:0.1398\n",
      "steps [2125/5000], loss:0.1807\n",
      "steps [2126/5000], loss:0.1448\n",
      "steps [2127/5000], loss:0.1405\n",
      "steps [2128/5000], loss:0.1388\n",
      "steps [2129/5000], loss:0.1537\n",
      "steps [2130/5000], loss:0.1562\n",
      "steps [2131/5000], loss:0.1389\n",
      "steps [2132/5000], loss:0.1492\n",
      "steps [2133/5000], loss:0.1407\n",
      "steps [2134/5000], loss:0.1462\n",
      "steps [2135/5000], loss:0.1340\n",
      "steps [2136/5000], loss:0.1496\n",
      "steps [2137/5000], loss:0.1373\n",
      "steps [2138/5000], loss:0.1485\n",
      "steps [2139/5000], loss:0.1465\n",
      "steps [2140/5000], loss:0.1366\n",
      "steps [2141/5000], loss:0.1596\n",
      "steps [2142/5000], loss:0.1544\n",
      "steps [2143/5000], loss:0.1326\n",
      "steps [2144/5000], loss:0.1390\n",
      "steps [2145/5000], loss:0.1282\n",
      "steps [2146/5000], loss:0.1357\n",
      "steps [2147/5000], loss:0.1537\n",
      "steps [2148/5000], loss:0.1295\n",
      "steps [2149/5000], loss:0.1236\n",
      "steps [2150/5000], loss:0.1527\n",
      "steps [2151/5000], loss:0.1360\n",
      "steps [2152/5000], loss:0.1427\n",
      "steps [2153/5000], loss:0.1308\n",
      "steps [2154/5000], loss:0.1529\n",
      "steps [2155/5000], loss:0.1644\n",
      "steps [2156/5000], loss:0.1286\n",
      "steps [2157/5000], loss:0.1258\n",
      "steps [2158/5000], loss:0.1361\n",
      "steps [2159/5000], loss:0.1466\n",
      "steps [2160/5000], loss:0.1380\n",
      "steps [2161/5000], loss:0.1408\n",
      "steps [2162/5000], loss:0.1605\n",
      "steps [2163/5000], loss:0.1328\n",
      "steps [2164/5000], loss:0.1344\n",
      "steps [2165/5000], loss:0.1533\n",
      "steps [2166/5000], loss:0.1285\n",
      "steps [2167/5000], loss:0.1291\n",
      "steps [2168/5000], loss:0.1278\n",
      "steps [2169/5000], loss:0.1448\n",
      "steps [2170/5000], loss:0.1525\n",
      "steps [2171/5000], loss:0.1314\n",
      "steps [2172/5000], loss:0.1465\n",
      "steps [2173/5000], loss:0.1544\n",
      "steps [2174/5000], loss:0.1350\n",
      "steps [2175/5000], loss:0.1416\n",
      "steps [2176/5000], loss:0.1373\n",
      "steps [2177/5000], loss:0.1585\n",
      "steps [2178/5000], loss:0.1515\n",
      "steps [2179/5000], loss:0.1304\n",
      "steps [2180/5000], loss:0.1423\n",
      "steps [2181/5000], loss:0.1571\n",
      "steps [2182/5000], loss:0.1634\n",
      "steps [2183/5000], loss:0.1386\n",
      "steps [2184/5000], loss:0.1467\n",
      "steps [2185/5000], loss:0.1540\n",
      "steps [2186/5000], loss:0.1352\n",
      "steps [2187/5000], loss:0.1359\n",
      "steps [2188/5000], loss:0.1468\n",
      "steps [2189/5000], loss:0.1462\n",
      "steps [2190/5000], loss:0.1306\n",
      "steps [2191/5000], loss:0.1604\n",
      "steps [2192/5000], loss:0.1532\n",
      "steps [2193/5000], loss:0.1458\n",
      "steps [2194/5000], loss:0.1673\n",
      "steps [2195/5000], loss:0.1396\n",
      "steps [2196/5000], loss:0.1666\n",
      "steps [2197/5000], loss:0.1361\n",
      "steps [2198/5000], loss:0.1355\n",
      "steps [2199/5000], loss:0.1440\n",
      "steps [2200/5000], loss:0.1467\n",
      "steps [2201/5000], loss:0.1283\n",
      "steps [2202/5000], loss:0.1463\n",
      "steps [2203/5000], loss:0.1619\n",
      "steps [2204/5000], loss:0.1510\n",
      "steps [2205/5000], loss:0.1492\n",
      "steps [2206/5000], loss:0.1576\n",
      "steps [2207/5000], loss:0.1616\n",
      "steps [2208/5000], loss:0.1373\n",
      "steps [2209/5000], loss:0.1542\n",
      "steps [2210/5000], loss:0.1450\n",
      "steps [2211/5000], loss:0.1617\n",
      "steps [2212/5000], loss:0.1434\n",
      "steps [2213/5000], loss:0.1411\n",
      "steps [2214/5000], loss:0.1510\n",
      "steps [2215/5000], loss:0.1485\n",
      "steps [2216/5000], loss:0.1325\n",
      "steps [2217/5000], loss:0.1340\n",
      "steps [2218/5000], loss:0.1311\n",
      "steps [2219/5000], loss:0.1510\n",
      "steps [2220/5000], loss:0.1408\n",
      "steps [2221/5000], loss:0.1425\n",
      "steps [2222/5000], loss:0.1490\n",
      "steps [2223/5000], loss:0.1472\n",
      "steps [2224/5000], loss:0.1398\n",
      "steps [2225/5000], loss:0.1424\n",
      "steps [2226/5000], loss:0.1400\n",
      "steps [2227/5000], loss:0.1393\n",
      "steps [2228/5000], loss:0.1337\n",
      "steps [2229/5000], loss:0.1349\n",
      "steps [2230/5000], loss:0.1622\n",
      "steps [2231/5000], loss:0.1303\n",
      "steps [2232/5000], loss:0.1651\n",
      "steps [2233/5000], loss:0.1436\n",
      "steps [2234/5000], loss:0.1473\n",
      "steps [2235/5000], loss:0.1528\n",
      "steps [2236/5000], loss:0.2162\n",
      "steps [2237/5000], loss:0.1196\n",
      "steps [2238/5000], loss:0.1456\n",
      "steps [2239/5000], loss:0.1633\n",
      "steps [2240/5000], loss:0.1454\n",
      "steps [2241/5000], loss:0.1183\n",
      "steps [2242/5000], loss:0.1475\n",
      "steps [2243/5000], loss:0.1481\n",
      "steps [2244/5000], loss:0.1348\n",
      "steps [2245/5000], loss:0.1567\n",
      "steps [2246/5000], loss:0.1732\n",
      "steps [2247/5000], loss:0.1298\n",
      "steps [2248/5000], loss:0.1459\n",
      "steps [2249/5000], loss:0.1370\n",
      "steps [2250/5000], loss:0.1623\n",
      "steps [2251/5000], loss:0.1673\n",
      "steps [2252/5000], loss:0.1471\n",
      "steps [2253/5000], loss:0.1553\n",
      "steps [2254/5000], loss:0.1433\n",
      "steps [2255/5000], loss:0.1449\n",
      "steps [2256/5000], loss:0.1411\n",
      "steps [2257/5000], loss:0.1416\n",
      "steps [2258/5000], loss:0.1900\n",
      "steps [2259/5000], loss:0.1343\n",
      "steps [2260/5000], loss:0.1469\n",
      "steps [2261/5000], loss:0.1438\n",
      "steps [2262/5000], loss:0.1625\n",
      "steps [2263/5000], loss:0.1335\n",
      "steps [2264/5000], loss:0.1391\n",
      "steps [2265/5000], loss:0.1456\n",
      "steps [2266/5000], loss:0.1692\n",
      "steps [2267/5000], loss:0.1556\n",
      "steps [2268/5000], loss:0.1414\n",
      "steps [2269/5000], loss:0.1744\n",
      "steps [2270/5000], loss:0.1512\n",
      "steps [2271/5000], loss:0.1488\n",
      "steps [2272/5000], loss:0.1408\n",
      "steps [2273/5000], loss:0.1484\n",
      "steps [2274/5000], loss:0.1351\n",
      "steps [2275/5000], loss:0.1592\n",
      "steps [2276/5000], loss:0.1371\n",
      "steps [2277/5000], loss:0.1431\n",
      "steps [2278/5000], loss:0.1503\n",
      "steps [2279/5000], loss:0.1489\n",
      "steps [2280/5000], loss:0.1683\n",
      "steps [2281/5000], loss:0.1368\n",
      "steps [2282/5000], loss:0.1471\n",
      "steps [2283/5000], loss:0.1371\n",
      "steps [2284/5000], loss:0.1534\n",
      "steps [2285/5000], loss:0.1422\n",
      "steps [2286/5000], loss:0.1565\n",
      "steps [2287/5000], loss:0.1379\n",
      "steps [2288/5000], loss:0.1481\n",
      "steps [2289/5000], loss:0.1428\n",
      "steps [2290/5000], loss:0.1504\n",
      "steps [2291/5000], loss:0.1565\n",
      "steps [2292/5000], loss:0.1636\n",
      "steps [2293/5000], loss:0.1586\n",
      "steps [2294/5000], loss:0.1371\n",
      "steps [2295/5000], loss:0.1394\n",
      "steps [2296/5000], loss:0.1514\n",
      "steps [2297/5000], loss:0.1475\n",
      "steps [2298/5000], loss:0.1372\n",
      "steps [2299/5000], loss:0.1541\n",
      "steps [2300/5000], loss:0.1278\n",
      "steps [2301/5000], loss:0.1698\n",
      "steps [2302/5000], loss:0.1832\n",
      "steps [2303/5000], loss:0.1537\n",
      "steps [2304/5000], loss:0.1495\n",
      "steps [2305/5000], loss:0.1328\n",
      "steps [2306/5000], loss:0.1532\n",
      "steps [2307/5000], loss:0.1551\n",
      "steps [2308/5000], loss:0.1369\n",
      "steps [2309/5000], loss:0.1400\n",
      "steps [2310/5000], loss:0.1490\n",
      "steps [2311/5000], loss:0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [2312/5000], loss:0.1418\n",
      "steps [2313/5000], loss:0.1334\n",
      "steps [2314/5000], loss:0.1521\n",
      "steps [2315/5000], loss:0.1506\n",
      "steps [2316/5000], loss:0.1439\n",
      "steps [2317/5000], loss:0.1362\n",
      "steps [2318/5000], loss:0.1309\n",
      "steps [2319/5000], loss:0.1329\n",
      "steps [2320/5000], loss:0.1543\n",
      "steps [2321/5000], loss:0.1377\n",
      "steps [2322/5000], loss:0.1472\n",
      "steps [2323/5000], loss:0.1455\n",
      "steps [2324/5000], loss:0.1354\n",
      "steps [2325/5000], loss:0.1291\n",
      "steps [2326/5000], loss:0.1478\n",
      "steps [2327/5000], loss:0.1453\n",
      "steps [2328/5000], loss:0.1507\n",
      "steps [2329/5000], loss:0.1422\n",
      "steps [2330/5000], loss:0.1239\n",
      "steps [2331/5000], loss:0.1430\n",
      "steps [2332/5000], loss:0.1582\n",
      "steps [2333/5000], loss:0.1498\n",
      "steps [2334/5000], loss:0.1312\n",
      "steps [2335/5000], loss:0.1660\n",
      "steps [2336/5000], loss:0.1491\n",
      "steps [2337/5000], loss:0.1324\n",
      "steps [2338/5000], loss:0.1653\n",
      "steps [2339/5000], loss:0.1513\n",
      "steps [2340/5000], loss:0.1555\n",
      "steps [2341/5000], loss:0.1427\n",
      "steps [2342/5000], loss:0.1432\n",
      "steps [2343/5000], loss:0.1456\n",
      "steps [2344/5000], loss:0.1524\n",
      "steps [2345/5000], loss:0.1398\n",
      "steps [2346/5000], loss:0.1476\n",
      "steps [2347/5000], loss:0.1323\n",
      "steps [2348/5000], loss:0.1398\n",
      "steps [2349/5000], loss:0.1582\n",
      "steps [2350/5000], loss:0.1561\n",
      "steps [2351/5000], loss:0.1690\n",
      "steps [2352/5000], loss:0.1291\n",
      "steps [2353/5000], loss:0.1361\n",
      "steps [2354/5000], loss:0.1457\n",
      "steps [2355/5000], loss:0.1346\n",
      "steps [2356/5000], loss:0.1555\n",
      "steps [2357/5000], loss:0.1469\n",
      "steps [2358/5000], loss:0.1205\n",
      "steps [2359/5000], loss:0.1817\n",
      "steps [2360/5000], loss:0.1425\n",
      "steps [2361/5000], loss:0.1519\n",
      "steps [2362/5000], loss:0.1487\n",
      "steps [2363/5000], loss:0.1428\n",
      "steps [2364/5000], loss:0.1447\n",
      "steps [2365/5000], loss:0.1394\n",
      "steps [2366/5000], loss:0.1433\n",
      "steps [2367/5000], loss:0.1393\n",
      "steps [2368/5000], loss:0.1453\n",
      "steps [2369/5000], loss:0.1510\n",
      "steps [2370/5000], loss:0.1736\n",
      "steps [2371/5000], loss:0.1407\n",
      "steps [2372/5000], loss:0.1510\n",
      "steps [2373/5000], loss:0.1303\n",
      "steps [2374/5000], loss:0.1256\n",
      "steps [2375/5000], loss:0.1463\n",
      "steps [2376/5000], loss:0.1504\n",
      "steps [2377/5000], loss:0.1236\n",
      "steps [2378/5000], loss:0.1410\n",
      "steps [2379/5000], loss:0.1517\n",
      "steps [2380/5000], loss:0.1320\n",
      "steps [2381/5000], loss:0.1412\n",
      "steps [2382/5000], loss:0.1366\n",
      "steps [2383/5000], loss:0.1459\n",
      "steps [2384/5000], loss:0.1602\n",
      "steps [2385/5000], loss:0.1598\n",
      "steps [2386/5000], loss:0.1459\n",
      "steps [2387/5000], loss:0.1333\n",
      "steps [2388/5000], loss:0.1409\n",
      "steps [2389/5000], loss:0.1376\n",
      "steps [2390/5000], loss:0.1562\n",
      "steps [2391/5000], loss:0.1424\n",
      "steps [2392/5000], loss:0.1544\n",
      "steps [2393/5000], loss:0.1476\n",
      "steps [2394/5000], loss:0.1630\n",
      "steps [2395/5000], loss:0.1500\n",
      "steps [2396/5000], loss:0.1563\n",
      "steps [2397/5000], loss:0.1371\n",
      "steps [2398/5000], loss:0.1424\n",
      "steps [2399/5000], loss:0.1526\n",
      "steps [2400/5000], loss:0.1590\n",
      "steps [2401/5000], loss:0.1288\n",
      "steps [2402/5000], loss:0.1491\n",
      "steps [2403/5000], loss:0.1304\n",
      "steps [2404/5000], loss:0.1455\n",
      "steps [2405/5000], loss:0.1507\n",
      "steps [2406/5000], loss:0.1355\n",
      "steps [2407/5000], loss:0.1322\n",
      "steps [2408/5000], loss:0.1349\n",
      "steps [2409/5000], loss:0.1633\n",
      "steps [2410/5000], loss:0.1161\n",
      "steps [2411/5000], loss:0.1637\n",
      "steps [2412/5000], loss:0.1525\n",
      "steps [2413/5000], loss:0.1383\n",
      "steps [2414/5000], loss:0.1783\n",
      "steps [2415/5000], loss:0.1468\n",
      "steps [2416/5000], loss:0.1197\n",
      "steps [2417/5000], loss:0.1363\n",
      "steps [2418/5000], loss:0.1256\n",
      "steps [2419/5000], loss:0.1422\n",
      "steps [2420/5000], loss:0.1399\n",
      "steps [2421/5000], loss:0.1554\n",
      "steps [2422/5000], loss:0.1546\n",
      "steps [2423/5000], loss:0.1397\n",
      "steps [2424/5000], loss:0.1389\n",
      "steps [2425/5000], loss:0.1438\n",
      "steps [2426/5000], loss:0.1366\n",
      "steps [2427/5000], loss:0.1344\n",
      "steps [2428/5000], loss:0.1498\n",
      "steps [2429/5000], loss:0.1628\n",
      "steps [2430/5000], loss:0.1395\n",
      "steps [2431/5000], loss:0.1605\n",
      "steps [2432/5000], loss:0.1529\n",
      "steps [2433/5000], loss:0.1432\n",
      "steps [2434/5000], loss:0.1489\n",
      "steps [2435/5000], loss:0.1503\n",
      "steps [2436/5000], loss:0.1514\n",
      "steps [2437/5000], loss:0.1426\n",
      "steps [2438/5000], loss:0.1599\n",
      "steps [2439/5000], loss:0.1456\n",
      "steps [2440/5000], loss:0.1682\n",
      "steps [2441/5000], loss:0.1314\n",
      "steps [2442/5000], loss:0.1497\n",
      "steps [2443/5000], loss:0.1562\n",
      "steps [2444/5000], loss:0.1385\n",
      "steps [2445/5000], loss:0.1614\n",
      "steps [2446/5000], loss:0.1421\n",
      "steps [2447/5000], loss:0.1526\n",
      "steps [2448/5000], loss:0.1457\n",
      "steps [2449/5000], loss:0.1485\n",
      "steps [2450/5000], loss:0.1316\n",
      "steps [2451/5000], loss:0.1428\n",
      "steps [2452/5000], loss:0.1386\n",
      "steps [2453/5000], loss:0.1538\n",
      "steps [2454/5000], loss:0.1443\n",
      "steps [2455/5000], loss:0.1488\n",
      "steps [2456/5000], loss:0.1410\n",
      "steps [2457/5000], loss:0.1483\n",
      "steps [2458/5000], loss:0.1511\n",
      "steps [2459/5000], loss:0.1673\n",
      "steps [2460/5000], loss:0.1217\n",
      "steps [2461/5000], loss:0.1477\n",
      "steps [2462/5000], loss:0.1516\n",
      "steps [2463/5000], loss:0.1449\n",
      "steps [2464/5000], loss:0.1480\n",
      "steps [2465/5000], loss:0.1562\n",
      "steps [2466/5000], loss:0.1353\n",
      "steps [2467/5000], loss:0.1395\n",
      "steps [2468/5000], loss:0.1380\n",
      "steps [2469/5000], loss:0.1407\n",
      "steps [2470/5000], loss:0.1508\n",
      "steps [2471/5000], loss:0.1439\n",
      "steps [2472/5000], loss:0.1527\n",
      "steps [2473/5000], loss:0.1516\n",
      "steps [2474/5000], loss:0.1371\n",
      "steps [2475/5000], loss:0.1581\n",
      "steps [2476/5000], loss:0.1423\n",
      "steps [2477/5000], loss:0.1453\n",
      "steps [2478/5000], loss:0.1361\n",
      "steps [2479/5000], loss:0.1405\n",
      "steps [2480/5000], loss:0.1646\n",
      "steps [2481/5000], loss:0.1356\n",
      "steps [2482/5000], loss:0.1380\n",
      "steps [2483/5000], loss:0.1366\n",
      "steps [2484/5000], loss:0.1396\n",
      "steps [2485/5000], loss:0.1393\n",
      "steps [2486/5000], loss:0.1745\n",
      "steps [2487/5000], loss:0.1446\n",
      "steps [2488/5000], loss:0.1320\n",
      "steps [2489/5000], loss:0.1285\n",
      "steps [2490/5000], loss:0.1355\n",
      "steps [2491/5000], loss:0.1275\n",
      "steps [2492/5000], loss:0.1481\n",
      "steps [2493/5000], loss:0.1527\n",
      "steps [2494/5000], loss:0.1526\n",
      "steps [2495/5000], loss:0.1376\n",
      "steps [2496/5000], loss:0.1266\n",
      "steps [2497/5000], loss:0.1575\n",
      "steps [2498/5000], loss:0.1443\n",
      "steps [2499/5000], loss:0.1315\n",
      "steps [2500/5000], loss:0.1536\n",
      "steps [2501/5000], loss:0.1342\n",
      "steps [2502/5000], loss:0.1381\n",
      "steps [2503/5000], loss:0.1421\n",
      "steps [2504/5000], loss:0.1409\n",
      "steps [2505/5000], loss:0.1467\n",
      "steps [2506/5000], loss:0.1718\n",
      "steps [2507/5000], loss:0.1637\n",
      "steps [2508/5000], loss:0.1425\n",
      "steps [2509/5000], loss:0.1661\n",
      "steps [2510/5000], loss:0.1394\n",
      "steps [2511/5000], loss:0.1486\n",
      "steps [2512/5000], loss:0.1441\n",
      "steps [2513/5000], loss:0.1542\n",
      "steps [2514/5000], loss:0.1384\n",
      "steps [2515/5000], loss:0.1429\n",
      "steps [2516/5000], loss:0.1488\n",
      "steps [2517/5000], loss:0.1667\n",
      "steps [2518/5000], loss:0.1408\n",
      "steps [2519/5000], loss:0.1463\n",
      "steps [2520/5000], loss:0.1392\n",
      "steps [2521/5000], loss:0.1402\n",
      "steps [2522/5000], loss:0.1421\n",
      "steps [2523/5000], loss:0.1563\n",
      "steps [2524/5000], loss:0.1500\n",
      "steps [2525/5000], loss:0.1426\n",
      "steps [2526/5000], loss:0.1563\n",
      "steps [2527/5000], loss:0.1620\n",
      "steps [2528/5000], loss:0.1584\n",
      "steps [2529/5000], loss:0.1389\n",
      "steps [2530/5000], loss:0.1368\n",
      "steps [2531/5000], loss:0.1597\n",
      "steps [2532/5000], loss:0.1311\n",
      "steps [2533/5000], loss:0.1391\n",
      "steps [2534/5000], loss:0.1534\n",
      "steps [2535/5000], loss:0.1555\n",
      "steps [2536/5000], loss:0.1435\n",
      "steps [2537/5000], loss:0.1409\n",
      "steps [2538/5000], loss:0.1604\n",
      "steps [2539/5000], loss:0.1559\n",
      "steps [2540/5000], loss:0.1442\n",
      "steps [2541/5000], loss:0.1369\n",
      "steps [2542/5000], loss:0.1537\n",
      "steps [2543/5000], loss:0.1299\n",
      "steps [2544/5000], loss:0.1488\n",
      "steps [2545/5000], loss:0.1352\n",
      "steps [2546/5000], loss:0.1624\n",
      "steps [2547/5000], loss:0.1534\n",
      "steps [2548/5000], loss:0.1325\n",
      "steps [2549/5000], loss:0.1354\n",
      "steps [2550/5000], loss:0.1359\n",
      "steps [2551/5000], loss:0.1386\n",
      "steps [2552/5000], loss:0.1404\n",
      "steps [2553/5000], loss:0.1459\n",
      "steps [2554/5000], loss:0.1385\n",
      "steps [2555/5000], loss:0.1491\n",
      "steps [2556/5000], loss:0.1417\n",
      "steps [2557/5000], loss:0.1358\n",
      "steps [2558/5000], loss:0.1383\n",
      "steps [2559/5000], loss:0.1305\n",
      "steps [2560/5000], loss:0.1288\n",
      "steps [2561/5000], loss:0.1353\n",
      "steps [2562/5000], loss:0.1493\n",
      "steps [2563/5000], loss:0.1565\n",
      "steps [2564/5000], loss:0.1456\n",
      "steps [2565/5000], loss:0.1472\n",
      "steps [2566/5000], loss:0.1462\n",
      "steps [2567/5000], loss:0.1498\n",
      "steps [2568/5000], loss:0.1588\n",
      "steps [2569/5000], loss:0.1451\n",
      "steps [2570/5000], loss:0.1349\n",
      "steps [2571/5000], loss:0.1339\n",
      "steps [2572/5000], loss:0.1665\n",
      "steps [2573/5000], loss:0.1505\n",
      "steps [2574/5000], loss:0.1393\n",
      "steps [2575/5000], loss:0.1398\n",
      "steps [2576/5000], loss:0.1339\n",
      "steps [2577/5000], loss:0.1583\n",
      "steps [2578/5000], loss:0.1313\n",
      "steps [2579/5000], loss:0.1336\n",
      "steps [2580/5000], loss:0.1375\n",
      "steps [2581/5000], loss:0.1402\n",
      "steps [2582/5000], loss:0.1441\n",
      "steps [2583/5000], loss:0.1450\n",
      "steps [2584/5000], loss:0.1461\n",
      "steps [2585/5000], loss:0.1312\n",
      "steps [2586/5000], loss:0.1426\n",
      "steps [2587/5000], loss:0.1305\n",
      "steps [2588/5000], loss:0.1345\n",
      "steps [2589/5000], loss:0.1397\n",
      "steps [2590/5000], loss:0.1391\n",
      "steps [2591/5000], loss:0.1323\n",
      "steps [2592/5000], loss:0.1576\n",
      "steps [2593/5000], loss:0.1384\n",
      "steps [2594/5000], loss:0.1431\n",
      "steps [2595/5000], loss:0.1476\n",
      "steps [2596/5000], loss:0.1650\n",
      "steps [2597/5000], loss:0.1313\n",
      "steps [2598/5000], loss:0.1418\n",
      "steps [2599/5000], loss:0.1576\n",
      "steps [2600/5000], loss:0.1821\n",
      "steps [2601/5000], loss:0.1542\n",
      "steps [2602/5000], loss:0.1455\n",
      "steps [2603/5000], loss:0.1312\n",
      "steps [2604/5000], loss:0.1217\n",
      "steps [2605/5000], loss:0.1391\n",
      "steps [2606/5000], loss:0.1497\n",
      "steps [2607/5000], loss:0.1651\n",
      "steps [2608/5000], loss:0.1261\n",
      "steps [2609/5000], loss:0.1525\n",
      "steps [2610/5000], loss:0.1449\n",
      "steps [2611/5000], loss:0.1392\n",
      "steps [2612/5000], loss:0.1548\n",
      "steps [2613/5000], loss:0.1436\n",
      "steps [2614/5000], loss:0.1395\n",
      "steps [2615/5000], loss:0.1495\n",
      "steps [2616/5000], loss:0.1602\n",
      "steps [2617/5000], loss:0.1195\n",
      "steps [2618/5000], loss:0.1390\n",
      "steps [2619/5000], loss:0.1310\n",
      "steps [2620/5000], loss:0.1461\n",
      "steps [2621/5000], loss:0.1428\n",
      "steps [2622/5000], loss:0.1386\n",
      "steps [2623/5000], loss:0.1537\n",
      "steps [2624/5000], loss:0.1488\n",
      "steps [2625/5000], loss:0.1528\n",
      "steps [2626/5000], loss:0.1361\n",
      "steps [2627/5000], loss:0.1391\n",
      "steps [2628/5000], loss:0.1524\n",
      "steps [2629/5000], loss:0.1540\n",
      "steps [2630/5000], loss:0.1458\n",
      "steps [2631/5000], loss:0.1521\n",
      "steps [2632/5000], loss:0.1425\n",
      "steps [2633/5000], loss:0.1342\n",
      "steps [2634/5000], loss:0.1511\n",
      "steps [2635/5000], loss:0.1362\n",
      "steps [2636/5000], loss:0.1299\n",
      "steps [2637/5000], loss:0.1545\n",
      "steps [2638/5000], loss:0.1772\n",
      "steps [2639/5000], loss:0.1399\n",
      "steps [2640/5000], loss:0.1686\n",
      "steps [2641/5000], loss:0.1296\n",
      "steps [2642/5000], loss:0.1513\n",
      "steps [2643/5000], loss:0.1480\n",
      "steps [2644/5000], loss:0.1325\n",
      "steps [2645/5000], loss:0.1312\n",
      "steps [2646/5000], loss:0.1403\n",
      "steps [2647/5000], loss:0.1354\n",
      "steps [2648/5000], loss:0.1345\n",
      "steps [2649/5000], loss:0.1566\n",
      "steps [2650/5000], loss:0.1356\n",
      "steps [2651/5000], loss:0.1376\n",
      "steps [2652/5000], loss:0.1491\n",
      "steps [2653/5000], loss:0.1457\n",
      "steps [2654/5000], loss:0.1407\n",
      "steps [2655/5000], loss:0.1575\n",
      "steps [2656/5000], loss:0.1378\n",
      "steps [2657/5000], loss:0.1367\n",
      "steps [2658/5000], loss:0.1521\n",
      "steps [2659/5000], loss:0.1329\n",
      "steps [2660/5000], loss:0.1393\n",
      "steps [2661/5000], loss:0.1342\n",
      "steps [2662/5000], loss:0.1492\n",
      "steps [2663/5000], loss:0.1494\n",
      "steps [2664/5000], loss:0.1568\n",
      "steps [2665/5000], loss:0.1510\n",
      "steps [2666/5000], loss:0.1613\n",
      "steps [2667/5000], loss:0.1469\n",
      "steps [2668/5000], loss:0.1372\n",
      "steps [2669/5000], loss:0.1320\n",
      "steps [2670/5000], loss:0.1458\n",
      "steps [2671/5000], loss:0.1229\n",
      "steps [2672/5000], loss:0.1554\n",
      "steps [2673/5000], loss:0.1350\n",
      "steps [2674/5000], loss:0.1262\n",
      "steps [2675/5000], loss:0.1615\n",
      "steps [2676/5000], loss:0.1918\n",
      "steps [2677/5000], loss:0.1363\n",
      "steps [2678/5000], loss:0.1464\n",
      "steps [2679/5000], loss:0.1346\n",
      "steps [2680/5000], loss:0.1568\n",
      "steps [2681/5000], loss:0.1314\n",
      "steps [2682/5000], loss:0.1469\n",
      "steps [2683/5000], loss:0.1537\n",
      "steps [2684/5000], loss:0.1206\n",
      "steps [2685/5000], loss:0.1538\n",
      "steps [2686/5000], loss:0.1532\n",
      "steps [2687/5000], loss:0.1435\n",
      "steps [2688/5000], loss:0.1389\n",
      "steps [2689/5000], loss:0.1268\n",
      "steps [2690/5000], loss:0.1472\n",
      "steps [2691/5000], loss:0.1332\n",
      "steps [2692/5000], loss:0.1326\n",
      "steps [2693/5000], loss:0.1792\n",
      "steps [2694/5000], loss:0.1260\n",
      "steps [2695/5000], loss:0.1455\n",
      "steps [2696/5000], loss:0.1550\n",
      "steps [2697/5000], loss:0.1469\n",
      "steps [2698/5000], loss:0.1332\n",
      "steps [2699/5000], loss:0.1634\n",
      "steps [2700/5000], loss:0.1305\n",
      "steps [2701/5000], loss:0.1541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [2702/5000], loss:0.1327\n",
      "steps [2703/5000], loss:0.1320\n",
      "steps [2704/5000], loss:0.1347\n",
      "steps [2705/5000], loss:0.1483\n",
      "steps [2706/5000], loss:0.1331\n",
      "steps [2707/5000], loss:0.1249\n",
      "steps [2708/5000], loss:0.1493\n",
      "steps [2709/5000], loss:0.1337\n",
      "steps [2710/5000], loss:0.1496\n",
      "steps [2711/5000], loss:0.1715\n",
      "steps [2712/5000], loss:0.1379\n",
      "steps [2713/5000], loss:0.1267\n",
      "steps [2714/5000], loss:0.1588\n",
      "steps [2715/5000], loss:0.1198\n",
      "steps [2716/5000], loss:0.1507\n",
      "steps [2717/5000], loss:0.1287\n",
      "steps [2718/5000], loss:0.1827\n",
      "steps [2719/5000], loss:0.1381\n",
      "steps [2720/5000], loss:0.1494\n",
      "steps [2721/5000], loss:0.1503\n",
      "steps [2722/5000], loss:0.1378\n",
      "steps [2723/5000], loss:0.1348\n",
      "steps [2724/5000], loss:0.1322\n",
      "steps [2725/5000], loss:0.1538\n",
      "steps [2726/5000], loss:0.1669\n",
      "steps [2727/5000], loss:0.1342\n",
      "steps [2728/5000], loss:0.1454\n",
      "steps [2729/5000], loss:0.1437\n",
      "steps [2730/5000], loss:0.1591\n",
      "steps [2731/5000], loss:0.1552\n",
      "steps [2732/5000], loss:0.1624\n",
      "steps [2733/5000], loss:0.1505\n",
      "steps [2734/5000], loss:0.1676\n",
      "steps [2735/5000], loss:0.1390\n",
      "steps [2736/5000], loss:0.1542\n",
      "steps [2737/5000], loss:0.1437\n",
      "steps [2738/5000], loss:0.1500\n",
      "steps [2739/5000], loss:0.1474\n",
      "steps [2740/5000], loss:0.1439\n",
      "steps [2741/5000], loss:0.1676\n",
      "steps [2742/5000], loss:0.1382\n",
      "steps [2743/5000], loss:0.1399\n",
      "steps [2744/5000], loss:0.1450\n",
      "steps [2745/5000], loss:0.1397\n",
      "steps [2746/5000], loss:0.1506\n",
      "steps [2747/5000], loss:0.1350\n",
      "steps [2748/5000], loss:0.1354\n",
      "steps [2749/5000], loss:0.1561\n",
      "steps [2750/5000], loss:0.1374\n",
      "steps [2751/5000], loss:0.1336\n",
      "steps [2752/5000], loss:0.1742\n",
      "steps [2753/5000], loss:0.1472\n",
      "steps [2754/5000], loss:0.1507\n",
      "steps [2755/5000], loss:0.1429\n",
      "steps [2756/5000], loss:0.1387\n",
      "steps [2757/5000], loss:0.1375\n",
      "steps [2758/5000], loss:0.1439\n",
      "steps [2759/5000], loss:0.1451\n",
      "steps [2760/5000], loss:0.1416\n",
      "steps [2761/5000], loss:0.1377\n",
      "steps [2762/5000], loss:0.1573\n",
      "steps [2763/5000], loss:0.1431\n",
      "steps [2764/5000], loss:0.1485\n",
      "steps [2765/5000], loss:0.1274\n",
      "steps [2766/5000], loss:0.1522\n",
      "steps [2767/5000], loss:0.1377\n",
      "steps [2768/5000], loss:0.1519\n",
      "steps [2769/5000], loss:0.1549\n",
      "steps [2770/5000], loss:0.1477\n",
      "steps [2771/5000], loss:0.1399\n",
      "steps [2772/5000], loss:0.1347\n",
      "steps [2773/5000], loss:0.1575\n",
      "steps [2774/5000], loss:0.1618\n",
      "steps [2775/5000], loss:0.1352\n",
      "steps [2776/5000], loss:0.1544\n",
      "steps [2777/5000], loss:0.1384\n",
      "steps [2778/5000], loss:0.1644\n",
      "steps [2779/5000], loss:0.1333\n",
      "steps [2780/5000], loss:0.1396\n",
      "steps [2781/5000], loss:0.1418\n",
      "steps [2782/5000], loss:0.1298\n",
      "steps [2783/5000], loss:0.1297\n",
      "steps [2784/5000], loss:0.1298\n",
      "steps [2785/5000], loss:0.1797\n",
      "steps [2786/5000], loss:0.1261\n",
      "steps [2787/5000], loss:0.1478\n",
      "steps [2788/5000], loss:0.1511\n",
      "steps [2789/5000], loss:0.1393\n",
      "steps [2790/5000], loss:0.1507\n",
      "steps [2791/5000], loss:0.1628\n",
      "steps [2792/5000], loss:0.1482\n",
      "steps [2793/5000], loss:0.1423\n",
      "steps [2794/5000], loss:0.1466\n",
      "steps [2795/5000], loss:0.1408\n",
      "steps [2796/5000], loss:0.1387\n",
      "steps [2797/5000], loss:0.1536\n",
      "steps [2798/5000], loss:0.1606\n",
      "steps [2799/5000], loss:0.1491\n",
      "steps [2800/5000], loss:0.1543\n",
      "steps [2801/5000], loss:0.1317\n",
      "steps [2802/5000], loss:0.1724\n",
      "steps [2803/5000], loss:0.1384\n",
      "steps [2804/5000], loss:0.1420\n",
      "steps [2805/5000], loss:0.1499\n",
      "steps [2806/5000], loss:0.1334\n",
      "steps [2807/5000], loss:0.1319\n",
      "steps [2808/5000], loss:0.1278\n",
      "steps [2809/5000], loss:0.1736\n",
      "steps [2810/5000], loss:0.1268\n",
      "steps [2811/5000], loss:0.1517\n",
      "steps [2812/5000], loss:0.1501\n",
      "steps [2813/5000], loss:0.1318\n",
      "steps [2814/5000], loss:0.1349\n",
      "steps [2815/5000], loss:0.1256\n",
      "steps [2816/5000], loss:0.1304\n",
      "steps [2817/5000], loss:0.1392\n",
      "steps [2818/5000], loss:0.1295\n",
      "steps [2819/5000], loss:0.1270\n",
      "steps [2820/5000], loss:0.1424\n",
      "steps [2821/5000], loss:0.1424\n",
      "steps [2822/5000], loss:0.1266\n",
      "steps [2823/5000], loss:0.1338\n",
      "steps [2824/5000], loss:0.1327\n",
      "steps [2825/5000], loss:0.1338\n",
      "steps [2826/5000], loss:0.1504\n",
      "steps [2827/5000], loss:0.1351\n",
      "steps [2828/5000], loss:0.1393\n",
      "steps [2829/5000], loss:0.1453\n",
      "steps [2830/5000], loss:0.1399\n",
      "steps [2831/5000], loss:0.1412\n",
      "steps [2832/5000], loss:0.1348\n",
      "steps [2833/5000], loss:0.1575\n",
      "steps [2834/5000], loss:0.1382\n",
      "steps [2835/5000], loss:0.1560\n",
      "steps [2836/5000], loss:0.1227\n",
      "steps [2837/5000], loss:0.1458\n",
      "steps [2838/5000], loss:0.1433\n",
      "steps [2839/5000], loss:0.1531\n",
      "steps [2840/5000], loss:0.1415\n",
      "steps [2841/5000], loss:0.1511\n",
      "steps [2842/5000], loss:0.1391\n",
      "steps [2843/5000], loss:0.1588\n",
      "steps [2844/5000], loss:0.1354\n",
      "steps [2845/5000], loss:0.1259\n",
      "steps [2846/5000], loss:0.1411\n",
      "steps [2847/5000], loss:0.1335\n",
      "steps [2848/5000], loss:0.1415\n",
      "steps [2849/5000], loss:0.1272\n",
      "steps [2850/5000], loss:0.1891\n",
      "steps [2851/5000], loss:0.1498\n",
      "steps [2852/5000], loss:0.1540\n",
      "steps [2853/5000], loss:0.1325\n",
      "steps [2854/5000], loss:0.1386\n",
      "steps [2855/5000], loss:0.1541\n",
      "steps [2856/5000], loss:0.1486\n",
      "steps [2857/5000], loss:0.1413\n",
      "steps [2858/5000], loss:0.1381\n",
      "steps [2859/5000], loss:0.1320\n",
      "steps [2860/5000], loss:0.1570\n",
      "steps [2861/5000], loss:0.1419\n",
      "steps [2862/5000], loss:0.1563\n",
      "steps [2863/5000], loss:0.1722\n",
      "steps [2864/5000], loss:0.1203\n",
      "steps [2865/5000], loss:0.1683\n",
      "steps [2866/5000], loss:0.1514\n",
      "steps [2867/5000], loss:0.1452\n",
      "steps [2868/5000], loss:0.1485\n",
      "steps [2869/5000], loss:0.1628\n",
      "steps [2870/5000], loss:0.1492\n",
      "steps [2871/5000], loss:0.1646\n",
      "steps [2872/5000], loss:0.1430\n",
      "steps [2873/5000], loss:0.1523\n",
      "steps [2874/5000], loss:0.1539\n",
      "steps [2875/5000], loss:0.1377\n",
      "steps [2876/5000], loss:0.1717\n",
      "steps [2877/5000], loss:0.1549\n",
      "steps [2878/5000], loss:0.1557\n",
      "steps [2879/5000], loss:0.1302\n",
      "steps [2880/5000], loss:0.1456\n",
      "steps [2881/5000], loss:0.1460\n",
      "steps [2882/5000], loss:0.1516\n",
      "steps [2883/5000], loss:0.1542\n",
      "steps [2884/5000], loss:0.1370\n",
      "steps [2885/5000], loss:0.1609\n",
      "steps [2886/5000], loss:0.1403\n",
      "steps [2887/5000], loss:0.1302\n",
      "steps [2888/5000], loss:0.1440\n",
      "steps [2889/5000], loss:0.1373\n",
      "steps [2890/5000], loss:0.1497\n",
      "steps [2891/5000], loss:0.1341\n",
      "steps [2892/5000], loss:0.1449\n",
      "steps [2893/5000], loss:0.1481\n",
      "steps [2894/5000], loss:0.1522\n",
      "steps [2895/5000], loss:0.1676\n",
      "steps [2896/5000], loss:0.1474\n",
      "steps [2897/5000], loss:0.1701\n",
      "steps [2898/5000], loss:0.1334\n",
      "steps [2899/5000], loss:0.1560\n",
      "steps [2900/5000], loss:0.1239\n",
      "steps [2901/5000], loss:0.1357\n",
      "steps [2902/5000], loss:0.1377\n",
      "steps [2903/5000], loss:0.1419\n",
      "steps [2904/5000], loss:0.1541\n",
      "steps [2905/5000], loss:0.1317\n",
      "steps [2906/5000], loss:0.1325\n",
      "steps [2907/5000], loss:0.1305\n",
      "steps [2908/5000], loss:0.1299\n",
      "steps [2909/5000], loss:0.1307\n",
      "steps [2910/5000], loss:0.1585\n",
      "steps [2911/5000], loss:0.1394\n",
      "steps [2912/5000], loss:0.1338\n",
      "steps [2913/5000], loss:0.1438\n",
      "steps [2914/5000], loss:0.1313\n",
      "steps [2915/5000], loss:0.1417\n",
      "steps [2916/5000], loss:0.1415\n",
      "steps [2917/5000], loss:0.1541\n",
      "steps [2918/5000], loss:0.1416\n",
      "steps [2919/5000], loss:0.1622\n",
      "steps [2920/5000], loss:0.1476\n",
      "steps [2921/5000], loss:0.1575\n",
      "steps [2922/5000], loss:0.1495\n",
      "steps [2923/5000], loss:0.1399\n",
      "steps [2924/5000], loss:0.1288\n",
      "steps [2925/5000], loss:0.1595\n",
      "steps [2926/5000], loss:0.1347\n",
      "steps [2927/5000], loss:0.1451\n",
      "steps [2928/5000], loss:0.1290\n",
      "steps [2929/5000], loss:0.1320\n",
      "steps [2930/5000], loss:0.1481\n",
      "steps [2931/5000], loss:0.1305\n",
      "steps [2932/5000], loss:0.1283\n",
      "steps [2933/5000], loss:0.1436\n",
      "steps [2934/5000], loss:0.1528\n",
      "steps [2935/5000], loss:0.1756\n",
      "steps [2936/5000], loss:0.1272\n",
      "steps [2937/5000], loss:0.1703\n",
      "steps [2938/5000], loss:0.1378\n",
      "steps [2939/5000], loss:0.1408\n",
      "steps [2940/5000], loss:0.1626\n",
      "steps [2941/5000], loss:0.1418\n",
      "steps [2942/5000], loss:0.1520\n",
      "steps [2943/5000], loss:0.1323\n",
      "steps [2944/5000], loss:0.1456\n",
      "steps [2945/5000], loss:0.1577\n",
      "steps [2946/5000], loss:0.1511\n",
      "steps [2947/5000], loss:0.1356\n",
      "steps [2948/5000], loss:0.1386\n",
      "steps [2949/5000], loss:0.1364\n",
      "steps [2950/5000], loss:0.1737\n",
      "steps [2951/5000], loss:0.1507\n",
      "steps [2952/5000], loss:0.1295\n",
      "steps [2953/5000], loss:0.1549\n",
      "steps [2954/5000], loss:0.1391\n",
      "steps [2955/5000], loss:0.1455\n",
      "steps [2956/5000], loss:0.1389\n",
      "steps [2957/5000], loss:0.1405\n",
      "steps [2958/5000], loss:0.1504\n",
      "steps [2959/5000], loss:0.1687\n",
      "steps [2960/5000], loss:0.1322\n",
      "steps [2961/5000], loss:0.1456\n",
      "steps [2962/5000], loss:0.1438\n",
      "steps [2963/5000], loss:0.1453\n",
      "steps [2964/5000], loss:0.1501\n",
      "steps [2965/5000], loss:0.1642\n",
      "steps [2966/5000], loss:0.1520\n",
      "steps [2967/5000], loss:0.1464\n",
      "steps [2968/5000], loss:0.1284\n",
      "steps [2969/5000], loss:0.1292\n",
      "steps [2970/5000], loss:0.1423\n",
      "steps [2971/5000], loss:0.1524\n",
      "steps [2972/5000], loss:0.1322\n",
      "steps [2973/5000], loss:0.1511\n",
      "steps [2974/5000], loss:0.1315\n",
      "steps [2975/5000], loss:0.1330\n",
      "steps [2976/5000], loss:0.1587\n",
      "steps [2977/5000], loss:0.1501\n",
      "steps [2978/5000], loss:0.1304\n",
      "steps [2979/5000], loss:0.1454\n",
      "steps [2980/5000], loss:0.1379\n",
      "steps [2981/5000], loss:0.1529\n",
      "steps [2982/5000], loss:0.1451\n",
      "steps [2983/5000], loss:0.1505\n",
      "steps [2984/5000], loss:0.1372\n",
      "steps [2985/5000], loss:0.1423\n",
      "steps [2986/5000], loss:0.1248\n",
      "steps [2987/5000], loss:0.1452\n",
      "steps [2988/5000], loss:0.1501\n",
      "steps [2989/5000], loss:0.1514\n",
      "steps [2990/5000], loss:0.1419\n",
      "steps [2991/5000], loss:0.1405\n",
      "steps [2992/5000], loss:0.1679\n",
      "steps [2993/5000], loss:0.1589\n",
      "steps [2994/5000], loss:0.1337\n",
      "steps [2995/5000], loss:0.1294\n",
      "steps [2996/5000], loss:0.1578\n",
      "steps [2997/5000], loss:0.1544\n",
      "steps [2998/5000], loss:0.1412\n",
      "steps [2999/5000], loss:0.1530\n",
      "steps [3000/5000], loss:0.1382\n",
      "steps [3001/5000], loss:0.1396\n",
      "steps [3002/5000], loss:0.1407\n",
      "steps [3003/5000], loss:0.1439\n",
      "steps [3004/5000], loss:0.1669\n",
      "steps [3005/5000], loss:0.1398\n",
      "steps [3006/5000], loss:0.1321\n",
      "steps [3007/5000], loss:0.1390\n",
      "steps [3008/5000], loss:0.1507\n",
      "steps [3009/5000], loss:0.1578\n",
      "steps [3010/5000], loss:0.1498\n",
      "steps [3011/5000], loss:0.1317\n",
      "steps [3012/5000], loss:0.1499\n",
      "steps [3013/5000], loss:0.1302\n",
      "steps [3014/5000], loss:0.1376\n",
      "steps [3015/5000], loss:0.1398\n",
      "steps [3016/5000], loss:0.1329\n",
      "steps [3017/5000], loss:0.1358\n",
      "steps [3018/5000], loss:0.1599\n",
      "steps [3019/5000], loss:0.1451\n",
      "steps [3020/5000], loss:0.1423\n",
      "steps [3021/5000], loss:0.1390\n",
      "steps [3022/5000], loss:0.1404\n",
      "steps [3023/5000], loss:0.1330\n",
      "steps [3024/5000], loss:0.1570\n",
      "steps [3025/5000], loss:0.1285\n",
      "steps [3026/5000], loss:0.1466\n",
      "steps [3027/5000], loss:0.1608\n",
      "steps [3028/5000], loss:0.1357\n",
      "steps [3029/5000], loss:0.1408\n",
      "steps [3030/5000], loss:0.1398\n",
      "steps [3031/5000], loss:0.1368\n",
      "steps [3032/5000], loss:0.1308\n",
      "steps [3033/5000], loss:0.1707\n",
      "steps [3034/5000], loss:0.1541\n",
      "steps [3035/5000], loss:0.1597\n",
      "steps [3036/5000], loss:0.1272\n",
      "steps [3037/5000], loss:0.1199\n",
      "steps [3038/5000], loss:0.1314\n",
      "steps [3039/5000], loss:0.1409\n",
      "steps [3040/5000], loss:0.1497\n",
      "steps [3041/5000], loss:0.1505\n",
      "steps [3042/5000], loss:0.1386\n",
      "steps [3043/5000], loss:0.1412\n",
      "steps [3044/5000], loss:0.1345\n",
      "steps [3045/5000], loss:0.1363\n",
      "steps [3046/5000], loss:0.1746\n",
      "steps [3047/5000], loss:0.1202\n",
      "steps [3048/5000], loss:0.1484\n",
      "steps [3049/5000], loss:0.1541\n",
      "steps [3050/5000], loss:0.1386\n",
      "steps [3051/5000], loss:0.1508\n",
      "steps [3052/5000], loss:0.1380\n",
      "steps [3053/5000], loss:0.1430\n",
      "steps [3054/5000], loss:0.1466\n",
      "steps [3055/5000], loss:0.1649\n",
      "steps [3056/5000], loss:0.1472\n",
      "steps [3057/5000], loss:0.1313\n",
      "steps [3058/5000], loss:0.1343\n",
      "steps [3059/5000], loss:0.1457\n",
      "steps [3060/5000], loss:0.1348\n",
      "steps [3061/5000], loss:0.1388\n",
      "steps [3062/5000], loss:0.1554\n",
      "steps [3063/5000], loss:0.1520\n",
      "steps [3064/5000], loss:0.1528\n",
      "steps [3065/5000], loss:0.1640\n",
      "steps [3066/5000], loss:0.1667\n",
      "steps [3067/5000], loss:0.1453\n",
      "steps [3068/5000], loss:0.1401\n",
      "steps [3069/5000], loss:0.1399\n",
      "steps [3070/5000], loss:0.1443\n",
      "steps [3071/5000], loss:0.1613\n",
      "steps [3072/5000], loss:0.1415\n",
      "steps [3073/5000], loss:0.1543\n",
      "steps [3074/5000], loss:0.1657\n",
      "steps [3075/5000], loss:0.1316\n",
      "steps [3076/5000], loss:0.1556\n",
      "steps [3077/5000], loss:0.1572\n",
      "steps [3078/5000], loss:0.1340\n",
      "steps [3079/5000], loss:0.1388\n",
      "steps [3080/5000], loss:0.1597\n",
      "steps [3081/5000], loss:0.1454\n",
      "steps [3082/5000], loss:0.1544\n",
      "steps [3083/5000], loss:0.1532\n",
      "steps [3084/5000], loss:0.1203\n",
      "steps [3085/5000], loss:0.1432\n",
      "steps [3086/5000], loss:0.1523\n",
      "steps [3087/5000], loss:0.1645\n",
      "steps [3088/5000], loss:0.1414\n",
      "steps [3089/5000], loss:0.1685\n",
      "steps [3090/5000], loss:0.1503\n",
      "steps [3091/5000], loss:0.1381\n",
      "steps [3092/5000], loss:0.1409\n",
      "steps [3093/5000], loss:0.1327\n",
      "steps [3094/5000], loss:0.1433\n",
      "steps [3095/5000], loss:0.1382\n",
      "steps [3096/5000], loss:0.1485\n",
      "steps [3097/5000], loss:0.1439\n",
      "steps [3098/5000], loss:0.1386\n",
      "steps [3099/5000], loss:0.1490\n",
      "steps [3100/5000], loss:0.1313\n",
      "steps [3101/5000], loss:0.1629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [3102/5000], loss:0.1477\n",
      "steps [3103/5000], loss:0.1359\n",
      "steps [3104/5000], loss:0.1495\n",
      "steps [3105/5000], loss:0.1395\n",
      "steps [3106/5000], loss:0.1459\n",
      "steps [3107/5000], loss:0.1352\n",
      "steps [3108/5000], loss:0.1415\n",
      "steps [3109/5000], loss:0.1409\n",
      "steps [3110/5000], loss:0.1344\n",
      "steps [3111/5000], loss:0.1462\n",
      "steps [3112/5000], loss:0.1555\n",
      "steps [3113/5000], loss:0.1502\n",
      "steps [3114/5000], loss:0.1617\n",
      "steps [3115/5000], loss:0.1482\n",
      "steps [3116/5000], loss:0.1458\n",
      "steps [3117/5000], loss:0.1423\n",
      "steps [3118/5000], loss:0.1555\n",
      "steps [3119/5000], loss:0.1484\n",
      "steps [3120/5000], loss:0.1436\n",
      "steps [3121/5000], loss:0.1453\n",
      "steps [3122/5000], loss:0.1548\n",
      "steps [3123/5000], loss:0.1279\n",
      "steps [3124/5000], loss:0.1553\n",
      "steps [3125/5000], loss:0.1328\n",
      "steps [3126/5000], loss:0.1517\n",
      "steps [3127/5000], loss:0.1431\n",
      "steps [3128/5000], loss:0.1338\n",
      "steps [3129/5000], loss:0.1759\n",
      "steps [3130/5000], loss:0.1580\n",
      "steps [3131/5000], loss:0.1637\n",
      "steps [3132/5000], loss:0.1385\n",
      "steps [3133/5000], loss:0.1529\n",
      "steps [3134/5000], loss:0.1311\n",
      "steps [3135/5000], loss:0.1363\n",
      "steps [3136/5000], loss:0.1357\n",
      "steps [3137/5000], loss:0.1479\n",
      "steps [3138/5000], loss:0.1583\n",
      "steps [3139/5000], loss:0.1378\n",
      "steps [3140/5000], loss:0.1291\n",
      "steps [3141/5000], loss:0.1395\n",
      "steps [3142/5000], loss:0.1454\n",
      "steps [3143/5000], loss:0.1792\n",
      "steps [3144/5000], loss:0.1690\n",
      "steps [3145/5000], loss:0.1379\n",
      "steps [3146/5000], loss:0.1318\n",
      "steps [3147/5000], loss:0.1651\n",
      "steps [3148/5000], loss:0.1667\n",
      "steps [3149/5000], loss:0.1314\n",
      "steps [3150/5000], loss:0.1339\n",
      "steps [3151/5000], loss:0.1324\n",
      "steps [3152/5000], loss:0.1785\n",
      "steps [3153/5000], loss:0.1450\n",
      "steps [3154/5000], loss:0.1568\n",
      "steps [3155/5000], loss:0.1418\n",
      "steps [3156/5000], loss:0.1434\n",
      "steps [3157/5000], loss:0.1346\n",
      "steps [3158/5000], loss:0.1388\n",
      "steps [3159/5000], loss:0.1550\n",
      "steps [3160/5000], loss:0.1399\n",
      "steps [3161/5000], loss:0.1470\n",
      "steps [3162/5000], loss:0.1456\n",
      "steps [3163/5000], loss:0.1480\n",
      "steps [3164/5000], loss:0.1296\n",
      "steps [3165/5000], loss:0.1627\n",
      "steps [3166/5000], loss:0.1476\n",
      "steps [3167/5000], loss:0.1883\n",
      "steps [3168/5000], loss:0.1464\n",
      "steps [3169/5000], loss:0.1416\n",
      "steps [3170/5000], loss:0.1514\n",
      "steps [3171/5000], loss:0.1269\n",
      "steps [3172/5000], loss:0.1412\n",
      "steps [3173/5000], loss:0.1395\n",
      "steps [3174/5000], loss:0.1381\n",
      "steps [3175/5000], loss:0.1431\n",
      "steps [3176/5000], loss:0.1365\n",
      "steps [3177/5000], loss:0.1476\n",
      "steps [3178/5000], loss:0.1432\n",
      "steps [3179/5000], loss:0.1700\n",
      "steps [3180/5000], loss:0.1407\n",
      "steps [3181/5000], loss:0.1856\n",
      "steps [3182/5000], loss:0.1313\n",
      "steps [3183/5000], loss:0.1531\n",
      "steps [3184/5000], loss:0.1363\n",
      "steps [3185/5000], loss:0.1383\n",
      "steps [3186/5000], loss:0.1472\n",
      "steps [3187/5000], loss:0.1469\n",
      "steps [3188/5000], loss:0.1334\n",
      "steps [3189/5000], loss:0.1454\n",
      "steps [3190/5000], loss:0.1479\n",
      "steps [3191/5000], loss:0.1476\n",
      "steps [3192/5000], loss:0.1385\n",
      "steps [3193/5000], loss:0.1575\n",
      "steps [3194/5000], loss:0.1376\n",
      "steps [3195/5000], loss:0.1293\n",
      "steps [3196/5000], loss:0.1338\n",
      "steps [3197/5000], loss:0.1619\n",
      "steps [3198/5000], loss:0.1380\n",
      "steps [3199/5000], loss:0.1556\n",
      "steps [3200/5000], loss:0.1461\n",
      "steps [3201/5000], loss:0.1481\n",
      "steps [3202/5000], loss:0.1447\n",
      "steps [3203/5000], loss:0.1401\n",
      "steps [3204/5000], loss:0.1374\n",
      "steps [3205/5000], loss:0.1309\n",
      "steps [3206/5000], loss:0.1457\n",
      "steps [3207/5000], loss:0.1462\n",
      "steps [3208/5000], loss:0.1396\n",
      "steps [3209/5000], loss:0.1464\n",
      "steps [3210/5000], loss:0.1616\n",
      "steps [3211/5000], loss:0.1468\n",
      "steps [3212/5000], loss:0.1516\n",
      "steps [3213/5000], loss:0.1396\n",
      "steps [3214/5000], loss:0.1572\n",
      "steps [3215/5000], loss:0.1520\n",
      "steps [3216/5000], loss:0.1607\n",
      "steps [3217/5000], loss:0.1529\n",
      "steps [3218/5000], loss:0.1820\n",
      "steps [3219/5000], loss:0.1556\n",
      "steps [3220/5000], loss:0.1445\n",
      "steps [3221/5000], loss:0.1725\n",
      "steps [3222/5000], loss:0.1418\n",
      "steps [3223/5000], loss:0.1534\n",
      "steps [3224/5000], loss:0.1524\n",
      "steps [3225/5000], loss:0.1342\n",
      "steps [3226/5000], loss:0.1543\n",
      "steps [3227/5000], loss:0.1480\n",
      "steps [3228/5000], loss:0.1338\n",
      "steps [3229/5000], loss:0.1559\n",
      "steps [3230/5000], loss:0.1564\n",
      "steps [3231/5000], loss:0.1460\n",
      "steps [3232/5000], loss:0.1513\n",
      "steps [3233/5000], loss:0.1693\n",
      "steps [3234/5000], loss:0.1594\n",
      "steps [3235/5000], loss:0.1696\n",
      "steps [3236/5000], loss:0.1492\n",
      "steps [3237/5000], loss:0.1465\n",
      "steps [3238/5000], loss:0.1582\n",
      "steps [3239/5000], loss:0.1285\n",
      "steps [3240/5000], loss:0.1365\n",
      "steps [3241/5000], loss:0.1399\n",
      "steps [3242/5000], loss:0.1499\n",
      "steps [3243/5000], loss:0.1449\n",
      "steps [3244/5000], loss:0.1649\n",
      "steps [3245/5000], loss:0.1463\n",
      "steps [3246/5000], loss:0.1440\n",
      "steps [3247/5000], loss:0.1594\n",
      "steps [3248/5000], loss:0.1441\n",
      "steps [3249/5000], loss:0.1631\n",
      "steps [3250/5000], loss:0.1600\n",
      "steps [3251/5000], loss:0.1419\n",
      "steps [3252/5000], loss:0.1688\n",
      "steps [3253/5000], loss:0.1344\n",
      "steps [3254/5000], loss:0.1572\n",
      "steps [3255/5000], loss:0.1482\n",
      "steps [3256/5000], loss:0.1546\n",
      "steps [3257/5000], loss:0.1453\n",
      "steps [3258/5000], loss:0.1625\n",
      "steps [3259/5000], loss:0.1376\n",
      "steps [3260/5000], loss:0.1647\n",
      "steps [3261/5000], loss:0.1469\n",
      "steps [3262/5000], loss:0.1692\n",
      "steps [3263/5000], loss:0.1471\n",
      "steps [3264/5000], loss:0.1681\n",
      "steps [3265/5000], loss:0.1439\n",
      "steps [3266/5000], loss:0.1498\n",
      "steps [3267/5000], loss:0.1305\n",
      "steps [3268/5000], loss:0.1718\n",
      "steps [3269/5000], loss:0.1423\n",
      "steps [3270/5000], loss:0.1533\n",
      "steps [3271/5000], loss:0.1530\n",
      "steps [3272/5000], loss:0.1428\n",
      "steps [3273/5000], loss:0.1331\n",
      "steps [3274/5000], loss:0.1431\n",
      "steps [3275/5000], loss:0.1277\n",
      "steps [3276/5000], loss:0.1509\n",
      "steps [3277/5000], loss:0.1562\n",
      "steps [3278/5000], loss:0.1450\n",
      "steps [3279/5000], loss:0.1493\n",
      "steps [3280/5000], loss:0.1330\n",
      "steps [3281/5000], loss:0.1427\n",
      "steps [3282/5000], loss:0.1667\n",
      "steps [3283/5000], loss:0.1329\n",
      "steps [3284/5000], loss:0.1377\n",
      "steps [3285/5000], loss:0.1493\n",
      "steps [3286/5000], loss:0.1505\n",
      "steps [3287/5000], loss:0.1535\n",
      "steps [3288/5000], loss:0.1486\n",
      "steps [3289/5000], loss:0.1724\n",
      "steps [3290/5000], loss:0.1536\n",
      "steps [3291/5000], loss:0.1478\n",
      "steps [3292/5000], loss:0.1352\n",
      "steps [3293/5000], loss:0.1433\n",
      "steps [3294/5000], loss:0.1537\n",
      "steps [3295/5000], loss:0.1446\n",
      "steps [3296/5000], loss:0.1460\n",
      "steps [3297/5000], loss:0.1435\n",
      "steps [3298/5000], loss:0.1498\n",
      "steps [3299/5000], loss:0.1284\n",
      "steps [3300/5000], loss:0.1586\n",
      "steps [3301/5000], loss:0.1463\n",
      "steps [3302/5000], loss:0.1408\n",
      "steps [3303/5000], loss:0.1290\n",
      "steps [3304/5000], loss:0.1329\n",
      "steps [3305/5000], loss:0.1379\n",
      "steps [3306/5000], loss:0.1491\n",
      "steps [3307/5000], loss:0.1652\n",
      "steps [3308/5000], loss:0.1516\n",
      "steps [3309/5000], loss:0.1501\n",
      "steps [3310/5000], loss:0.1475\n",
      "steps [3311/5000], loss:0.1544\n",
      "steps [3312/5000], loss:0.1424\n",
      "steps [3313/5000], loss:0.1444\n",
      "steps [3314/5000], loss:0.1489\n",
      "steps [3315/5000], loss:0.1335\n",
      "steps [3316/5000], loss:0.1558\n",
      "steps [3317/5000], loss:0.1532\n",
      "steps [3318/5000], loss:0.1547\n",
      "steps [3319/5000], loss:0.1625\n",
      "steps [3320/5000], loss:0.1363\n",
      "steps [3321/5000], loss:0.1346\n",
      "steps [3322/5000], loss:0.1492\n",
      "steps [3323/5000], loss:0.1452\n",
      "steps [3324/5000], loss:0.1460\n",
      "steps [3325/5000], loss:0.1502\n",
      "steps [3326/5000], loss:0.1445\n",
      "steps [3327/5000], loss:0.1553\n",
      "steps [3328/5000], loss:0.1481\n",
      "steps [3329/5000], loss:0.1646\n",
      "steps [3330/5000], loss:0.1523\n",
      "steps [3331/5000], loss:0.1457\n",
      "steps [3332/5000], loss:0.1596\n",
      "steps [3333/5000], loss:0.1338\n",
      "steps [3334/5000], loss:0.1467\n",
      "steps [3335/5000], loss:0.1458\n",
      "steps [3336/5000], loss:0.1425\n",
      "steps [3337/5000], loss:0.1371\n",
      "steps [3338/5000], loss:0.1494\n",
      "steps [3339/5000], loss:0.1320\n",
      "steps [3340/5000], loss:0.1445\n",
      "steps [3341/5000], loss:0.1563\n",
      "steps [3342/5000], loss:0.1373\n",
      "steps [3343/5000], loss:0.1509\n",
      "steps [3344/5000], loss:0.1459\n",
      "steps [3345/5000], loss:0.1526\n",
      "steps [3346/5000], loss:0.1600\n",
      "steps [3347/5000], loss:0.1322\n",
      "steps [3348/5000], loss:0.1460\n",
      "steps [3349/5000], loss:0.1667\n",
      "steps [3350/5000], loss:0.1451\n",
      "steps [3351/5000], loss:0.1409\n",
      "steps [3352/5000], loss:0.1585\n",
      "steps [3353/5000], loss:0.1392\n",
      "steps [3354/5000], loss:0.1591\n",
      "steps [3355/5000], loss:0.1285\n",
      "steps [3356/5000], loss:0.1375\n",
      "steps [3357/5000], loss:0.1390\n",
      "steps [3358/5000], loss:0.1380\n",
      "steps [3359/5000], loss:0.1404\n",
      "steps [3360/5000], loss:0.1460\n",
      "steps [3361/5000], loss:0.1275\n",
      "steps [3362/5000], loss:0.1431\n",
      "steps [3363/5000], loss:0.1615\n",
      "steps [3364/5000], loss:0.1401\n",
      "steps [3365/5000], loss:0.1539\n",
      "steps [3366/5000], loss:0.1678\n",
      "steps [3367/5000], loss:0.1501\n",
      "steps [3368/5000], loss:0.1396\n",
      "steps [3369/5000], loss:0.1501\n",
      "steps [3370/5000], loss:0.1411\n",
      "steps [3371/5000], loss:0.1447\n",
      "steps [3372/5000], loss:0.1523\n",
      "steps [3373/5000], loss:0.1313\n",
      "steps [3374/5000], loss:0.1398\n",
      "steps [3375/5000], loss:0.1365\n",
      "steps [3376/5000], loss:0.1288\n",
      "steps [3377/5000], loss:0.1395\n",
      "steps [3378/5000], loss:0.1574\n",
      "steps [3379/5000], loss:0.1554\n",
      "steps [3380/5000], loss:0.1459\n",
      "steps [3381/5000], loss:0.1819\n",
      "steps [3382/5000], loss:0.1640\n",
      "steps [3383/5000], loss:0.1379\n",
      "steps [3384/5000], loss:0.1649\n",
      "steps [3385/5000], loss:0.1642\n",
      "steps [3386/5000], loss:0.1416\n",
      "steps [3387/5000], loss:0.1454\n",
      "steps [3388/5000], loss:0.1427\n",
      "steps [3389/5000], loss:0.1452\n",
      "steps [3390/5000], loss:0.1248\n",
      "steps [3391/5000], loss:0.1338\n",
      "steps [3392/5000], loss:0.1389\n",
      "steps [3393/5000], loss:0.1421\n",
      "steps [3394/5000], loss:0.1430\n",
      "steps [3395/5000], loss:0.1463\n",
      "steps [3396/5000], loss:0.1548\n",
      "steps [3397/5000], loss:0.1518\n",
      "steps [3398/5000], loss:0.1503\n",
      "steps [3399/5000], loss:0.1398\n",
      "steps [3400/5000], loss:0.1448\n",
      "steps [3401/5000], loss:0.1345\n",
      "steps [3402/5000], loss:0.1413\n",
      "steps [3403/5000], loss:0.1394\n",
      "steps [3404/5000], loss:0.1465\n",
      "steps [3405/5000], loss:0.1323\n",
      "steps [3406/5000], loss:0.1497\n",
      "steps [3407/5000], loss:0.1327\n",
      "steps [3408/5000], loss:0.1236\n",
      "steps [3409/5000], loss:0.1550\n",
      "steps [3410/5000], loss:0.1410\n",
      "steps [3411/5000], loss:0.1491\n",
      "steps [3412/5000], loss:0.1417\n",
      "steps [3413/5000], loss:0.1337\n",
      "steps [3414/5000], loss:0.1470\n",
      "steps [3415/5000], loss:0.1412\n",
      "steps [3416/5000], loss:0.1538\n",
      "steps [3417/5000], loss:0.1652\n",
      "steps [3418/5000], loss:0.1425\n",
      "steps [3419/5000], loss:0.1715\n",
      "steps [3420/5000], loss:0.1768\n",
      "steps [3421/5000], loss:0.1788\n",
      "steps [3422/5000], loss:0.1391\n",
      "steps [3423/5000], loss:0.1761\n",
      "steps [3424/5000], loss:0.1508\n",
      "steps [3425/5000], loss:0.1566\n",
      "steps [3426/5000], loss:0.1734\n",
      "steps [3427/5000], loss:0.1327\n",
      "steps [3428/5000], loss:0.1511\n",
      "steps [3429/5000], loss:0.1299\n",
      "steps [3430/5000], loss:0.1375\n",
      "steps [3431/5000], loss:0.1263\n",
      "steps [3432/5000], loss:0.1582\n",
      "steps [3433/5000], loss:0.1365\n",
      "steps [3434/5000], loss:0.1360\n",
      "steps [3435/5000], loss:0.1720\n",
      "steps [3436/5000], loss:0.1447\n",
      "steps [3437/5000], loss:0.1699\n",
      "steps [3438/5000], loss:0.1343\n",
      "steps [3439/5000], loss:0.1442\n",
      "steps [3440/5000], loss:0.1521\n",
      "steps [3441/5000], loss:0.1538\n",
      "steps [3442/5000], loss:0.1515\n",
      "steps [3443/5000], loss:0.1265\n",
      "steps [3444/5000], loss:0.1374\n",
      "steps [3445/5000], loss:0.1319\n",
      "steps [3446/5000], loss:0.1429\n",
      "steps [3447/5000], loss:0.1435\n",
      "steps [3448/5000], loss:0.1485\n",
      "steps [3449/5000], loss:0.1462\n",
      "steps [3450/5000], loss:0.1731\n",
      "steps [3451/5000], loss:0.1508\n",
      "steps [3452/5000], loss:0.1395\n",
      "steps [3453/5000], loss:0.1420\n",
      "steps [3454/5000], loss:0.1343\n",
      "steps [3455/5000], loss:0.1355\n",
      "steps [3456/5000], loss:0.1551\n",
      "steps [3457/5000], loss:0.1431\n",
      "steps [3458/5000], loss:0.1487\n",
      "steps [3459/5000], loss:0.1572\n",
      "steps [3460/5000], loss:0.1281\n",
      "steps [3461/5000], loss:0.1575\n",
      "steps [3462/5000], loss:0.1346\n",
      "steps [3463/5000], loss:0.1359\n",
      "steps [3464/5000], loss:0.1297\n",
      "steps [3465/5000], loss:0.1389\n",
      "steps [3466/5000], loss:0.1390\n",
      "steps [3467/5000], loss:0.1378\n",
      "steps [3468/5000], loss:0.1358\n",
      "steps [3469/5000], loss:0.1422\n",
      "steps [3470/5000], loss:0.1553\n",
      "steps [3471/5000], loss:0.1392\n",
      "steps [3472/5000], loss:0.1382\n",
      "steps [3473/5000], loss:0.1413\n",
      "steps [3474/5000], loss:0.1229\n",
      "steps [3475/5000], loss:0.1448\n",
      "steps [3476/5000], loss:0.1351\n",
      "steps [3477/5000], loss:0.1429\n",
      "steps [3478/5000], loss:0.1403\n",
      "steps [3479/5000], loss:0.1549\n",
      "steps [3480/5000], loss:0.1488\n",
      "steps [3481/5000], loss:0.1265\n",
      "steps [3482/5000], loss:0.1300\n",
      "steps [3483/5000], loss:0.1338\n",
      "steps [3484/5000], loss:0.1450\n",
      "steps [3485/5000], loss:0.1428\n",
      "steps [3486/5000], loss:0.1518\n",
      "steps [3487/5000], loss:0.1588\n",
      "steps [3488/5000], loss:0.1309\n",
      "steps [3489/5000], loss:0.1802\n",
      "steps [3490/5000], loss:0.1448\n",
      "steps [3491/5000], loss:0.1915\n",
      "steps [3492/5000], loss:0.1327\n",
      "steps [3493/5000], loss:0.1409\n",
      "steps [3494/5000], loss:0.1601\n",
      "steps [3495/5000], loss:0.1376\n",
      "steps [3496/5000], loss:0.1321\n",
      "steps [3497/5000], loss:0.1275\n",
      "steps [3498/5000], loss:0.1484\n",
      "steps [3499/5000], loss:0.1380\n",
      "steps [3500/5000], loss:0.1397\n",
      "steps [3501/5000], loss:0.1364\n",
      "steps [3502/5000], loss:0.1468\n",
      "steps [3503/5000], loss:0.1586\n",
      "steps [3504/5000], loss:0.1459\n",
      "steps [3505/5000], loss:0.1517\n",
      "steps [3506/5000], loss:0.1430\n",
      "steps [3507/5000], loss:0.1514\n",
      "steps [3508/5000], loss:0.1430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [3509/5000], loss:0.1248\n",
      "steps [3510/5000], loss:0.1407\n",
      "steps [3511/5000], loss:0.1576\n",
      "steps [3512/5000], loss:0.1533\n",
      "steps [3513/5000], loss:0.1430\n",
      "steps [3514/5000], loss:0.1494\n",
      "steps [3515/5000], loss:0.1451\n",
      "steps [3516/5000], loss:0.1589\n",
      "steps [3517/5000], loss:0.1397\n",
      "steps [3518/5000], loss:0.1320\n",
      "steps [3519/5000], loss:0.1663\n",
      "steps [3520/5000], loss:0.1457\n",
      "steps [3521/5000], loss:0.1499\n",
      "steps [3522/5000], loss:0.1341\n",
      "steps [3523/5000], loss:0.1395\n",
      "steps [3524/5000], loss:0.1484\n",
      "steps [3525/5000], loss:0.1456\n",
      "steps [3526/5000], loss:0.1569\n",
      "steps [3527/5000], loss:0.1423\n",
      "steps [3528/5000], loss:0.1571\n",
      "steps [3529/5000], loss:0.1414\n",
      "steps [3530/5000], loss:0.1395\n",
      "steps [3531/5000], loss:0.1456\n",
      "steps [3532/5000], loss:0.1403\n",
      "steps [3533/5000], loss:0.1291\n",
      "steps [3534/5000], loss:0.1340\n",
      "steps [3535/5000], loss:0.1513\n",
      "steps [3536/5000], loss:0.1599\n",
      "steps [3537/5000], loss:0.1492\n",
      "steps [3538/5000], loss:0.1476\n",
      "steps [3539/5000], loss:0.1458\n",
      "steps [3540/5000], loss:0.1450\n",
      "steps [3541/5000], loss:0.1419\n",
      "steps [3542/5000], loss:0.1510\n",
      "steps [3543/5000], loss:0.1417\n",
      "steps [3544/5000], loss:0.1238\n",
      "steps [3545/5000], loss:0.1449\n",
      "steps [3546/5000], loss:0.1232\n",
      "steps [3547/5000], loss:0.1358\n",
      "steps [3548/5000], loss:0.1560\n",
      "steps [3549/5000], loss:0.1539\n",
      "steps [3550/5000], loss:0.1352\n",
      "steps [3551/5000], loss:0.1356\n",
      "steps [3552/5000], loss:0.1572\n",
      "steps [3553/5000], loss:0.1339\n",
      "steps [3554/5000], loss:0.1508\n",
      "steps [3555/5000], loss:0.1238\n",
      "steps [3556/5000], loss:0.1424\n",
      "steps [3557/5000], loss:0.1395\n",
      "steps [3558/5000], loss:0.1330\n",
      "steps [3559/5000], loss:0.1416\n",
      "steps [3560/5000], loss:0.1275\n",
      "steps [3561/5000], loss:0.1307\n",
      "steps [3562/5000], loss:0.1354\n",
      "steps [3563/5000], loss:0.1410\n",
      "steps [3564/5000], loss:0.1457\n",
      "steps [3565/5000], loss:0.1470\n",
      "steps [3566/5000], loss:0.1352\n",
      "steps [3567/5000], loss:0.1343\n",
      "steps [3568/5000], loss:0.1772\n",
      "steps [3569/5000], loss:0.1500\n",
      "steps [3570/5000], loss:0.1556\n",
      "steps [3571/5000], loss:0.1472\n",
      "steps [3572/5000], loss:0.1566\n",
      "steps [3573/5000], loss:0.1871\n",
      "steps [3574/5000], loss:0.1481\n",
      "steps [3575/5000], loss:0.1360\n",
      "steps [3576/5000], loss:0.1325\n",
      "steps [3577/5000], loss:0.1447\n",
      "steps [3578/5000], loss:0.1579\n",
      "steps [3579/5000], loss:0.1555\n",
      "steps [3580/5000], loss:0.1346\n",
      "steps [3581/5000], loss:0.1744\n",
      "steps [3582/5000], loss:0.1368\n",
      "steps [3583/5000], loss:0.1556\n",
      "steps [3584/5000], loss:0.1365\n",
      "steps [3585/5000], loss:0.1431\n",
      "steps [3586/5000], loss:0.1684\n",
      "steps [3587/5000], loss:0.1414\n",
      "steps [3588/5000], loss:0.1527\n",
      "steps [3589/5000], loss:0.1437\n",
      "steps [3590/5000], loss:0.1536\n",
      "steps [3591/5000], loss:0.1439\n",
      "steps [3592/5000], loss:0.1673\n",
      "steps [3593/5000], loss:0.1393\n",
      "steps [3594/5000], loss:0.1342\n",
      "steps [3595/5000], loss:0.1369\n",
      "steps [3596/5000], loss:0.1401\n",
      "steps [3597/5000], loss:0.1425\n",
      "steps [3598/5000], loss:0.1497\n",
      "steps [3599/5000], loss:0.1284\n",
      "steps [3600/5000], loss:0.1571\n",
      "steps [3601/5000], loss:0.1472\n",
      "steps [3602/5000], loss:0.1786\n",
      "steps [3603/5000], loss:0.1430\n",
      "steps [3604/5000], loss:0.1404\n",
      "steps [3605/5000], loss:0.1388\n",
      "steps [3606/5000], loss:0.1341\n",
      "steps [3607/5000], loss:0.1291\n",
      "steps [3608/5000], loss:0.1451\n",
      "steps [3609/5000], loss:0.1302\n",
      "steps [3610/5000], loss:0.1505\n",
      "steps [3611/5000], loss:0.1573\n",
      "steps [3612/5000], loss:0.1485\n",
      "steps [3613/5000], loss:0.1326\n",
      "steps [3614/5000], loss:0.1409\n",
      "steps [3615/5000], loss:0.1873\n",
      "steps [3616/5000], loss:0.1348\n",
      "steps [3617/5000], loss:0.1551\n",
      "steps [3618/5000], loss:0.1321\n",
      "steps [3619/5000], loss:0.1354\n",
      "steps [3620/5000], loss:0.1333\n",
      "steps [3621/5000], loss:0.1701\n",
      "steps [3622/5000], loss:0.1282\n",
      "steps [3623/5000], loss:0.1452\n",
      "steps [3624/5000], loss:0.1490\n",
      "steps [3625/5000], loss:0.1547\n",
      "steps [3626/5000], loss:0.1421\n",
      "steps [3627/5000], loss:0.1533\n",
      "steps [3628/5000], loss:0.1325\n",
      "steps [3629/5000], loss:0.1474\n",
      "steps [3630/5000], loss:0.1254\n",
      "steps [3631/5000], loss:0.1437\n",
      "steps [3632/5000], loss:0.1476\n",
      "steps [3633/5000], loss:0.1417\n",
      "steps [3634/5000], loss:0.1613\n",
      "steps [3635/5000], loss:0.1386\n",
      "steps [3636/5000], loss:0.1404\n",
      "steps [3637/5000], loss:0.1641\n",
      "steps [3638/5000], loss:0.1388\n",
      "steps [3639/5000], loss:0.1529\n",
      "steps [3640/5000], loss:0.1437\n",
      "steps [3641/5000], loss:0.1332\n",
      "steps [3642/5000], loss:0.1455\n",
      "steps [3643/5000], loss:0.1725\n",
      "steps [3644/5000], loss:0.1264\n",
      "steps [3645/5000], loss:0.1385\n",
      "steps [3646/5000], loss:0.1570\n",
      "steps [3647/5000], loss:0.1288\n",
      "steps [3648/5000], loss:0.1396\n",
      "steps [3649/5000], loss:0.1389\n",
      "steps [3650/5000], loss:0.1887\n",
      "steps [3651/5000], loss:0.1532\n",
      "steps [3652/5000], loss:0.1448\n",
      "steps [3653/5000], loss:0.1336\n",
      "steps [3654/5000], loss:0.1425\n",
      "steps [3655/5000], loss:0.1603\n",
      "steps [3656/5000], loss:0.1319\n",
      "steps [3657/5000], loss:0.1439\n",
      "steps [3658/5000], loss:0.1493\n",
      "steps [3659/5000], loss:0.1441\n",
      "steps [3660/5000], loss:0.1540\n",
      "steps [3661/5000], loss:0.1316\n",
      "steps [3662/5000], loss:0.1460\n",
      "steps [3663/5000], loss:0.1475\n",
      "steps [3664/5000], loss:0.1312\n",
      "steps [3665/5000], loss:0.1345\n",
      "steps [3666/5000], loss:0.1710\n",
      "steps [3667/5000], loss:0.1415\n",
      "steps [3668/5000], loss:0.1213\n",
      "steps [3669/5000], loss:0.1322\n",
      "steps [3670/5000], loss:0.1419\n",
      "steps [3671/5000], loss:0.1487\n",
      "steps [3672/5000], loss:0.1496\n",
      "steps [3673/5000], loss:0.1561\n",
      "steps [3674/5000], loss:0.1527\n",
      "steps [3675/5000], loss:0.1468\n",
      "steps [3676/5000], loss:0.1740\n",
      "steps [3677/5000], loss:0.1443\n",
      "steps [3678/5000], loss:0.1657\n",
      "steps [3679/5000], loss:0.1543\n",
      "steps [3680/5000], loss:0.1562\n",
      "steps [3681/5000], loss:0.1345\n",
      "steps [3682/5000], loss:0.1335\n",
      "steps [3683/5000], loss:0.1443\n",
      "steps [3684/5000], loss:0.1434\n",
      "steps [3685/5000], loss:0.1672\n",
      "steps [3686/5000], loss:0.1250\n",
      "steps [3687/5000], loss:0.1480\n",
      "steps [3688/5000], loss:0.1626\n",
      "steps [3689/5000], loss:0.1565\n",
      "steps [3690/5000], loss:0.1353\n",
      "steps [3691/5000], loss:0.1403\n",
      "steps [3692/5000], loss:0.1478\n",
      "steps [3693/5000], loss:0.1277\n",
      "steps [3694/5000], loss:0.1577\n",
      "steps [3695/5000], loss:0.1434\n",
      "steps [3696/5000], loss:0.1535\n",
      "steps [3697/5000], loss:0.1402\n",
      "steps [3698/5000], loss:0.1361\n",
      "steps [3699/5000], loss:0.1393\n",
      "steps [3700/5000], loss:0.1413\n",
      "steps [3701/5000], loss:0.1401\n",
      "steps [3702/5000], loss:0.1412\n",
      "steps [3703/5000], loss:0.1354\n",
      "steps [3704/5000], loss:0.1541\n",
      "steps [3705/5000], loss:0.1575\n",
      "steps [3706/5000], loss:0.1246\n",
      "steps [3707/5000], loss:0.1701\n",
      "steps [3708/5000], loss:0.1421\n",
      "steps [3709/5000], loss:0.1609\n",
      "steps [3710/5000], loss:0.1412\n",
      "steps [3711/5000], loss:0.1350\n",
      "steps [3712/5000], loss:0.1341\n",
      "steps [3713/5000], loss:0.1495\n",
      "steps [3714/5000], loss:0.1524\n",
      "steps [3715/5000], loss:0.1354\n",
      "steps [3716/5000], loss:0.1538\n",
      "steps [3717/5000], loss:0.1414\n",
      "steps [3718/5000], loss:0.1551\n",
      "steps [3719/5000], loss:0.1631\n",
      "steps [3720/5000], loss:0.1574\n",
      "steps [3721/5000], loss:0.1272\n",
      "steps [3722/5000], loss:0.1496\n",
      "steps [3723/5000], loss:0.1447\n",
      "steps [3724/5000], loss:0.1528\n",
      "steps [3725/5000], loss:0.1372\n",
      "steps [3726/5000], loss:0.1484\n",
      "steps [3727/5000], loss:0.1414\n",
      "steps [3728/5000], loss:0.1338\n",
      "steps [3729/5000], loss:0.1569\n",
      "steps [3730/5000], loss:0.1431\n",
      "steps [3731/5000], loss:0.1322\n",
      "steps [3732/5000], loss:0.1740\n",
      "steps [3733/5000], loss:0.1361\n",
      "steps [3734/5000], loss:0.1364\n",
      "steps [3735/5000], loss:0.1557\n",
      "steps [3736/5000], loss:0.1669\n",
      "steps [3737/5000], loss:0.1251\n",
      "steps [3738/5000], loss:0.1330\n",
      "steps [3739/5000], loss:0.1457\n",
      "steps [3740/5000], loss:0.1548\n",
      "steps [3741/5000], loss:0.1348\n",
      "steps [3742/5000], loss:0.1342\n",
      "steps [3743/5000], loss:0.1483\n",
      "steps [3744/5000], loss:0.1512\n",
      "steps [3745/5000], loss:0.1314\n",
      "steps [3746/5000], loss:0.1448\n",
      "steps [3747/5000], loss:0.1417\n",
      "steps [3748/5000], loss:0.1587\n",
      "steps [3749/5000], loss:0.1573\n",
      "steps [3750/5000], loss:0.1453\n",
      "steps [3751/5000], loss:0.1439\n",
      "steps [3752/5000], loss:0.1435\n",
      "steps [3753/5000], loss:0.1418\n",
      "steps [3754/5000], loss:0.1490\n",
      "steps [3755/5000], loss:0.1349\n",
      "steps [3756/5000], loss:0.1427\n",
      "steps [3757/5000], loss:0.1473\n",
      "steps [3758/5000], loss:0.1783\n",
      "steps [3759/5000], loss:0.1566\n",
      "steps [3760/5000], loss:0.1276\n",
      "steps [3761/5000], loss:0.1435\n",
      "steps [3762/5000], loss:0.1336\n",
      "steps [3763/5000], loss:0.1406\n",
      "steps [3764/5000], loss:0.1423\n",
      "steps [3765/5000], loss:0.1466\n",
      "steps [3766/5000], loss:0.1602\n",
      "steps [3767/5000], loss:0.1375\n",
      "steps [3768/5000], loss:0.1602\n",
      "steps [3769/5000], loss:0.1453\n",
      "steps [3770/5000], loss:0.1435\n",
      "steps [3771/5000], loss:0.1415\n",
      "steps [3772/5000], loss:0.1613\n",
      "steps [3773/5000], loss:0.1557\n",
      "steps [3774/5000], loss:0.1364\n",
      "steps [3775/5000], loss:0.1374\n",
      "steps [3776/5000], loss:0.1408\n",
      "steps [3777/5000], loss:0.1332\n",
      "steps [3778/5000], loss:0.1487\n",
      "steps [3779/5000], loss:0.1583\n",
      "steps [3780/5000], loss:0.1456\n",
      "steps [3781/5000], loss:0.1488\n",
      "steps [3782/5000], loss:0.1363\n",
      "steps [3783/5000], loss:0.1594\n",
      "steps [3784/5000], loss:0.1540\n",
      "steps [3785/5000], loss:0.1377\n",
      "steps [3786/5000], loss:0.1342\n",
      "steps [3787/5000], loss:0.1495\n",
      "steps [3788/5000], loss:0.1303\n",
      "steps [3789/5000], loss:0.1352\n",
      "steps [3790/5000], loss:0.1305\n",
      "steps [3791/5000], loss:0.1363\n",
      "steps [3792/5000], loss:0.1400\n",
      "steps [3793/5000], loss:0.1451\n",
      "steps [3794/5000], loss:0.1290\n",
      "steps [3795/5000], loss:0.1525\n",
      "steps [3796/5000], loss:0.1313\n",
      "steps [3797/5000], loss:0.1635\n",
      "steps [3798/5000], loss:0.1665\n",
      "steps [3799/5000], loss:0.1399\n",
      "steps [3800/5000], loss:0.1509\n",
      "steps [3801/5000], loss:0.1334\n",
      "steps [3802/5000], loss:0.1403\n",
      "steps [3803/5000], loss:0.1886\n",
      "steps [3804/5000], loss:0.1265\n",
      "steps [3805/5000], loss:0.1721\n",
      "steps [3806/5000], loss:0.1378\n",
      "steps [3807/5000], loss:0.1542\n",
      "steps [3808/5000], loss:0.1377\n",
      "steps [3809/5000], loss:0.1466\n",
      "steps [3810/5000], loss:0.1281\n",
      "steps [3811/5000], loss:0.1504\n",
      "steps [3812/5000], loss:0.1409\n",
      "steps [3813/5000], loss:0.1474\n",
      "steps [3814/5000], loss:0.1364\n",
      "steps [3815/5000], loss:0.1407\n",
      "steps [3816/5000], loss:0.1357\n",
      "steps [3817/5000], loss:0.1449\n",
      "steps [3818/5000], loss:0.1597\n",
      "steps [3819/5000], loss:0.1538\n",
      "steps [3820/5000], loss:0.1486\n",
      "steps [3821/5000], loss:0.1548\n",
      "steps [3822/5000], loss:0.1291\n",
      "steps [3823/5000], loss:0.1529\n",
      "steps [3824/5000], loss:0.1282\n",
      "steps [3825/5000], loss:0.1553\n",
      "steps [3826/5000], loss:0.1367\n",
      "steps [3827/5000], loss:0.1607\n",
      "steps [3828/5000], loss:0.1643\n",
      "steps [3829/5000], loss:0.1557\n",
      "steps [3830/5000], loss:0.1416\n",
      "steps [3831/5000], loss:0.1386\n",
      "steps [3832/5000], loss:0.1564\n",
      "steps [3833/5000], loss:0.1569\n",
      "steps [3834/5000], loss:0.1452\n",
      "steps [3835/5000], loss:0.1419\n",
      "steps [3836/5000], loss:0.1657\n",
      "steps [3837/5000], loss:0.1288\n",
      "steps [3838/5000], loss:0.1450\n",
      "steps [3839/5000], loss:0.1439\n",
      "steps [3840/5000], loss:0.1591\n",
      "steps [3841/5000], loss:0.1310\n",
      "steps [3842/5000], loss:0.1528\n",
      "steps [3843/5000], loss:0.1442\n",
      "steps [3844/5000], loss:0.1308\n",
      "steps [3845/5000], loss:0.1362\n",
      "steps [3846/5000], loss:0.1298\n",
      "steps [3847/5000], loss:0.1555\n",
      "steps [3848/5000], loss:0.1720\n",
      "steps [3849/5000], loss:0.1653\n",
      "steps [3850/5000], loss:0.1387\n",
      "steps [3851/5000], loss:0.1346\n",
      "steps [3852/5000], loss:0.1493\n",
      "steps [3853/5000], loss:0.1537\n",
      "steps [3854/5000], loss:0.1430\n",
      "steps [3855/5000], loss:0.1325\n",
      "steps [3856/5000], loss:0.1239\n",
      "steps [3857/5000], loss:0.1560\n",
      "steps [3858/5000], loss:0.1535\n",
      "steps [3859/5000], loss:0.1250\n",
      "steps [3860/5000], loss:0.1507\n",
      "steps [3861/5000], loss:0.1420\n",
      "steps [3862/5000], loss:0.1576\n",
      "steps [3863/5000], loss:0.1484\n",
      "steps [3864/5000], loss:0.1451\n",
      "steps [3865/5000], loss:0.1342\n",
      "steps [3866/5000], loss:0.1469\n",
      "steps [3867/5000], loss:0.1573\n",
      "steps [3868/5000], loss:0.1319\n",
      "steps [3869/5000], loss:0.1393\n",
      "steps [3870/5000], loss:0.1390\n",
      "steps [3871/5000], loss:0.1641\n",
      "steps [3872/5000], loss:0.1506\n",
      "steps [3873/5000], loss:0.1342\n",
      "steps [3874/5000], loss:0.1346\n",
      "steps [3875/5000], loss:0.1299\n",
      "steps [3876/5000], loss:0.1433\n",
      "steps [3877/5000], loss:0.1506\n",
      "steps [3878/5000], loss:0.1285\n",
      "steps [3879/5000], loss:0.1335\n",
      "steps [3880/5000], loss:0.1423\n",
      "steps [3881/5000], loss:0.1557\n",
      "steps [3882/5000], loss:0.1376\n",
      "steps [3883/5000], loss:0.1413\n",
      "steps [3884/5000], loss:0.1467\n",
      "steps [3885/5000], loss:0.1456\n",
      "steps [3886/5000], loss:0.1452\n",
      "steps [3887/5000], loss:0.1845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [3888/5000], loss:0.1385\n",
      "steps [3889/5000], loss:0.1401\n",
      "steps [3890/5000], loss:0.1592\n",
      "steps [3891/5000], loss:0.1469\n",
      "steps [3892/5000], loss:0.1364\n",
      "steps [3893/5000], loss:0.1285\n",
      "steps [3894/5000], loss:0.1405\n",
      "steps [3895/5000], loss:0.1365\n",
      "steps [3896/5000], loss:0.1546\n",
      "steps [3897/5000], loss:0.1580\n",
      "steps [3898/5000], loss:0.1673\n",
      "steps [3899/5000], loss:0.1539\n",
      "steps [3900/5000], loss:0.1419\n",
      "steps [3901/5000], loss:0.1396\n",
      "steps [3902/5000], loss:0.1416\n",
      "steps [3903/5000], loss:0.1568\n",
      "steps [3904/5000], loss:0.1383\n",
      "steps [3905/5000], loss:0.1433\n",
      "steps [3906/5000], loss:0.1500\n",
      "steps [3907/5000], loss:0.1599\n",
      "steps [3908/5000], loss:0.1411\n",
      "steps [3909/5000], loss:0.1461\n",
      "steps [3910/5000], loss:0.1584\n",
      "steps [3911/5000], loss:0.1586\n",
      "steps [3912/5000], loss:0.1418\n",
      "steps [3913/5000], loss:0.1531\n",
      "steps [3914/5000], loss:0.1774\n",
      "steps [3915/5000], loss:0.1619\n",
      "steps [3916/5000], loss:0.1228\n",
      "steps [3917/5000], loss:0.1391\n",
      "steps [3918/5000], loss:0.1325\n",
      "steps [3919/5000], loss:0.1445\n",
      "steps [3920/5000], loss:0.1555\n",
      "steps [3921/5000], loss:0.1403\n",
      "steps [3922/5000], loss:0.1393\n",
      "steps [3923/5000], loss:0.1467\n",
      "steps [3924/5000], loss:0.1566\n",
      "steps [3925/5000], loss:0.1426\n",
      "steps [3926/5000], loss:0.1403\n",
      "steps [3927/5000], loss:0.1499\n",
      "steps [3928/5000], loss:0.1358\n",
      "steps [3929/5000], loss:0.1497\n",
      "steps [3930/5000], loss:0.1478\n",
      "steps [3931/5000], loss:0.1480\n",
      "steps [3932/5000], loss:0.1605\n",
      "steps [3933/5000], loss:0.1475\n",
      "steps [3934/5000], loss:0.1400\n",
      "steps [3935/5000], loss:0.1300\n",
      "steps [3936/5000], loss:0.1441\n",
      "steps [3937/5000], loss:0.1413\n",
      "steps [3938/5000], loss:0.1480\n",
      "steps [3939/5000], loss:0.1477\n",
      "steps [3940/5000], loss:0.1489\n",
      "steps [3941/5000], loss:0.1661\n",
      "steps [3942/5000], loss:0.1472\n",
      "steps [3943/5000], loss:0.1383\n",
      "steps [3944/5000], loss:0.1460\n",
      "steps [3945/5000], loss:0.1324\n",
      "steps [3946/5000], loss:0.1596\n",
      "steps [3947/5000], loss:0.1375\n",
      "steps [3948/5000], loss:0.1559\n",
      "steps [3949/5000], loss:0.1398\n",
      "steps [3950/5000], loss:0.1459\n",
      "steps [3951/5000], loss:0.1263\n",
      "steps [3952/5000], loss:0.1497\n",
      "steps [3953/5000], loss:0.1417\n",
      "steps [3954/5000], loss:0.1367\n",
      "steps [3955/5000], loss:0.1452\n",
      "steps [3956/5000], loss:0.1396\n",
      "steps [3957/5000], loss:0.1394\n",
      "steps [3958/5000], loss:0.1358\n",
      "steps [3959/5000], loss:0.1337\n",
      "steps [3960/5000], loss:0.1367\n",
      "steps [3961/5000], loss:0.1369\n",
      "steps [3962/5000], loss:0.1378\n",
      "steps [3963/5000], loss:0.1446\n",
      "steps [3964/5000], loss:0.1478\n",
      "steps [3965/5000], loss:0.1650\n",
      "steps [3966/5000], loss:0.1411\n",
      "steps [3967/5000], loss:0.1318\n",
      "steps [3968/5000], loss:0.1481\n",
      "steps [3969/5000], loss:0.1625\n",
      "steps [3970/5000], loss:0.1516\n",
      "steps [3971/5000], loss:0.1511\n",
      "steps [3972/5000], loss:0.1374\n",
      "steps [3973/5000], loss:0.1323\n",
      "steps [3974/5000], loss:0.1491\n",
      "steps [3975/5000], loss:0.1363\n",
      "steps [3976/5000], loss:0.1657\n",
      "steps [3977/5000], loss:0.1456\n",
      "steps [3978/5000], loss:0.1458\n",
      "steps [3979/5000], loss:0.1650\n",
      "steps [3980/5000], loss:0.1384\n",
      "steps [3981/5000], loss:0.1495\n",
      "steps [3982/5000], loss:0.1399\n",
      "steps [3983/5000], loss:0.1407\n",
      "steps [3984/5000], loss:0.1405\n",
      "steps [3985/5000], loss:0.1443\n",
      "steps [3986/5000], loss:0.1383\n",
      "steps [3987/5000], loss:0.1362\n",
      "steps [3988/5000], loss:0.1426\n",
      "steps [3989/5000], loss:0.1377\n",
      "steps [3990/5000], loss:0.1530\n",
      "steps [3991/5000], loss:0.1393\n",
      "steps [3992/5000], loss:0.1877\n",
      "steps [3993/5000], loss:0.1438\n",
      "steps [3994/5000], loss:0.1276\n",
      "steps [3995/5000], loss:0.1528\n",
      "steps [3996/5000], loss:0.1431\n",
      "steps [3997/5000], loss:0.1366\n",
      "steps [3998/5000], loss:0.1529\n",
      "steps [3999/5000], loss:0.1518\n",
      "steps [4000/5000], loss:0.1401\n",
      "steps [4001/5000], loss:0.1275\n",
      "steps [4002/5000], loss:0.1632\n",
      "steps [4003/5000], loss:0.1567\n",
      "steps [4004/5000], loss:0.1320\n",
      "steps [4005/5000], loss:0.1338\n",
      "steps [4006/5000], loss:0.1485\n",
      "steps [4007/5000], loss:0.1407\n",
      "steps [4008/5000], loss:0.1556\n",
      "steps [4009/5000], loss:0.1413\n",
      "steps [4010/5000], loss:0.1340\n",
      "steps [4011/5000], loss:0.1435\n",
      "steps [4012/5000], loss:0.1456\n",
      "steps [4013/5000], loss:0.1578\n",
      "steps [4014/5000], loss:0.1668\n",
      "steps [4015/5000], loss:0.1362\n",
      "steps [4016/5000], loss:0.1673\n",
      "steps [4017/5000], loss:0.1326\n",
      "steps [4018/5000], loss:0.1441\n",
      "steps [4019/5000], loss:0.1504\n",
      "steps [4020/5000], loss:0.1467\n",
      "steps [4021/5000], loss:0.1340\n",
      "steps [4022/5000], loss:0.1410\n",
      "steps [4023/5000], loss:0.1670\n",
      "steps [4024/5000], loss:0.1475\n",
      "steps [4025/5000], loss:0.1410\n",
      "steps [4026/5000], loss:0.1310\n",
      "steps [4027/5000], loss:0.1289\n",
      "steps [4028/5000], loss:0.1465\n",
      "steps [4029/5000], loss:0.1507\n",
      "steps [4030/5000], loss:0.1362\n",
      "steps [4031/5000], loss:0.1318\n",
      "steps [4032/5000], loss:0.1503\n",
      "steps [4033/5000], loss:0.1583\n",
      "steps [4034/5000], loss:0.1645\n",
      "steps [4035/5000], loss:0.1374\n",
      "steps [4036/5000], loss:0.1476\n",
      "steps [4037/5000], loss:0.1583\n",
      "steps [4038/5000], loss:0.1325\n",
      "steps [4039/5000], loss:0.1368\n",
      "steps [4040/5000], loss:0.1259\n",
      "steps [4041/5000], loss:0.1254\n",
      "steps [4042/5000], loss:0.1566\n",
      "steps [4043/5000], loss:0.1605\n",
      "steps [4044/5000], loss:0.1369\n",
      "steps [4045/5000], loss:0.1463\n",
      "steps [4046/5000], loss:0.1392\n",
      "steps [4047/5000], loss:0.1455\n",
      "steps [4048/5000], loss:0.1368\n",
      "steps [4049/5000], loss:0.1454\n",
      "steps [4050/5000], loss:0.1332\n",
      "steps [4051/5000], loss:0.1852\n",
      "steps [4052/5000], loss:0.1391\n",
      "steps [4053/5000], loss:0.1329\n",
      "steps [4054/5000], loss:0.1538\n",
      "steps [4055/5000], loss:0.1359\n",
      "steps [4056/5000], loss:0.1414\n",
      "steps [4057/5000], loss:0.1489\n",
      "steps [4058/5000], loss:0.1506\n",
      "steps [4059/5000], loss:0.1288\n",
      "steps [4060/5000], loss:0.1300\n",
      "steps [4061/5000], loss:0.1493\n",
      "steps [4062/5000], loss:0.1488\n",
      "steps [4063/5000], loss:0.1270\n",
      "steps [4064/5000], loss:0.1367\n",
      "steps [4065/5000], loss:0.1531\n",
      "steps [4066/5000], loss:0.1537\n",
      "steps [4067/5000], loss:0.1409\n",
      "steps [4068/5000], loss:0.1301\n",
      "steps [4069/5000], loss:0.1383\n",
      "steps [4070/5000], loss:0.1228\n",
      "steps [4071/5000], loss:0.1537\n",
      "steps [4072/5000], loss:0.1370\n",
      "steps [4073/5000], loss:0.1299\n",
      "steps [4074/5000], loss:0.1394\n",
      "steps [4075/5000], loss:0.1573\n",
      "steps [4076/5000], loss:0.1549\n",
      "steps [4077/5000], loss:0.1336\n",
      "steps [4078/5000], loss:0.1519\n",
      "steps [4079/5000], loss:0.1420\n",
      "steps [4080/5000], loss:0.1600\n",
      "steps [4081/5000], loss:0.1593\n",
      "steps [4082/5000], loss:0.1516\n",
      "steps [4083/5000], loss:0.1441\n",
      "steps [4084/5000], loss:0.1374\n",
      "steps [4085/5000], loss:0.1709\n",
      "steps [4086/5000], loss:0.1523\n",
      "steps [4087/5000], loss:0.1678\n",
      "steps [4088/5000], loss:0.1473\n",
      "steps [4089/5000], loss:0.1276\n",
      "steps [4090/5000], loss:0.1417\n",
      "steps [4091/5000], loss:0.1322\n",
      "steps [4092/5000], loss:0.1601\n",
      "steps [4093/5000], loss:0.1675\n",
      "steps [4094/5000], loss:0.1306\n",
      "steps [4095/5000], loss:0.1309\n",
      "steps [4096/5000], loss:0.1277\n",
      "steps [4097/5000], loss:0.1525\n",
      "steps [4098/5000], loss:0.1321\n",
      "steps [4099/5000], loss:0.1512\n",
      "steps [4100/5000], loss:0.1596\n",
      "steps [4101/5000], loss:0.1440\n",
      "steps [4102/5000], loss:0.1419\n",
      "steps [4103/5000], loss:0.1404\n",
      "steps [4104/5000], loss:0.1313\n",
      "steps [4105/5000], loss:0.1317\n",
      "steps [4106/5000], loss:0.1482\n",
      "steps [4107/5000], loss:0.1400\n",
      "steps [4108/5000], loss:0.1384\n",
      "steps [4109/5000], loss:0.1518\n",
      "steps [4110/5000], loss:0.1438\n",
      "steps [4111/5000], loss:0.1308\n",
      "steps [4112/5000], loss:0.1519\n",
      "steps [4113/5000], loss:0.1350\n",
      "steps [4114/5000], loss:0.1378\n",
      "steps [4115/5000], loss:0.1511\n",
      "steps [4116/5000], loss:0.1435\n",
      "steps [4117/5000], loss:0.1504\n",
      "steps [4118/5000], loss:0.1545\n",
      "steps [4119/5000], loss:0.1389\n",
      "steps [4120/5000], loss:0.1573\n",
      "steps [4121/5000], loss:0.1394\n",
      "steps [4122/5000], loss:0.1494\n",
      "steps [4123/5000], loss:0.1315\n",
      "steps [4124/5000], loss:0.1499\n",
      "steps [4125/5000], loss:0.1330\n",
      "steps [4126/5000], loss:0.1333\n",
      "steps [4127/5000], loss:0.1455\n",
      "steps [4128/5000], loss:0.1396\n",
      "steps [4129/5000], loss:0.1245\n",
      "steps [4130/5000], loss:0.1298\n",
      "steps [4131/5000], loss:0.1408\n",
      "steps [4132/5000], loss:0.1336\n",
      "steps [4133/5000], loss:0.1425\n",
      "steps [4134/5000], loss:0.1316\n",
      "steps [4135/5000], loss:0.1615\n",
      "steps [4136/5000], loss:0.1310\n",
      "steps [4137/5000], loss:0.1423\n",
      "steps [4138/5000], loss:0.1250\n",
      "steps [4139/5000], loss:0.1389\n",
      "steps [4140/5000], loss:0.1658\n",
      "steps [4141/5000], loss:0.1339\n",
      "steps [4142/5000], loss:0.1461\n",
      "steps [4143/5000], loss:0.1420\n",
      "steps [4144/5000], loss:0.1336\n",
      "steps [4145/5000], loss:0.1439\n",
      "steps [4146/5000], loss:0.1325\n",
      "steps [4147/5000], loss:0.1369\n",
      "steps [4148/5000], loss:0.1415\n",
      "steps [4149/5000], loss:0.1498\n",
      "steps [4150/5000], loss:0.1311\n",
      "steps [4151/5000], loss:0.1533\n",
      "steps [4152/5000], loss:0.1707\n",
      "steps [4153/5000], loss:0.1550\n",
      "steps [4154/5000], loss:0.1563\n",
      "steps [4155/5000], loss:0.1285\n",
      "steps [4156/5000], loss:0.1545\n",
      "steps [4157/5000], loss:0.1501\n",
      "steps [4158/5000], loss:0.1248\n",
      "steps [4159/5000], loss:0.1336\n",
      "steps [4160/5000], loss:0.1678\n",
      "steps [4161/5000], loss:0.1460\n",
      "steps [4162/5000], loss:0.1386\n",
      "steps [4163/5000], loss:0.1383\n",
      "steps [4164/5000], loss:0.1381\n",
      "steps [4165/5000], loss:0.1270\n",
      "steps [4166/5000], loss:0.1305\n",
      "steps [4167/5000], loss:0.1379\n",
      "steps [4168/5000], loss:0.1343\n",
      "steps [4169/5000], loss:0.1254\n",
      "steps [4170/5000], loss:0.1504\n",
      "steps [4171/5000], loss:0.1559\n",
      "steps [4172/5000], loss:0.1578\n",
      "steps [4173/5000], loss:0.1458\n",
      "steps [4174/5000], loss:0.1632\n",
      "steps [4175/5000], loss:0.1279\n",
      "steps [4176/5000], loss:0.1510\n",
      "steps [4177/5000], loss:0.1487\n",
      "steps [4178/5000], loss:0.1678\n",
      "steps [4179/5000], loss:0.1401\n",
      "steps [4180/5000], loss:0.1391\n",
      "steps [4181/5000], loss:0.1509\n",
      "steps [4182/5000], loss:0.1436\n",
      "steps [4183/5000], loss:0.1437\n",
      "steps [4184/5000], loss:0.1446\n",
      "steps [4185/5000], loss:0.1477\n",
      "steps [4186/5000], loss:0.1496\n",
      "steps [4187/5000], loss:0.1419\n",
      "steps [4188/5000], loss:0.1426\n",
      "steps [4189/5000], loss:0.1439\n",
      "steps [4190/5000], loss:0.1396\n",
      "steps [4191/5000], loss:0.1506\n",
      "steps [4192/5000], loss:0.1525\n",
      "steps [4193/5000], loss:0.1428\n",
      "steps [4194/5000], loss:0.1578\n",
      "steps [4195/5000], loss:0.1633\n",
      "steps [4196/5000], loss:0.1496\n",
      "steps [4197/5000], loss:0.1430\n",
      "steps [4198/5000], loss:0.1651\n",
      "steps [4199/5000], loss:0.1410\n",
      "steps [4200/5000], loss:0.1468\n",
      "steps [4201/5000], loss:0.1433\n",
      "steps [4202/5000], loss:0.1399\n",
      "steps [4203/5000], loss:0.1591\n",
      "steps [4204/5000], loss:0.1285\n",
      "steps [4205/5000], loss:0.1525\n",
      "steps [4206/5000], loss:0.1384\n",
      "steps [4207/5000], loss:0.1324\n",
      "steps [4208/5000], loss:0.1597\n",
      "steps [4209/5000], loss:0.1935\n",
      "steps [4210/5000], loss:0.1561\n",
      "steps [4211/5000], loss:0.1389\n",
      "steps [4212/5000], loss:0.1291\n",
      "steps [4213/5000], loss:0.1645\n",
      "steps [4214/5000], loss:0.1627\n",
      "steps [4215/5000], loss:0.1483\n",
      "steps [4216/5000], loss:0.1502\n",
      "steps [4217/5000], loss:0.1280\n",
      "steps [4218/5000], loss:0.1338\n",
      "steps [4219/5000], loss:0.1633\n",
      "steps [4220/5000], loss:0.1312\n",
      "steps [4221/5000], loss:0.1678\n",
      "steps [4222/5000], loss:0.1478\n",
      "steps [4223/5000], loss:0.1463\n",
      "steps [4224/5000], loss:0.1514\n",
      "steps [4225/5000], loss:0.1742\n",
      "steps [4226/5000], loss:0.1299\n",
      "steps [4227/5000], loss:0.1451\n",
      "steps [4228/5000], loss:0.1306\n",
      "steps [4229/5000], loss:0.1487\n",
      "steps [4230/5000], loss:0.1380\n",
      "steps [4231/5000], loss:0.1427\n",
      "steps [4232/5000], loss:0.1438\n",
      "steps [4233/5000], loss:0.1358\n",
      "steps [4234/5000], loss:0.1305\n",
      "steps [4235/5000], loss:0.1426\n",
      "steps [4236/5000], loss:0.1448\n",
      "steps [4237/5000], loss:0.1770\n",
      "steps [4238/5000], loss:0.1711\n",
      "steps [4239/5000], loss:0.1543\n",
      "steps [4240/5000], loss:0.1513\n",
      "steps [4241/5000], loss:0.1690\n",
      "steps [4242/5000], loss:0.1456\n",
      "steps [4243/5000], loss:0.2029\n",
      "steps [4244/5000], loss:0.1629\n",
      "steps [4245/5000], loss:0.1300\n",
      "steps [4246/5000], loss:0.1547\n",
      "steps [4247/5000], loss:0.1568\n",
      "steps [4248/5000], loss:0.1497\n",
      "steps [4249/5000], loss:0.1423\n",
      "steps [4250/5000], loss:0.1489\n",
      "steps [4251/5000], loss:0.1309\n",
      "steps [4252/5000], loss:0.1480\n",
      "steps [4253/5000], loss:0.1761\n",
      "steps [4254/5000], loss:0.1531\n",
      "steps [4255/5000], loss:0.1474\n",
      "steps [4256/5000], loss:0.1344\n",
      "steps [4257/5000], loss:0.1410\n",
      "steps [4258/5000], loss:0.1511\n",
      "steps [4259/5000], loss:0.1473\n",
      "steps [4260/5000], loss:0.1463\n",
      "steps [4261/5000], loss:0.1578\n",
      "steps [4262/5000], loss:0.1593\n",
      "steps [4263/5000], loss:0.1542\n",
      "steps [4264/5000], loss:0.1651\n",
      "steps [4265/5000], loss:0.1711\n",
      "steps [4266/5000], loss:0.1807\n",
      "steps [4267/5000], loss:0.1493\n",
      "steps [4268/5000], loss:0.1532\n",
      "steps [4269/5000], loss:0.1435\n",
      "steps [4270/5000], loss:0.1432\n",
      "steps [4271/5000], loss:0.1417\n",
      "steps [4272/5000], loss:0.1431\n",
      "steps [4273/5000], loss:0.1543\n",
      "steps [4274/5000], loss:0.1426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [4275/5000], loss:0.1554\n",
      "steps [4276/5000], loss:0.1429\n",
      "steps [4277/5000], loss:0.1440\n",
      "steps [4278/5000], loss:0.1328\n",
      "steps [4279/5000], loss:0.1555\n",
      "steps [4280/5000], loss:0.1514\n",
      "steps [4281/5000], loss:0.1346\n",
      "steps [4282/5000], loss:0.1506\n",
      "steps [4283/5000], loss:0.1839\n",
      "steps [4284/5000], loss:0.1542\n",
      "steps [4285/5000], loss:0.1485\n",
      "steps [4286/5000], loss:0.1356\n",
      "steps [4287/5000], loss:0.1361\n",
      "steps [4288/5000], loss:0.1537\n",
      "steps [4289/5000], loss:0.1591\n",
      "steps [4290/5000], loss:0.1379\n",
      "steps [4291/5000], loss:0.1424\n",
      "steps [4292/5000], loss:0.1465\n",
      "steps [4293/5000], loss:0.1391\n",
      "steps [4294/5000], loss:0.1797\n",
      "steps [4295/5000], loss:0.1720\n",
      "steps [4296/5000], loss:0.1577\n",
      "steps [4297/5000], loss:0.1493\n",
      "steps [4298/5000], loss:0.1503\n",
      "steps [4299/5000], loss:0.1625\n",
      "steps [4300/5000], loss:0.1580\n",
      "steps [4301/5000], loss:0.1403\n",
      "steps [4302/5000], loss:0.1659\n",
      "steps [4303/5000], loss:0.1556\n",
      "steps [4304/5000], loss:0.1450\n",
      "steps [4305/5000], loss:0.1504\n",
      "steps [4306/5000], loss:0.1488\n",
      "steps [4307/5000], loss:0.1582\n",
      "steps [4308/5000], loss:0.1474\n",
      "steps [4309/5000], loss:0.1447\n",
      "steps [4310/5000], loss:0.1373\n",
      "steps [4311/5000], loss:0.1285\n",
      "steps [4312/5000], loss:0.1471\n",
      "steps [4313/5000], loss:0.1416\n",
      "steps [4314/5000], loss:0.1705\n",
      "steps [4315/5000], loss:0.1659\n",
      "steps [4316/5000], loss:0.1436\n",
      "steps [4317/5000], loss:0.1409\n",
      "steps [4318/5000], loss:0.1324\n",
      "steps [4319/5000], loss:0.1664\n",
      "steps [4320/5000], loss:0.1425\n",
      "steps [4321/5000], loss:0.1904\n",
      "steps [4322/5000], loss:0.1482\n",
      "steps [4323/5000], loss:0.1750\n",
      "steps [4324/5000], loss:0.1300\n",
      "steps [4325/5000], loss:0.1508\n",
      "steps [4326/5000], loss:0.1575\n",
      "steps [4327/5000], loss:0.1440\n",
      "steps [4328/5000], loss:0.1429\n",
      "steps [4329/5000], loss:0.1450\n",
      "steps [4330/5000], loss:0.1385\n",
      "steps [4331/5000], loss:0.1567\n",
      "steps [4332/5000], loss:0.1372\n",
      "steps [4333/5000], loss:0.1410\n",
      "steps [4334/5000], loss:0.1547\n",
      "steps [4335/5000], loss:0.1400\n",
      "steps [4336/5000], loss:0.1818\n",
      "steps [4337/5000], loss:0.1317\n",
      "steps [4338/5000], loss:0.1354\n",
      "steps [4339/5000], loss:0.1466\n",
      "steps [4340/5000], loss:0.1253\n",
      "steps [4341/5000], loss:0.1428\n",
      "steps [4342/5000], loss:0.1367\n",
      "steps [4343/5000], loss:0.1367\n",
      "steps [4344/5000], loss:0.1508\n",
      "steps [4345/5000], loss:0.1550\n",
      "steps [4346/5000], loss:0.1363\n",
      "steps [4347/5000], loss:0.1946\n",
      "steps [4348/5000], loss:0.1579\n",
      "steps [4349/5000], loss:0.1490\n",
      "steps [4350/5000], loss:0.1565\n",
      "steps [4351/5000], loss:0.1323\n",
      "steps [4352/5000], loss:0.1464\n",
      "steps [4353/5000], loss:0.1554\n",
      "steps [4354/5000], loss:0.1503\n",
      "steps [4355/5000], loss:0.1228\n",
      "steps [4356/5000], loss:0.1404\n",
      "steps [4357/5000], loss:0.1783\n",
      "steps [4358/5000], loss:0.1523\n",
      "steps [4359/5000], loss:0.1677\n",
      "steps [4360/5000], loss:0.1433\n",
      "steps [4361/5000], loss:0.1827\n",
      "steps [4362/5000], loss:0.1366\n",
      "steps [4363/5000], loss:0.1389\n",
      "steps [4364/5000], loss:0.1880\n",
      "steps [4365/5000], loss:0.1384\n",
      "steps [4366/5000], loss:0.1469\n",
      "steps [4367/5000], loss:0.1465\n",
      "steps [4368/5000], loss:0.1531\n",
      "steps [4369/5000], loss:0.1256\n",
      "steps [4370/5000], loss:0.1346\n",
      "steps [4371/5000], loss:0.1330\n",
      "steps [4372/5000], loss:0.1430\n",
      "steps [4373/5000], loss:0.1390\n",
      "steps [4374/5000], loss:0.1701\n",
      "steps [4375/5000], loss:0.1545\n",
      "steps [4376/5000], loss:0.1477\n",
      "steps [4377/5000], loss:0.1606\n",
      "steps [4378/5000], loss:0.1534\n",
      "steps [4379/5000], loss:0.1563\n",
      "steps [4380/5000], loss:0.1408\n",
      "steps [4381/5000], loss:0.1548\n",
      "steps [4382/5000], loss:0.1426\n",
      "steps [4383/5000], loss:0.1583\n",
      "steps [4384/5000], loss:0.1402\n",
      "steps [4385/5000], loss:0.1347\n",
      "steps [4386/5000], loss:0.1303\n",
      "steps [4387/5000], loss:0.1408\n",
      "steps [4388/5000], loss:0.1731\n",
      "steps [4389/5000], loss:0.1457\n",
      "steps [4390/5000], loss:0.1454\n",
      "steps [4391/5000], loss:0.1678\n",
      "steps [4392/5000], loss:0.1433\n",
      "steps [4393/5000], loss:0.1579\n",
      "steps [4394/5000], loss:0.1340\n",
      "steps [4395/5000], loss:0.1379\n",
      "steps [4396/5000], loss:0.1349\n",
      "steps [4397/5000], loss:0.1377\n",
      "steps [4398/5000], loss:0.1458\n",
      "steps [4399/5000], loss:0.1483\n",
      "steps [4400/5000], loss:0.1412\n",
      "steps [4401/5000], loss:0.1392\n",
      "steps [4402/5000], loss:0.1616\n",
      "steps [4403/5000], loss:0.1260\n",
      "steps [4404/5000], loss:0.1404\n",
      "steps [4405/5000], loss:0.1476\n",
      "steps [4406/5000], loss:0.1634\n",
      "steps [4407/5000], loss:0.1517\n",
      "steps [4408/5000], loss:0.1223\n",
      "steps [4409/5000], loss:0.1509\n",
      "steps [4410/5000], loss:0.1352\n",
      "steps [4411/5000], loss:0.1515\n",
      "steps [4412/5000], loss:0.1540\n",
      "steps [4413/5000], loss:0.1519\n",
      "steps [4414/5000], loss:0.1445\n",
      "steps [4415/5000], loss:0.1309\n",
      "steps [4416/5000], loss:0.1451\n",
      "steps [4417/5000], loss:0.1427\n",
      "steps [4418/5000], loss:0.1401\n",
      "steps [4419/5000], loss:0.1360\n",
      "steps [4420/5000], loss:0.1371\n",
      "steps [4421/5000], loss:0.1404\n",
      "steps [4422/5000], loss:0.1563\n",
      "steps [4423/5000], loss:0.1302\n",
      "steps [4424/5000], loss:0.1488\n",
      "steps [4425/5000], loss:0.1500\n",
      "steps [4426/5000], loss:0.1432\n",
      "steps [4427/5000], loss:0.1538\n",
      "steps [4428/5000], loss:0.1334\n",
      "steps [4429/5000], loss:0.1375\n",
      "steps [4430/5000], loss:0.1388\n",
      "steps [4431/5000], loss:0.1390\n",
      "steps [4432/5000], loss:0.1273\n",
      "steps [4433/5000], loss:0.1395\n",
      "steps [4434/5000], loss:0.1416\n",
      "steps [4435/5000], loss:0.1412\n",
      "steps [4436/5000], loss:0.1519\n",
      "steps [4437/5000], loss:0.1474\n",
      "steps [4438/5000], loss:0.1450\n",
      "steps [4439/5000], loss:0.1444\n",
      "steps [4440/5000], loss:0.1438\n",
      "steps [4441/5000], loss:0.1456\n",
      "steps [4442/5000], loss:0.1464\n",
      "steps [4443/5000], loss:0.1522\n",
      "steps [4444/5000], loss:0.1347\n",
      "steps [4445/5000], loss:0.1421\n",
      "steps [4446/5000], loss:0.1346\n",
      "steps [4447/5000], loss:0.1385\n",
      "steps [4448/5000], loss:0.1482\n",
      "steps [4449/5000], loss:0.1319\n",
      "steps [4450/5000], loss:0.1446\n",
      "steps [4451/5000], loss:0.1323\n",
      "steps [4452/5000], loss:0.1406\n",
      "steps [4453/5000], loss:0.1478\n",
      "steps [4454/5000], loss:0.1500\n",
      "steps [4455/5000], loss:0.1429\n",
      "steps [4456/5000], loss:0.1561\n",
      "steps [4457/5000], loss:0.1424\n",
      "steps [4458/5000], loss:0.1594\n",
      "steps [4459/5000], loss:0.1562\n",
      "steps [4460/5000], loss:0.1637\n",
      "steps [4461/5000], loss:0.1536\n",
      "steps [4462/5000], loss:0.1415\n",
      "steps [4463/5000], loss:0.1435\n",
      "steps [4464/5000], loss:0.1379\n",
      "steps [4465/5000], loss:0.1364\n",
      "steps [4466/5000], loss:0.1393\n",
      "steps [4467/5000], loss:0.1466\n",
      "steps [4468/5000], loss:0.1533\n",
      "steps [4469/5000], loss:0.1383\n",
      "steps [4470/5000], loss:0.1629\n",
      "steps [4471/5000], loss:0.1544\n",
      "steps [4472/5000], loss:0.1410\n",
      "steps [4473/5000], loss:0.1727\n",
      "steps [4474/5000], loss:0.1560\n",
      "steps [4475/5000], loss:0.1662\n",
      "steps [4476/5000], loss:0.1441\n",
      "steps [4477/5000], loss:0.1398\n",
      "steps [4478/5000], loss:0.1335\n",
      "steps [4479/5000], loss:0.1434\n",
      "steps [4480/5000], loss:0.1576\n",
      "steps [4481/5000], loss:0.1718\n",
      "steps [4482/5000], loss:0.1535\n",
      "steps [4483/5000], loss:0.1361\n",
      "steps [4484/5000], loss:0.1555\n",
      "steps [4485/5000], loss:0.1275\n",
      "steps [4486/5000], loss:0.1412\n",
      "steps [4487/5000], loss:0.1471\n",
      "steps [4488/5000], loss:0.1597\n",
      "steps [4489/5000], loss:0.1443\n",
      "steps [4490/5000], loss:0.1323\n",
      "steps [4491/5000], loss:0.1286\n",
      "steps [4492/5000], loss:0.1369\n",
      "steps [4493/5000], loss:0.1342\n",
      "steps [4494/5000], loss:0.1313\n",
      "steps [4495/5000], loss:0.1330\n",
      "steps [4496/5000], loss:0.1524\n",
      "steps [4497/5000], loss:0.1325\n",
      "steps [4498/5000], loss:0.1463\n",
      "steps [4499/5000], loss:0.1494\n",
      "steps [4500/5000], loss:0.1445\n",
      "steps [4501/5000], loss:0.1396\n",
      "steps [4502/5000], loss:0.1574\n",
      "steps [4503/5000], loss:0.1428\n",
      "steps [4504/5000], loss:0.1520\n",
      "steps [4505/5000], loss:0.1512\n",
      "steps [4506/5000], loss:0.1688\n",
      "steps [4507/5000], loss:0.1509\n",
      "steps [4508/5000], loss:0.1321\n",
      "steps [4509/5000], loss:0.1466\n",
      "steps [4510/5000], loss:0.1542\n",
      "steps [4511/5000], loss:0.1277\n",
      "steps [4512/5000], loss:0.1377\n",
      "steps [4513/5000], loss:0.1415\n",
      "steps [4514/5000], loss:0.1377\n",
      "steps [4515/5000], loss:0.1325\n",
      "steps [4516/5000], loss:0.1319\n",
      "steps [4517/5000], loss:0.1367\n",
      "steps [4518/5000], loss:0.1529\n",
      "steps [4519/5000], loss:0.1780\n",
      "steps [4520/5000], loss:0.1546\n",
      "steps [4521/5000], loss:0.1476\n",
      "steps [4522/5000], loss:0.1362\n",
      "steps [4523/5000], loss:0.1407\n",
      "steps [4524/5000], loss:0.1259\n",
      "steps [4525/5000], loss:0.1404\n",
      "steps [4526/5000], loss:0.1305\n",
      "steps [4527/5000], loss:0.1391\n",
      "steps [4528/5000], loss:0.1349\n",
      "steps [4529/5000], loss:0.1488\n",
      "steps [4530/5000], loss:0.1372\n",
      "steps [4531/5000], loss:0.1528\n",
      "steps [4532/5000], loss:0.1291\n",
      "steps [4533/5000], loss:0.1287\n",
      "steps [4534/5000], loss:0.1404\n",
      "steps [4535/5000], loss:0.1418\n",
      "steps [4536/5000], loss:0.1546\n",
      "steps [4537/5000], loss:0.1525\n",
      "steps [4538/5000], loss:0.1570\n",
      "steps [4539/5000], loss:0.1531\n",
      "steps [4540/5000], loss:0.1302\n",
      "steps [4541/5000], loss:0.1292\n",
      "steps [4542/5000], loss:0.1225\n",
      "steps [4543/5000], loss:0.1473\n",
      "steps [4544/5000], loss:0.1339\n",
      "steps [4545/5000], loss:0.1580\n",
      "steps [4546/5000], loss:0.1562\n",
      "steps [4547/5000], loss:0.1234\n",
      "steps [4548/5000], loss:0.1523\n",
      "steps [4549/5000], loss:0.1448\n",
      "steps [4550/5000], loss:0.1371\n",
      "steps [4551/5000], loss:0.1725\n",
      "steps [4552/5000], loss:0.1368\n",
      "steps [4553/5000], loss:0.1569\n",
      "steps [4554/5000], loss:0.1400\n",
      "steps [4555/5000], loss:0.1338\n",
      "steps [4556/5000], loss:0.1465\n",
      "steps [4557/5000], loss:0.1555\n",
      "steps [4558/5000], loss:0.1383\n",
      "steps [4559/5000], loss:0.1484\n",
      "steps [4560/5000], loss:0.1554\n",
      "steps [4561/5000], loss:0.1281\n",
      "steps [4562/5000], loss:0.1481\n",
      "steps [4563/5000], loss:0.1458\n",
      "steps [4564/5000], loss:0.1653\n",
      "steps [4565/5000], loss:0.1303\n",
      "steps [4566/5000], loss:0.1438\n",
      "steps [4567/5000], loss:0.1621\n",
      "steps [4568/5000], loss:0.1498\n",
      "steps [4569/5000], loss:0.1380\n",
      "steps [4570/5000], loss:0.1508\n",
      "steps [4571/5000], loss:0.1302\n",
      "steps [4572/5000], loss:0.1532\n",
      "steps [4573/5000], loss:0.1480\n",
      "steps [4574/5000], loss:0.1374\n",
      "steps [4575/5000], loss:0.1333\n",
      "steps [4576/5000], loss:0.1390\n",
      "steps [4577/5000], loss:0.1368\n",
      "steps [4578/5000], loss:0.1408\n",
      "steps [4579/5000], loss:0.1913\n",
      "steps [4580/5000], loss:0.1500\n",
      "steps [4581/5000], loss:0.1573\n",
      "steps [4582/5000], loss:0.1341\n",
      "steps [4583/5000], loss:0.1259\n",
      "steps [4584/5000], loss:0.1414\n",
      "steps [4585/5000], loss:0.1410\n",
      "steps [4586/5000], loss:0.1447\n",
      "steps [4587/5000], loss:0.1441\n",
      "steps [4588/5000], loss:0.1463\n",
      "steps [4589/5000], loss:0.1447\n",
      "steps [4590/5000], loss:0.1577\n",
      "steps [4591/5000], loss:0.1516\n",
      "steps [4592/5000], loss:0.1465\n",
      "steps [4593/5000], loss:0.1567\n",
      "steps [4594/5000], loss:0.1393\n",
      "steps [4595/5000], loss:0.1505\n",
      "steps [4596/5000], loss:0.1462\n",
      "steps [4597/5000], loss:0.1539\n",
      "steps [4598/5000], loss:0.1591\n",
      "steps [4599/5000], loss:0.1530\n",
      "steps [4600/5000], loss:0.1537\n",
      "steps [4601/5000], loss:0.1565\n",
      "steps [4602/5000], loss:0.1388\n",
      "steps [4603/5000], loss:0.1470\n",
      "steps [4604/5000], loss:0.1409\n",
      "steps [4605/5000], loss:0.1359\n",
      "steps [4606/5000], loss:0.1452\n",
      "steps [4607/5000], loss:0.1246\n",
      "steps [4608/5000], loss:0.1303\n",
      "steps [4609/5000], loss:0.1380\n",
      "steps [4610/5000], loss:0.1486\n",
      "steps [4611/5000], loss:0.1386\n",
      "steps [4612/5000], loss:0.1426\n",
      "steps [4613/5000], loss:0.1499\n",
      "steps [4614/5000], loss:0.1488\n",
      "steps [4615/5000], loss:0.1331\n",
      "steps [4616/5000], loss:0.1515\n",
      "steps [4617/5000], loss:0.1384\n",
      "steps [4618/5000], loss:0.1304\n",
      "steps [4619/5000], loss:0.1468\n",
      "steps [4620/5000], loss:0.1402\n",
      "steps [4621/5000], loss:0.1494\n",
      "steps [4622/5000], loss:0.1469\n",
      "steps [4623/5000], loss:0.1402\n",
      "steps [4624/5000], loss:0.1472\n",
      "steps [4625/5000], loss:0.1413\n",
      "steps [4626/5000], loss:0.1414\n",
      "steps [4627/5000], loss:0.1323\n",
      "steps [4628/5000], loss:0.1469\n",
      "steps [4629/5000], loss:0.1403\n",
      "steps [4630/5000], loss:0.1377\n",
      "steps [4631/5000], loss:0.1556\n",
      "steps [4632/5000], loss:0.1434\n",
      "steps [4633/5000], loss:0.1545\n",
      "steps [4634/5000], loss:0.1335\n",
      "steps [4635/5000], loss:0.1318\n",
      "steps [4636/5000], loss:0.1327\n",
      "steps [4637/5000], loss:0.1266\n",
      "steps [4638/5000], loss:0.1388\n",
      "steps [4639/5000], loss:0.1799\n",
      "steps [4640/5000], loss:0.1643\n",
      "steps [4641/5000], loss:0.1435\n",
      "steps [4642/5000], loss:0.1498\n",
      "steps [4643/5000], loss:0.1597\n",
      "steps [4644/5000], loss:0.1380\n",
      "steps [4645/5000], loss:0.1270\n",
      "steps [4646/5000], loss:0.1397\n",
      "steps [4647/5000], loss:0.1439\n",
      "steps [4648/5000], loss:0.1474\n",
      "steps [4649/5000], loss:0.1395\n",
      "steps [4650/5000], loss:0.1442\n",
      "steps [4651/5000], loss:0.1347\n",
      "steps [4652/5000], loss:0.1415\n",
      "steps [4653/5000], loss:0.1314\n",
      "steps [4654/5000], loss:0.1487\n",
      "steps [4655/5000], loss:0.1380\n",
      "steps [4656/5000], loss:0.1487\n",
      "steps [4657/5000], loss:0.1581\n",
      "steps [4658/5000], loss:0.1510\n",
      "steps [4659/5000], loss:0.1730\n",
      "steps [4660/5000], loss:0.1531\n",
      "steps [4661/5000], loss:0.1769\n",
      "steps [4662/5000], loss:0.1496\n",
      "steps [4663/5000], loss:0.1308\n",
      "steps [4664/5000], loss:0.1302\n",
      "steps [4665/5000], loss:0.1415\n",
      "steps [4666/5000], loss:0.1553\n",
      "steps [4667/5000], loss:0.1568\n",
      "steps [4668/5000], loss:0.1514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps [4669/5000], loss:0.1535\n",
      "steps [4670/5000], loss:0.1478\n",
      "steps [4671/5000], loss:0.1344\n",
      "steps [4672/5000], loss:0.1305\n",
      "steps [4673/5000], loss:0.1428\n",
      "steps [4674/5000], loss:0.1466\n",
      "steps [4675/5000], loss:0.1608\n",
      "steps [4676/5000], loss:0.1335\n",
      "steps [4677/5000], loss:0.1435\n",
      "steps [4678/5000], loss:0.1381\n",
      "steps [4679/5000], loss:0.1474\n",
      "steps [4680/5000], loss:0.1660\n",
      "steps [4681/5000], loss:0.1365\n",
      "steps [4682/5000], loss:0.1420\n",
      "steps [4683/5000], loss:0.1375\n",
      "steps [4684/5000], loss:0.1446\n",
      "steps [4685/5000], loss:0.1434\n",
      "steps [4686/5000], loss:0.1327\n",
      "steps [4687/5000], loss:0.1307\n",
      "steps [4688/5000], loss:0.1416\n",
      "steps [4689/5000], loss:0.1558\n",
      "steps [4690/5000], loss:0.1580\n",
      "steps [4691/5000], loss:0.1521\n",
      "steps [4692/5000], loss:0.1340\n",
      "steps [4693/5000], loss:0.1439\n",
      "steps [4694/5000], loss:0.1248\n",
      "steps [4695/5000], loss:0.1601\n",
      "steps [4696/5000], loss:0.1441\n",
      "steps [4697/5000], loss:0.1274\n",
      "steps [4698/5000], loss:0.1521\n",
      "steps [4699/5000], loss:0.1657\n",
      "steps [4700/5000], loss:0.1456\n",
      "steps [4701/5000], loss:0.1366\n",
      "steps [4702/5000], loss:0.1374\n",
      "steps [4703/5000], loss:0.1427\n",
      "steps [4704/5000], loss:0.1321\n",
      "steps [4705/5000], loss:0.1504\n",
      "steps [4706/5000], loss:0.1510\n",
      "steps [4707/5000], loss:0.1308\n",
      "steps [4708/5000], loss:0.1292\n",
      "steps [4709/5000], loss:0.1408\n",
      "steps [4710/5000], loss:0.1414\n",
      "steps [4711/5000], loss:0.1405\n",
      "steps [4712/5000], loss:0.1344\n",
      "steps [4713/5000], loss:0.1406\n",
      "steps [4714/5000], loss:0.1302\n",
      "steps [4715/5000], loss:0.1597\n",
      "steps [4716/5000], loss:0.1345\n",
      "steps [4717/5000], loss:0.1403\n",
      "steps [4718/5000], loss:0.1426\n",
      "steps [4719/5000], loss:0.1396\n",
      "steps [4720/5000], loss:0.1622\n",
      "steps [4721/5000], loss:0.1667\n",
      "steps [4722/5000], loss:0.1332\n",
      "steps [4723/5000], loss:0.1471\n",
      "steps [4724/5000], loss:0.1432\n",
      "steps [4725/5000], loss:0.1475\n",
      "steps [4726/5000], loss:0.1320\n",
      "steps [4727/5000], loss:0.1311\n",
      "steps [4728/5000], loss:0.1293\n",
      "steps [4729/5000], loss:0.1298\n",
      "steps [4730/5000], loss:0.1551\n",
      "steps [4731/5000], loss:0.1535\n",
      "steps [4732/5000], loss:0.1638\n",
      "steps [4733/5000], loss:0.1454\n",
      "steps [4734/5000], loss:0.1428\n",
      "steps [4735/5000], loss:0.1556\n",
      "steps [4736/5000], loss:0.1345\n",
      "steps [4737/5000], loss:0.1575\n",
      "steps [4738/5000], loss:0.1428\n",
      "steps [4739/5000], loss:0.1459\n",
      "steps [4740/5000], loss:0.1523\n",
      "steps [4741/5000], loss:0.1456\n",
      "steps [4742/5000], loss:0.1329\n",
      "steps [4743/5000], loss:0.1383\n",
      "steps [4744/5000], loss:0.1584\n",
      "steps [4745/5000], loss:0.1351\n",
      "steps [4746/5000], loss:0.1565\n",
      "steps [4747/5000], loss:0.1538\n",
      "steps [4748/5000], loss:0.1588\n",
      "steps [4749/5000], loss:0.1301\n",
      "steps [4750/5000], loss:0.1418\n",
      "steps [4751/5000], loss:0.1550\n",
      "steps [4752/5000], loss:0.1346\n",
      "steps [4753/5000], loss:0.1463\n",
      "steps [4754/5000], loss:0.1399\n",
      "steps [4755/5000], loss:0.1441\n",
      "steps [4756/5000], loss:0.1490\n",
      "steps [4757/5000], loss:0.1329\n",
      "steps [4758/5000], loss:0.1582\n",
      "steps [4759/5000], loss:0.1279\n",
      "steps [4760/5000], loss:0.1380\n",
      "steps [4761/5000], loss:0.1388\n",
      "steps [4762/5000], loss:0.1454\n",
      "steps [4763/5000], loss:0.1375\n",
      "steps [4764/5000], loss:0.1341\n",
      "steps [4765/5000], loss:0.1353\n",
      "steps [4766/5000], loss:0.1789\n",
      "steps [4767/5000], loss:0.1238\n",
      "steps [4768/5000], loss:0.1622\n",
      "steps [4769/5000], loss:0.1445\n",
      "steps [4770/5000], loss:0.1487\n",
      "steps [4771/5000], loss:0.1561\n",
      "steps [4772/5000], loss:0.1384\n",
      "steps [4773/5000], loss:0.1703\n",
      "steps [4774/5000], loss:0.1469\n",
      "steps [4775/5000], loss:0.1429\n",
      "steps [4776/5000], loss:0.1475\n",
      "steps [4777/5000], loss:0.1397\n",
      "steps [4778/5000], loss:0.1478\n",
      "steps [4779/5000], loss:0.1567\n",
      "steps [4780/5000], loss:0.1432\n",
      "steps [4781/5000], loss:0.1273\n",
      "steps [4782/5000], loss:0.1516\n",
      "steps [4783/5000], loss:0.1366\n",
      "steps [4784/5000], loss:0.1502\n",
      "steps [4785/5000], loss:0.1550\n",
      "steps [4786/5000], loss:0.1221\n",
      "steps [4787/5000], loss:0.1454\n",
      "steps [4788/5000], loss:0.1471\n",
      "steps [4789/5000], loss:0.1388\n",
      "steps [4790/5000], loss:0.1597\n",
      "steps [4791/5000], loss:0.1526\n",
      "steps [4792/5000], loss:0.1540\n",
      "steps [4793/5000], loss:0.1752\n",
      "steps [4794/5000], loss:0.1502\n",
      "steps [4795/5000], loss:0.1420\n",
      "steps [4796/5000], loss:0.1657\n",
      "steps [4797/5000], loss:0.1547\n",
      "steps [4798/5000], loss:0.1724\n",
      "steps [4799/5000], loss:0.1513\n",
      "steps [4800/5000], loss:0.1560\n",
      "steps [4801/5000], loss:0.1522\n",
      "steps [4802/5000], loss:0.1376\n",
      "steps [4803/5000], loss:0.1525\n",
      "steps [4804/5000], loss:0.1438\n",
      "steps [4805/5000], loss:0.1403\n",
      "steps [4806/5000], loss:0.1521\n",
      "steps [4807/5000], loss:0.1476\n",
      "steps [4808/5000], loss:0.1429\n",
      "steps [4809/5000], loss:0.1347\n",
      "steps [4810/5000], loss:0.1523\n",
      "steps [4811/5000], loss:0.1486\n",
      "steps [4812/5000], loss:0.1330\n",
      "steps [4813/5000], loss:0.1615\n",
      "steps [4814/5000], loss:0.1405\n",
      "steps [4815/5000], loss:0.1328\n",
      "steps [4816/5000], loss:0.1313\n",
      "steps [4817/5000], loss:0.1337\n",
      "steps [4818/5000], loss:0.1422\n",
      "steps [4819/5000], loss:0.1310\n",
      "steps [4820/5000], loss:0.1700\n",
      "steps [4821/5000], loss:0.1458\n",
      "steps [4822/5000], loss:0.1543\n",
      "steps [4823/5000], loss:0.1501\n",
      "steps [4824/5000], loss:0.1383\n",
      "steps [4825/5000], loss:0.1572\n",
      "steps [4826/5000], loss:0.1388\n",
      "steps [4827/5000], loss:0.1574\n",
      "steps [4828/5000], loss:0.1450\n",
      "steps [4829/5000], loss:0.1431\n",
      "steps [4830/5000], loss:0.1526\n",
      "steps [4831/5000], loss:0.1464\n",
      "steps [4832/5000], loss:0.1350\n",
      "steps [4833/5000], loss:0.1683\n",
      "steps [4834/5000], loss:0.1371\n",
      "steps [4835/5000], loss:0.1444\n",
      "steps [4836/5000], loss:0.1336\n",
      "steps [4837/5000], loss:0.1647\n",
      "steps [4838/5000], loss:0.1443\n",
      "steps [4839/5000], loss:0.1548\n",
      "steps [4840/5000], loss:0.1356\n",
      "steps [4841/5000], loss:0.1908\n",
      "steps [4842/5000], loss:0.1836\n",
      "steps [4843/5000], loss:0.1828\n",
      "steps [4844/5000], loss:0.1537\n",
      "steps [4845/5000], loss:0.1614\n",
      "steps [4846/5000], loss:0.1495\n",
      "steps [4847/5000], loss:0.1366\n",
      "steps [4848/5000], loss:0.1393\n",
      "steps [4849/5000], loss:0.1541\n",
      "steps [4850/5000], loss:0.1551\n",
      "steps [4851/5000], loss:0.1397\n",
      "steps [4852/5000], loss:0.1455\n",
      "steps [4853/5000], loss:0.1551\n",
      "steps [4854/5000], loss:0.1329\n",
      "steps [4855/5000], loss:0.1576\n",
      "steps [4856/5000], loss:0.1350\n",
      "steps [4857/5000], loss:0.1468\n",
      "steps [4858/5000], loss:0.1441\n",
      "steps [4859/5000], loss:0.1487\n",
      "steps [4860/5000], loss:0.1461\n",
      "steps [4861/5000], loss:0.1578\n",
      "steps [4862/5000], loss:0.1328\n",
      "steps [4863/5000], loss:0.1475\n",
      "steps [4864/5000], loss:0.1771\n",
      "steps [4865/5000], loss:0.1490\n",
      "steps [4866/5000], loss:0.1375\n",
      "steps [4867/5000], loss:0.1318\n",
      "steps [4868/5000], loss:0.1710\n",
      "steps [4869/5000], loss:0.1346\n",
      "steps [4870/5000], loss:0.1440\n",
      "steps [4871/5000], loss:0.1307\n",
      "steps [4872/5000], loss:0.1464\n",
      "steps [4873/5000], loss:0.1384\n",
      "steps [4874/5000], loss:0.1562\n",
      "steps [4875/5000], loss:0.1739\n",
      "steps [4876/5000], loss:0.1299\n",
      "steps [4877/5000], loss:0.1553\n",
      "steps [4878/5000], loss:0.1455\n",
      "steps [4879/5000], loss:0.1383\n",
      "steps [4880/5000], loss:0.1334\n",
      "steps [4881/5000], loss:0.1674\n",
      "steps [4882/5000], loss:0.1405\n",
      "steps [4883/5000], loss:0.1294\n",
      "steps [4884/5000], loss:0.1457\n",
      "steps [4885/5000], loss:0.1526\n",
      "steps [4886/5000], loss:0.1691\n",
      "steps [4887/5000], loss:0.1556\n",
      "steps [4888/5000], loss:0.1444\n",
      "steps [4889/5000], loss:0.1326\n",
      "steps [4890/5000], loss:0.1453\n",
      "steps [4891/5000], loss:0.1506\n",
      "steps [4892/5000], loss:0.1472\n",
      "steps [4893/5000], loss:0.1590\n",
      "steps [4894/5000], loss:0.1325\n",
      "steps [4895/5000], loss:0.1474\n",
      "steps [4896/5000], loss:0.1543\n",
      "steps [4897/5000], loss:0.1301\n",
      "steps [4898/5000], loss:0.1463\n",
      "steps [4899/5000], loss:0.1465\n",
      "steps [4900/5000], loss:0.1277\n",
      "steps [4901/5000], loss:0.1599\n",
      "steps [4902/5000], loss:0.1336\n",
      "steps [4903/5000], loss:0.1395\n",
      "steps [4904/5000], loss:0.1439\n",
      "steps [4905/5000], loss:0.1379\n",
      "steps [4906/5000], loss:0.1456\n",
      "steps [4907/5000], loss:0.1415\n",
      "steps [4908/5000], loss:0.1441\n",
      "steps [4909/5000], loss:0.1427\n",
      "steps [4910/5000], loss:0.1480\n",
      "steps [4911/5000], loss:0.1478\n",
      "steps [4912/5000], loss:0.1433\n",
      "steps [4913/5000], loss:0.1439\n",
      "steps [4914/5000], loss:0.1370\n",
      "steps [4915/5000], loss:0.1497\n",
      "steps [4916/5000], loss:0.1413\n",
      "steps [4917/5000], loss:0.1392\n",
      "steps [4918/5000], loss:0.1789\n",
      "steps [4919/5000], loss:0.1460\n",
      "steps [4920/5000], loss:0.1402\n",
      "steps [4921/5000], loss:0.1424\n",
      "steps [4922/5000], loss:0.1594\n",
      "steps [4923/5000], loss:0.1394\n",
      "steps [4924/5000], loss:0.1466\n",
      "steps [4925/5000], loss:0.1326\n",
      "steps [4926/5000], loss:0.1486\n",
      "steps [4927/5000], loss:0.1486\n",
      "steps [4928/5000], loss:0.1568\n",
      "steps [4929/5000], loss:0.1472\n",
      "steps [4930/5000], loss:0.1465\n",
      "steps [4931/5000], loss:0.1407\n",
      "steps [4932/5000], loss:0.1330\n",
      "steps [4933/5000], loss:0.1316\n",
      "steps [4934/5000], loss:0.1400\n",
      "steps [4935/5000], loss:0.1513\n",
      "steps [4936/5000], loss:0.1488\n",
      "steps [4937/5000], loss:0.1499\n",
      "steps [4938/5000], loss:0.1326\n",
      "steps [4939/5000], loss:0.1470\n",
      "steps [4940/5000], loss:0.1439\n",
      "steps [4941/5000], loss:0.1423\n",
      "steps [4942/5000], loss:0.1322\n",
      "steps [4943/5000], loss:0.1527\n",
      "steps [4944/5000], loss:0.1369\n",
      "steps [4945/5000], loss:0.1469\n",
      "steps [4946/5000], loss:0.1424\n",
      "steps [4947/5000], loss:0.1406\n",
      "steps [4948/5000], loss:0.1688\n",
      "steps [4949/5000], loss:0.1465\n",
      "steps [4950/5000], loss:0.1625\n",
      "steps [4951/5000], loss:0.1620\n",
      "steps [4952/5000], loss:0.1341\n",
      "steps [4953/5000], loss:0.1408\n",
      "steps [4954/5000], loss:0.1404\n",
      "steps [4955/5000], loss:0.1283\n",
      "steps [4956/5000], loss:0.1499\n",
      "steps [4957/5000], loss:0.1567\n",
      "steps [4958/5000], loss:0.1365\n",
      "steps [4959/5000], loss:0.1495\n",
      "steps [4960/5000], loss:0.1580\n",
      "steps [4961/5000], loss:0.1260\n",
      "steps [4962/5000], loss:0.1507\n",
      "steps [4963/5000], loss:0.1493\n",
      "steps [4964/5000], loss:0.1448\n",
      "steps [4965/5000], loss:0.1279\n",
      "steps [4966/5000], loss:0.1416\n",
      "steps [4967/5000], loss:0.1450\n",
      "steps [4968/5000], loss:0.1601\n",
      "steps [4969/5000], loss:0.1495\n",
      "steps [4970/5000], loss:0.1332\n",
      "steps [4971/5000], loss:0.1597\n",
      "steps [4972/5000], loss:0.1444\n",
      "steps [4973/5000], loss:0.1379\n",
      "steps [4974/5000], loss:0.1354\n",
      "steps [4975/5000], loss:0.1522\n",
      "steps [4976/5000], loss:0.1561\n",
      "steps [4977/5000], loss:0.1387\n",
      "steps [4978/5000], loss:0.1377\n",
      "steps [4979/5000], loss:0.1587\n",
      "steps [4980/5000], loss:0.1498\n",
      "steps [4981/5000], loss:0.1434\n",
      "steps [4982/5000], loss:0.1456\n",
      "steps [4983/5000], loss:0.1821\n",
      "steps [4984/5000], loss:0.1445\n",
      "steps [4985/5000], loss:0.1640\n",
      "steps [4986/5000], loss:0.1349\n",
      "steps [4987/5000], loss:0.1409\n",
      "steps [4988/5000], loss:0.1233\n",
      "steps [4989/5000], loss:0.1584\n",
      "steps [4990/5000], loss:0.1374\n",
      "steps [4991/5000], loss:0.1707\n",
      "steps [4992/5000], loss:0.1473\n",
      "steps [4993/5000], loss:0.1351\n",
      "steps [4994/5000], loss:0.1336\n",
      "steps [4995/5000], loss:0.1526\n",
      "steps [4996/5000], loss:0.1513\n",
      "steps [4997/5000], loss:0.1621\n",
      "steps [4998/5000], loss:0.1557\n",
      "steps [4999/5000], loss:0.1274\n",
      "steps [5000/5000], loss:0.1330\n"
     ]
    }
   ],
   "source": [
    "PPA = autoencoder()\n",
    "PPA.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "criterion.cuda()\n",
    "optimizer = torch.optim.Adam(\n",
    "    PPA.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for k in range(steps):\n",
    "    pos = np.random.randint(0,train_vector.shape[0] - batch_size+1)\n",
    "    data_train = torch.Tensor(train_vector[pos:pos+batch_size,:]).cuda()\n",
    "    # ===================forward=====================\n",
    "    data_reconstruction, _,_ = PPA(data_train)\n",
    "    loss = criterion(data_train, data_reconstruction)\n",
    "    # ===================backward====================\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # ===================log========================\n",
    "    if steps%100 == 0:\n",
    "        print('steps [{}/{}], loss:{:.4f}'.format(k + 1, steps, loss.item()))\n",
    "\n",
    "\n",
    "torch.save(PPA.state_dict(), './temp_result/PPA.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [gap_train,gap_valid,gap_test]:\n",
    "    for i in range(df.shape[0]):\n",
    "        _,_,first_ppa_vector = PPA(torch.Tensor(df.vector[i]-mean_vector).cuda())\n",
    "        first_ppa_vector = first_ppa_vector.cpu().data.numpy()\n",
    "        df.loc[i,\"vector\"]  = [first_ppa_vector]\n",
    "        df.loc[i,\"A_vector\"] = [first_ppa_vector[df.A_idx[i],:]]\n",
    "        df.loc[i,\"B_vector\"] = [first_ppa_vector[df.B_idx[i],:]]\n",
    "        df.loc[i,\"pron_vector\"] = [first_ppa_vector[df.pron_idx[i],:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train.to_pickle('./temp_result/train_kaggle_processed_PPA')\n",
    "gap_test.to_pickle('./temp_result/test_kaggle_processed_PPA')\n",
    "gap_valid.to_pickle('./temp_result/valid_kaggle_processed_PPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
