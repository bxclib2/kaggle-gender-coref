{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gap_train= pd.read_pickle('./temp_result/train_kaggle_processed_PPA_PCA_PPA')\n",
    "gap_test= pd.read_pickle('./temp_result/test_kaggle_processed_PPA_PCA_PPA')\n",
    "gap_valid= pd.read_pickle('./temp_result/valid_kaggle_processed_PPA_PCA_PPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import StanfordNERTagger\n",
    "st = StanfordNERTagger('stanford-ner/english.all.3class.distsim.crf.ser.gz', 'stanford-ner/stanford-ner.jar')\n",
    "\n",
    "def spans(txt):\n",
    "    span = []\n",
    "    tokens=nltk.word_tokenize(txt)\n",
    "    offset = 0\n",
    "    for token in tokens:\n",
    "        offset = txt.find(token, offset)\n",
    "        span.append((token, offset))\n",
    "    return tokens, span\n",
    "\n",
    "def extract_name(text):\n",
    "    tokens, span = spans(text)\n",
    "    name_span = []\n",
    "    tags = st.tag(tokens)\n",
    "    for ind, tag in enumerate(tags):\n",
    "        if tag[1]=='PERSON': \n",
    "            name_span.append(span[ind])\n",
    "    return name_span\n",
    "\n",
    "#test['name_index'] = test['Text'].apply(lambda x: extract_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>...</th>\n",
       "      <th>B_dist</th>\n",
       "      <th>A_pos</th>\n",
       "      <th>B_pos</th>\n",
       "      <th>pron_pos</th>\n",
       "      <th>A_idx</th>\n",
       "      <th>B_idx</th>\n",
       "      <th>pron_idx</th>\n",
       "      <th>A_vector</th>\n",
       "      <th>B_vector</th>\n",
       "      <th>pron_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>Upon their acceptance into the Kontinental Hoc...</td>\n",
       "      <td>His</td>\n",
       "      <td>383</td>\n",
       "      <td>Bob Suter</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "      <td>Dehner</td>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.464052</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>[96, 97, 98, 99]</td>\n",
       "      <td>[101, 102, 103]</td>\n",
       "      <td>[109]</td>\n",
       "      <td>[[-0.16258414, 0.7170149, -0.16182709, 0.33984...</td>\n",
       "      <td>[[0.46089026, 0.8022368, -0.26556754, 0.248125...</td>\n",
       "      <td>[[0.6202348, -0.49657542, 0.5204739, -0.727411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-2</td>\n",
       "      <td>Between the years 1979-1981, River won four lo...</td>\n",
       "      <td>him</td>\n",
       "      <td>430</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>353</td>\n",
       "      <td>True</td>\n",
       "      <td>Alfredo Di St*fano</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.253623</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.300725</td>\n",
       "      <td>[92, 93, 94]</td>\n",
       "      <td>[100, 101, 102, 103, 104, 105, 106, 107, 108]</td>\n",
       "      <td>[113]</td>\n",
       "      <td>[[-0.37001002, 0.51947534, 0.41240457, -0.0459...</td>\n",
       "      <td>[[0.66546816, 0.78631735, 0.57873654, 0.009659...</td>\n",
       "      <td>[[0.6709301, -0.5158502, 0.73226666, -0.564204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-3</td>\n",
       "      <td>Though his emigration from the country has aff...</td>\n",
       "      <td>He</td>\n",
       "      <td>312</td>\n",
       "      <td>Ali Aladhadh</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>Saddam</td>\n",
       "      <td>295</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>[63, 64, 65, 66, 67, 68]</td>\n",
       "      <td>[75, 76]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>[[-0.13203266, 1.3001504, 1.0933744, 0.0792686...</td>\n",
       "      <td>[[0.08869687, 0.7399757, -0.47687554, 0.293353...</td>\n",
       "      <td>[[0.37514523, -0.4730158, 0.10452151, -0.03368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test-4</td>\n",
       "      <td>At the trial, Pisciotta said: ``Those who have...</td>\n",
       "      <td>his</td>\n",
       "      <td>526</td>\n",
       "      <td>Alliata</td>\n",
       "      <td>377</td>\n",
       "      <td>False</td>\n",
       "      <td>Pisciotta</td>\n",
       "      <td>536</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.222951</td>\n",
       "      <td>0.321311</td>\n",
       "      <td>0.314754</td>\n",
       "      <td>[108, 109, 110]</td>\n",
       "      <td>[143, 144, 145, 146]</td>\n",
       "      <td>[141]</td>\n",
       "      <td>[[-0.43812943, 0.23181425, -1.1097318, 0.02765...</td>\n",
       "      <td>[[-0.76229733, -0.70085824, -0.23845942, -0.59...</td>\n",
       "      <td>[[0.6802153, -0.041674256, 0.36125743, 0.46846...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test-5</td>\n",
       "      <td>It is about a pair of United States Navy shore...</td>\n",
       "      <td>his</td>\n",
       "      <td>406</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>421</td>\n",
       "      <td>True</td>\n",
       "      <td>Rock Reilly</td>\n",
       "      <td>559</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.607527</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>[113, 114]</td>\n",
       "      <td>[142, 143, 144, 145]</td>\n",
       "      <td>[110]</td>\n",
       "      <td>[[-0.3663241, 1.0233932, -0.040710405, -1.4244...</td>\n",
       "      <td>[[1.2342895, -0.16074917, -0.08441551, 0.13165...</td>\n",
       "      <td>[[0.31947732, -0.5680447, 1.1254325, -0.703441...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Text Pronoun  \\\n",
       "0  test-1  Upon their acceptance into the Kontinental Hoc...     His   \n",
       "1  test-2  Between the years 1979-1981, River won four lo...     him   \n",
       "2  test-3  Though his emigration from the country has aff...      He   \n",
       "3  test-4  At the trial, Pisciotta said: ``Those who have...     his   \n",
       "4  test-5  It is about a pair of United States Navy shore...     his   \n",
       "\n",
       "   Pronoun-offset             A  A-offset  A-coref                   B  \\\n",
       "0             383     Bob Suter       352    False              Dehner   \n",
       "1             430        Alonso       353     True  Alfredo Di St*fano   \n",
       "2             312  Ali Aladhadh       256     True              Saddam   \n",
       "3             526       Alliata       377    False           Pisciotta   \n",
       "4             406         Eddie       421     True         Rock Reilly   \n",
       "\n",
       "   B-offset  B-coref  ... B_dist     A_pos     B_pos  pron_pos  \\\n",
       "0       366     True  ...  0.008  0.444444  0.464052  0.490196   \n",
       "1       390    False  ...  0.014  0.253623  0.275362  0.300725   \n",
       "2       295    False  ...  0.008  0.408333  0.475000  0.508333   \n",
       "3       536     True  ... -0.004  0.222951  0.321311  0.314754   \n",
       "4       559    False  ... -0.056  0.473118  0.607527  0.456989   \n",
       "\n",
       "                      A_idx                                          B_idx  \\\n",
       "0          [96, 97, 98, 99]                                [101, 102, 103]   \n",
       "1              [92, 93, 94]  [100, 101, 102, 103, 104, 105, 106, 107, 108]   \n",
       "2  [63, 64, 65, 66, 67, 68]                                       [75, 76]   \n",
       "3           [108, 109, 110]                           [143, 144, 145, 146]   \n",
       "4                [113, 114]                           [142, 143, 144, 145]   \n",
       "\n",
       "   pron_idx                                           A_vector  \\\n",
       "0     [109]  [[-0.16258414, 0.7170149, -0.16182709, 0.33984...   \n",
       "1     [113]  [[-0.37001002, 0.51947534, 0.41240457, -0.0459...   \n",
       "2      [81]  [[-0.13203266, 1.3001504, 1.0933744, 0.0792686...   \n",
       "3     [141]  [[-0.43812943, 0.23181425, -1.1097318, 0.02765...   \n",
       "4     [110]  [[-0.3663241, 1.0233932, -0.040710405, -1.4244...   \n",
       "\n",
       "                                            B_vector  \\\n",
       "0  [[0.46089026, 0.8022368, -0.26556754, 0.248125...   \n",
       "1  [[0.66546816, 0.78631735, 0.57873654, 0.009659...   \n",
       "2  [[0.08869687, 0.7399757, -0.47687554, 0.293353...   \n",
       "3  [[-0.76229733, -0.70085824, -0.23845942, -0.59...   \n",
       "4  [[1.2342895, -0.16074917, -0.08441551, 0.13165...   \n",
       "\n",
       "                                         pron_vector  \n",
       "0  [[0.6202348, -0.49657542, 0.5204739, -0.727411...  \n",
       "1  [[0.6709301, -0.5158502, 0.73226666, -0.564204...  \n",
       "2  [[0.37514523, -0.4730158, 0.10452151, -0.03368...  \n",
       "3  [[0.6802153, -0.041674256, 0.36125743, 0.46846...  \n",
       "4  [[0.31947732, -0.5680447, 1.1254325, -0.703441...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train['name_list'] = gap_train['Text'].apply(lambda x: extract_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_test['name_list'] = gap_test['Text'].apply(lambda x: extract_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_valid['name_list'] = gap_valid['Text'].apply(lambda x: extract_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_AB(name_list, A, B):\n",
    "    names = A.split(' ')+B.split(' ')\n",
    "    names = [n.lower() for n in names]\n",
    "    return [i for i in name_list if i[0].lower() not in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train['name_list_2']  =  gap_train.apply(lambda x:remove_AB(x['name_list'],x[\"A\"],x[\"B\"]),axis = 1)\n",
    "gap_valid['name_list_2']  =  gap_valid.apply(lambda x:remove_AB(x['name_list'],x[\"A\"],x[\"B\"]),axis = 1)\n",
    "gap_test['name_list_2']  =  gap_test.apply(lambda x:remove_AB(x['name_list'],x[\"A\"],x[\"B\"]),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_vector_index(name,offset,token_map):\n",
    "    name = \"\".join(name.lower().split(\" \"))\n",
    "    idx = 0\n",
    "    s = \"\"\n",
    "    res = []\n",
    "    for i in sorted(token_map.keys()):\n",
    "        idx = idx + 1\n",
    "        if i < offset:\n",
    "            continue\n",
    "        else:\n",
    "            s = s+token_map[i]\n",
    "            res.append(idx)\n",
    "            if s == name:\n",
    "                break\n",
    "    return np.array(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_vector_index(name_list,token_map):\n",
    "    idx = []\n",
    "    for (n,o) in name_list:\n",
    "        idx.extend(get_vector_index(n,o,token_map))\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train['neither_idx'] = gap_train.apply(lambda x: get_name_vector_index(x[\"name_list\"],x['token_map']), axis=1)\n",
    "gap_test['neither_idx'] = gap_test.apply(lambda x: get_name_vector_index(x[\"name_list\"],x['token_map']), axis=1)\n",
    "gap_valid['neither_idx'] = gap_valid.apply(lambda x: get_name_vector_index(x[\"name_list\"],x['token_map']), axis=1)\n",
    "\n",
    "gap_train['neither_idx_2'] = gap_train.apply(lambda x: get_name_vector_index(x[\"name_list_2\"],x['token_map']), axis=1)\n",
    "gap_test['neither_idx_2'] = gap_test.apply(lambda x: get_name_vector_index(x[\"name_list_2\"],x['token_map']), axis=1)\n",
    "gap_valid['neither_idx_2'] = gap_valid.apply(lambda x: get_name_vector_index(x[\"name_list_2\"],x['token_map']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_idx(idx_1,idx_2):\n",
    "    return sorted(set(idx_1)-set(idx_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train['neither_idx'] = gap_train.apply(lambda x: del_idx(x[\"neither_idx\"],x['pron_idx']), axis=1)\n",
    "gap_test['neither_idx'] = gap_test.apply(lambda x: del_idx(x[\"neither_idx\"],x['pron_idx']), axis=1)\n",
    "gap_valid['neither_idx'] = gap_valid.apply(lambda x: del_idx(x[\"neither_idx\"],x['pron_idx']), axis=1)\n",
    "\n",
    "gap_train['neither_idx_2'] = gap_train.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['pron_idx']), axis=1)\n",
    "gap_test['neither_idx_2'] = gap_test.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['pron_idx']), axis=1)\n",
    "gap_valid['neither_idx_2'] = gap_valid.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['pron_idx']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train['neither_idx'] = gap_train.apply(lambda x: del_idx(x[\"neither_idx\"],x['A_idx']), axis=1)\n",
    "gap_test['neither_idx'] = gap_test.apply(lambda x: del_idx(x[\"neither_idx\"],x['A_idx']), axis=1)\n",
    "gap_valid['neither_idx'] = gap_valid.apply(lambda x: del_idx(x[\"neither_idx\"],x['A_idx']), axis=1)\n",
    "\n",
    "gap_train['neither_idx_2'] = gap_train.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['A_idx']), axis=1)\n",
    "gap_test['neither_idx_2'] = gap_test.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['A_idx']), axis=1)\n",
    "gap_valid['neither_idx_2'] = gap_valid.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['A_idx']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train['neither_idx'] = gap_train.apply(lambda x: del_idx(x[\"neither_idx\"],x['B_idx']), axis=1)\n",
    "gap_test['neither_idx'] = gap_test.apply(lambda x: del_idx(x[\"neither_idx\"],x['B_idx']), axis=1)\n",
    "gap_valid['neither_idx'] = gap_valid.apply(lambda x: del_idx(x[\"neither_idx\"],x['B_idx']), axis=1)\n",
    "\n",
    "gap_train['neither_idx_2'] = gap_train.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['B_idx']), axis=1)\n",
    "gap_test['neither_idx_2'] = gap_test.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['B_idx']), axis=1)\n",
    "gap_valid['neither_idx_2'] = gap_valid.apply(lambda x: del_idx(x[\"neither_idx_2\"],x['B_idx']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train['neither_vector'] = gap_train.apply(lambda x: x[\"vector\"][x['neither_idx'],:], axis=1)\n",
    "gap_test['neither_vector'] = gap_test.apply(lambda x: x[\"vector\"][x['neither_idx'],:], axis=1)\n",
    "gap_valid['neither_vector'] = gap_valid.apply(lambda x: x[\"vector\"][x['neither_idx'],:], axis=1)\n",
    "\n",
    "gap_train['neither_vector_2'] = gap_train.apply(lambda x: x[\"vector\"][x['neither_idx_2'],:], axis=1)\n",
    "gap_test['neither_vector_2'] = gap_test.apply(lambda x: x[\"vector\"][x['neither_idx_2'],:], axis=1)\n",
    "gap_valid['neither_vector_2'] = gap_valid.apply(lambda x: x[\"vector\"][x['neither_idx_2'],:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train.to_pickle('./temp_result/train_kaggle_processed_PPA_PCA_PPA_neither')\n",
    "gap_test.to_pickle('./temp_result/test_kaggle_processed_PPA_PCA_PPA_neither')\n",
    "gap_valid.to_pickle('./temp_result/valid_kaggle_processed_PPA_PCA_PPA_neither')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
