{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train= pd.read_pickle('./temp_result/train_kaggle_processed_PPA_PCA_PPA')\n",
    "gap_test= pd.read_pickle('./temp_result/test_kaggle_processed_PPA_PCA_PPA')\n",
    "gap_valid= pd.read_pickle('./temp_result/valid_kaggle_processed_PPA_PCA_PPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(A,B):\n",
    "    if A is True:\n",
    "        return 0\n",
    "    if B is True:\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def compute_loss(sub_df,test_data):\n",
    "    pred = torch.Tensor(np.log(sub_df.loc[:,['A','B','NEITHER']].values))\n",
    "    label = torch.LongTensor(list(test_data.label))\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    loss_value = loss(pred,label).item()\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gap_train.drop(columns = ['ID', 'Text', 'Pronoun', 'vector','Pronoun-offset', 'A', 'A-offset',\n",
    "       'B', 'B-offset', 'URL', 'tokens', 'token_map',\n",
    "       'sentence_map','A_idx', 'B_idx', 'pron_idx'])\n",
    "train_data.A_vector = train_data.A_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "train_data.B_vector = train_data.B_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "train_data.pron_vector = train_data.pron_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "train_data[\"product_vector_A\"] = train_data.A_vector*train_data.pron_vector\n",
    "train_data[\"product_vector_B\"] = train_data.B_vector*train_data.pron_vector\n",
    "train_data[\"label\"] = train_data.apply(lambda x:label(x[\"A-coref\"],x[\"B-coref\"]),axis = 1)\n",
    "train_data = train_data.drop(columns= [\"A-coref\",\"B-coref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = gap_test.drop(columns = ['ID', 'Text', 'Pronoun', 'vector','Pronoun-offset', 'A', 'A-offset',\n",
    "       'B', 'B-offset', 'URL', 'tokens', 'token_map',\n",
    "       'sentence_map','A_idx', 'B_idx', 'pron_idx'])\n",
    "test_data.A_vector = test_data.A_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "test_data.B_vector = test_data.B_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "test_data.pron_vector = test_data.pron_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "test_data[\"product_vector_A\"] = test_data.A_vector*test_data.pron_vector\n",
    "test_data[\"product_vector_B\"] = test_data.B_vector*test_data.pron_vector\n",
    "test_data[\"label\"] = test_data.apply(lambda x:label(x[\"A-coref\"],x[\"B-coref\"]),axis = 1)\n",
    "test_data = test_data.drop(columns= [\"A-coref\",\"B-coref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = gap_valid.drop(columns = ['ID', 'Text', 'Pronoun', 'vector','Pronoun-offset', 'A', 'A-offset',\n",
    "       'B', 'B-offset', 'URL', 'tokens', 'token_map',\n",
    "       'sentence_map','A_idx', 'B_idx', 'pron_idx'])\n",
    "valid_data.A_vector = valid_data.A_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "valid_data.B_vector = valid_data.B_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "valid_data.pron_vector = valid_data.pron_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "valid_data[\"product_vector_A\"] = valid_data.A_vector*valid_data.pron_vector\n",
    "valid_data[\"product_vector_B\"] = valid_data.B_vector*valid_data.pron_vector\n",
    "valid_data[\"label\"] = valid_data.apply(lambda x:label(x[\"A-coref\"],x[\"B-coref\"]),axis = 1)\n",
    "valid_data = valid_data.drop(columns= [\"A-coref\",\"B-coref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_data.columns[:-1]\n",
    "X_train = np.concatenate([np.array(list(train_data[col])).reshape(train_data.shape[0],-1) for col in columns],axis = 1)\n",
    "y_train = list(train_data.label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.concatenate([np.array(list(valid_data[col])).reshape(valid_data.shape[0],-1) for col in columns],axis = 1)\n",
    "y_valid = list(valid_data.label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate([np.array(list(test_data[col])).reshape(test_data.shape[0],-1) for col in columns],axis = 1)\n",
    "y_test= list(test_data.label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_dist</th>\n",
       "      <th>B_dist</th>\n",
       "      <th>A_pos</th>\n",
       "      <th>B_pos</th>\n",
       "      <th>pron_pos</th>\n",
       "      <th>A_vector</th>\n",
       "      <th>B_vector</th>\n",
       "      <th>pron_vector</th>\n",
       "      <th>product_vector_A</th>\n",
       "      <th>product_vector_B</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.464052</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>[-0.16186124, 0.10288441, -0.13267949, 0.09381...</td>\n",
       "      <td>[0.46889028, 0.719243, -0.12934478, 0.2970564,...</td>\n",
       "      <td>[0.6202348, -0.49657542, 0.5204739, -0.7274118...</td>\n",
       "      <td>[-0.10039197, -0.051089868, -0.06905621, -0.06...</td>\n",
       "      <td>[0.29082206, -0.3571584, -0.06732058, -0.21608...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.253623</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.300725</td>\n",
       "      <td>[-0.1530692, -0.45684996, -0.10911498, -0.1501...</td>\n",
       "      <td>[0.38673186, 0.017928414, 0.034514368, 0.03494...</td>\n",
       "      <td>[0.6709301, -0.5158502, 0.73226666, -0.5642047...</td>\n",
       "      <td>[-0.10269873, 0.23566614, -0.07990126, 0.08469...</td>\n",
       "      <td>[0.25947005, -0.009248376, 0.025273722, -0.019...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>[0.15905416, 0.3745935, 0.068947755, 0.3243495...</td>\n",
       "      <td>[0.14589697, 0.29442316, -0.3740158, 0.4216888...</td>\n",
       "      <td>[0.37514523, -0.4730158, 0.10452151, -0.033686...</td>\n",
       "      <td>[0.05966841, -0.17718863, 0.007206524, -0.0109...</td>\n",
       "      <td>[0.054732554, -0.1392668, -0.039092697, -0.014...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.222951</td>\n",
       "      <td>0.321311</td>\n",
       "      <td>0.314754</td>\n",
       "      <td>[0.05937913, 0.2836007, -0.36608246, 0.7199421...</td>\n",
       "      <td>[-0.6133348, -0.49770007, -0.5726678, 0.862215...</td>\n",
       "      <td>[0.6802153, -0.041674256, 0.36125743, 0.468463...</td>\n",
       "      <td>[0.040390592, -0.011818848, -0.13225001, 0.337...</td>\n",
       "      <td>[-0.4171997, 0.02074128, -0.2068805, 0.4039163...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.607527</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>[0.19817783, 0.30553705, 0.70740294, -1.038957...</td>\n",
       "      <td>[-0.02850709, -0.038969748, 0.3848874, -0.7527...</td>\n",
       "      <td>[0.31947732, -0.5680447, 1.1254325, -0.7034413...</td>\n",
       "      <td>[0.06331332, -0.17355871, 0.79613423, 0.730845...</td>\n",
       "      <td>[-0.009107368, 0.02213656, 0.43316478, 0.52953...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A_dist  B_dist     A_pos     B_pos  pron_pos  \\\n",
       "0   0.014   0.008  0.444444  0.464052  0.490196   \n",
       "1   0.026   0.014  0.253623  0.275362  0.300725   \n",
       "2   0.024   0.008  0.408333  0.475000  0.508333   \n",
       "3   0.056  -0.004  0.222951  0.321311  0.314754   \n",
       "4  -0.006  -0.056  0.473118  0.607527  0.456989   \n",
       "\n",
       "                                            A_vector  \\\n",
       "0  [-0.16186124, 0.10288441, -0.13267949, 0.09381...   \n",
       "1  [-0.1530692, -0.45684996, -0.10911498, -0.1501...   \n",
       "2  [0.15905416, 0.3745935, 0.068947755, 0.3243495...   \n",
       "3  [0.05937913, 0.2836007, -0.36608246, 0.7199421...   \n",
       "4  [0.19817783, 0.30553705, 0.70740294, -1.038957...   \n",
       "\n",
       "                                            B_vector  \\\n",
       "0  [0.46889028, 0.719243, -0.12934478, 0.2970564,...   \n",
       "1  [0.38673186, 0.017928414, 0.034514368, 0.03494...   \n",
       "2  [0.14589697, 0.29442316, -0.3740158, 0.4216888...   \n",
       "3  [-0.6133348, -0.49770007, -0.5726678, 0.862215...   \n",
       "4  [-0.02850709, -0.038969748, 0.3848874, -0.7527...   \n",
       "\n",
       "                                         pron_vector  \\\n",
       "0  [0.6202348, -0.49657542, 0.5204739, -0.7274118...   \n",
       "1  [0.6709301, -0.5158502, 0.73226666, -0.5642047...   \n",
       "2  [0.37514523, -0.4730158, 0.10452151, -0.033686...   \n",
       "3  [0.6802153, -0.041674256, 0.36125743, 0.468463...   \n",
       "4  [0.31947732, -0.5680447, 1.1254325, -0.7034413...   \n",
       "\n",
       "                                    product_vector_A  \\\n",
       "0  [-0.10039197, -0.051089868, -0.06905621, -0.06...   \n",
       "1  [-0.10269873, 0.23566614, -0.07990126, 0.08469...   \n",
       "2  [0.05966841, -0.17718863, 0.007206524, -0.0109...   \n",
       "3  [0.040390592, -0.011818848, -0.13225001, 0.337...   \n",
       "4  [0.06331332, -0.17355871, 0.79613423, 0.730845...   \n",
       "\n",
       "                                    product_vector_B  label  \n",
       "0  [0.29082206, -0.3571584, -0.06732058, -0.21608...      1  \n",
       "1  [0.25947005, -0.009248376, 0.025273722, -0.019...      0  \n",
       "2  [0.054732554, -0.1392668, -0.039092697, -0.014...      0  \n",
       "3  [-0.4171997, 0.02074128, -0.2068805, 0.4039163...      1  \n",
       "4  [-0.009107368, 0.02213656, 0.43316478, 0.52953...      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pickle\n",
    "f = open( \"./temp_result/base_model_data_PPA\", \"wb\" )\n",
    "pickle.dump(X_train,  f)\n",
    "pickle.dump(y_train,  f)\n",
    "pickle.dump(X_valid,  f)\n",
    "pickle.dump(y_valid,  f)\n",
    "pickle.dump(X_test,  f)\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bao/anaconda3/envs/EPFL/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pred_lr = lr.predict_proba(X_test)\n",
    "\n",
    "sub_df = pd.read_csv(\"./test_and_submit/sample_submission_stage_1.csv\")\n",
    "sub_df.loc[:, ['A','B','NEITHER']] = pred_lr\n",
    "\n",
    "sub_df.head()\n",
    "\n",
    "\n",
    "sub_df.to_csv(\"./test_and_submit/submission+model+lr@\"+str(datetime.datetime.now())+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9079073667526245"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(sub_df,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(C = 7.0,verbose=True,probability = True,gamma = \"auto\").fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pred_svm = svm.predict_proba(X_test)\n",
    "\n",
    "sub_df = pd.read_csv(\"./test_and_submit/sample_submission_stage_1.csv\")\n",
    "sub_df.loc[:, ['A','B','NEITHER']] = pred_svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>0.750300</td>\n",
       "      <td>0.175348</td>\n",
       "      <td>0.074353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>0.785681</td>\n",
       "      <td>0.117283</td>\n",
       "      <td>0.097036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>0.046601</td>\n",
       "      <td>0.928087</td>\n",
       "      <td>0.025312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>0.035881</td>\n",
       "      <td>0.763022</td>\n",
       "      <td>0.201097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>0.027071</td>\n",
       "      <td>0.786711</td>\n",
       "      <td>0.186218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID         A         B   NEITHER\n",
       "0  development-1  0.750300  0.175348  0.074353\n",
       "1  development-2  0.785681  0.117283  0.097036\n",
       "2  development-3  0.046601  0.928087  0.025312\n",
       "3  development-4  0.035881  0.763022  0.201097\n",
       "4  development-5  0.027071  0.786711  0.186218"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.to_csv(\"./test_and_submit/submission+model+svm@\"+str(datetime.datetime.now())+\".csv\", index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5227930545806885"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(sub_df,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
