{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_train= pd.read_pickle('./temp_result/train_kaggle_processed_PPA_PCA_PPA')\n",
    "gap_test= pd.read_pickle('./temp_result/test_kaggle_processed_PPA_PCA_PPA')\n",
    "gap_valid= pd.read_pickle('./temp_result/valid_kaggle_processed_PPA_PCA_PPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = gap_train.count().values[0]\n",
    "NUM_TEST = gap_test.count().values[0]\n",
    "NUM_VALID = gap_valid.count().values[0]\n",
    "def label(A,B):\n",
    "    if A is True:\n",
    "        return 0\n",
    "    if B is True:\n",
    "        return 1\n",
    "    return 2\n",
    "def switch_label(l):\n",
    "    if l==2:\n",
    "        return 2\n",
    "    return 1-l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prediction(pred):\n",
    "    s = pred.shape[0]//2\n",
    "    pred0 = pred[0:s,:]\n",
    "    pred1 = pred[s:,:]\n",
    "    pred1 = pred1[:,[1,0,2]]\n",
    "    pred_out = pred0+pred1\n",
    "    return pred_out/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_A_B(df):\n",
    "    columnsTitles = [\"B_dist\",\"A_dist\",\"B_pos\", \"A_pos\",\"pron_pos\", \"B_vector\", \"A_vector\",\"pron_vector\",\"product_vector_B\",\"product_vector_A\",\"label\"]\n",
    "    df2=df.reindex(columns=columnsTitles).copy()\n",
    "    df2.columns = df.columns\n",
    "    df2.label = df2.label.map(switch_label)\n",
    "    return pd.concat([df,df2],axis = 0, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def compute_loss(sub_df,test_data):\n",
    "    pred = torch.Tensor(np.log(sub_df.loc[:,['A','B','NEITHER']].values))\n",
    "    label = torch.LongTensor(list(test_data.label))\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    loss_value = loss(pred,label).item()\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gap_train.drop(columns = ['ID', 'Text', 'Pronoun', 'vector','Pronoun-offset', 'A', 'A-offset',\n",
    "       'B', 'B-offset', 'URL', 'tokens', 'token_map',\n",
    "       'sentence_map','A_idx', 'B_idx', 'pron_idx'])\n",
    "train_data.A_vector = train_data.A_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "train_data.B_vector = train_data.B_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "train_data.pron_vector = train_data.pron_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "train_data[\"product_vector_A\"] = train_data.A_vector*train_data.pron_vector\n",
    "train_data[\"product_vector_B\"] = train_data.B_vector*train_data.pron_vector\n",
    "train_data[\"label\"] = train_data.apply(lambda x:label(x[\"A-coref\"],x[\"B-coref\"]),axis = 1)\n",
    "train_data = train_data.drop(columns= [\"A-coref\",\"B-coref\"])\n",
    "#train_data = switch_A_B(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = gap_test.drop(columns = ['ID', 'Text', 'Pronoun', 'vector','Pronoun-offset', 'A', 'A-offset',\n",
    "       'B', 'B-offset', 'URL', 'tokens', 'token_map',\n",
    "       'sentence_map','A_idx', 'B_idx', 'pron_idx'])\n",
    "test_data.A_vector = test_data.A_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "test_data.B_vector = test_data.B_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "test_data.pron_vector = test_data.pron_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "test_data[\"product_vector_A\"] = test_data.A_vector*test_data.pron_vector\n",
    "test_data[\"product_vector_B\"] = test_data.B_vector*test_data.pron_vector\n",
    "test_data[\"label\"] = test_data.apply(lambda x:label(x[\"A-coref\"],x[\"B-coref\"]),axis = 1)\n",
    "test_data = test_data.drop(columns= [\"A-coref\",\"B-coref\"])\n",
    "#test_data = switch_A_B(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = gap_valid.drop(columns = ['ID', 'Text', 'Pronoun', 'vector','Pronoun-offset', 'A', 'A-offset',\n",
    "       'B', 'B-offset', 'URL', 'tokens', 'token_map',\n",
    "       'sentence_map','A_idx', 'B_idx', 'pron_idx'])\n",
    "valid_data.A_vector = valid_data.A_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "valid_data.B_vector = valid_data.B_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "valid_data.pron_vector = valid_data.pron_vector.map(lambda x:np.mean(x,axis = 0))\n",
    "valid_data[\"product_vector_A\"] = valid_data.A_vector*valid_data.pron_vector\n",
    "valid_data[\"product_vector_B\"] = valid_data.B_vector*valid_data.pron_vector\n",
    "valid_data[\"label\"] = valid_data.apply(lambda x:label(x[\"A-coref\"],x[\"B-coref\"]),axis = 1)\n",
    "valid_data = valid_data.drop(columns= [\"A-coref\",\"B-coref\"])\n",
    "#valid_data = switch_A_B(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_data.columns[:-1]\n",
    "X_train = np.concatenate([np.array(list(train_data[col])).reshape(train_data.shape[0],-1) for col in columns],axis = 1)\n",
    "y_train = list(train_data.label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.concatenate([np.array(list(valid_data[col])).reshape(valid_data.shape[0],-1) for col in columns],axis = 1)\n",
    "y_valid = list(valid_data.label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate([np.array(list(test_data[col])).reshape(test_data.shape[0],-1) for col in columns],axis = 1)\n",
    "y_test= list(test_data.label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\nf = open( \"./temp_result/base_model_data_PPA\", \"wb\" )\\npickle.dump(X_train,  f)\\npickle.dump(y_train,  f)\\npickle.dump(X_valid,  f)\\npickle.dump(y_valid,  f)\\npickle.dump(X_test,  f)\\nf.close()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pickle\n",
    "f = open( \"./temp_result/base_model_data_PPA\", \"wb\" )\n",
    "pickle.dump(X_train,  f)\n",
    "pickle.dump(y_train,  f)\n",
    "pickle.dump(X_valid,  f)\n",
    "pickle.dump(y_valid,  f)\n",
    "pickle.dump(X_test,  f)\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bao/anaconda3/envs/EPFL/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>0.879443</td>\n",
       "      <td>0.108679</td>\n",
       "      <td>0.011878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>0.991720</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.998309</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.995328</td>\n",
       "      <td>0.004644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID         A         B   NEITHER\n",
       "0  development-1  0.879443  0.108679  0.011878\n",
       "1  development-2  0.991720  0.005467  0.002814\n",
       "2  development-3  0.001668  0.998309  0.000023\n",
       "3  development-4  0.000127  0.996551  0.003321\n",
       "4  development-5  0.000028  0.995328  0.004644"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred_lr = process_prediction(pred_lr)\n",
    "sub_df = pd.read_csv(\"./test_and_submit/sample_submission_stage_1.csv\")\n",
    "sub_df.loc[:, ['A','B','NEITHER']] = pred_lr\n",
    "\n",
    "\n",
    "sub_df.to_csv(\"./test_and_submit/submission+model+lr@\"+str(datetime.datetime.now())+\".csv\", index=False)\n",
    "\n",
    "sub_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9079073667526245"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(sub_df,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(C = 7.0,verbose=True,probability = True,gamma = \"auto\",class_weight='balanced').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pred_svm = process_prediction(pred_svm)\n",
    "sub_df = pd.read_csv(\"./test_and_submit/sample_submission_stage_1.csv\")\n",
    "sub_df.loc[:, ['A','B','NEITHER']] = pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>0.752101</td>\n",
       "      <td>0.195995</td>\n",
       "      <td>0.051904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>0.838148</td>\n",
       "      <td>0.107213</td>\n",
       "      <td>0.054640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>0.049593</td>\n",
       "      <td>0.914481</td>\n",
       "      <td>0.035926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0.776955</td>\n",
       "      <td>0.183611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>0.015716</td>\n",
       "      <td>0.876834</td>\n",
       "      <td>0.107450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID         A         B   NEITHER\n",
       "0  development-1  0.752101  0.195995  0.051904\n",
       "1  development-2  0.838148  0.107213  0.054640\n",
       "2  development-3  0.049593  0.914481  0.035926\n",
       "3  development-4  0.039434  0.776955  0.183611\n",
       "4  development-5  0.015716  0.876834  0.107450"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.to_csv(\"./test_and_submit/submission+model+svm@\"+str(datetime.datetime.now())+\".csv\", index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5225053429603577"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(sub_df,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(256*5+5, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.95),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.layers[0].weight)\n",
    "        nn.init.xavier_uniform_(self.layers[-1].weight)\n",
    "    def forward(self, x):\n",
    "        # convert tensor (128, 1, 28, 28) --> (128, 1*28*28)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "batch_size = 25\n",
    "mlp = MLP()\n",
    "mlp.cuda()\n",
    "opt = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()#weight = torch.Tensor([1.0,1.0,5.0]))\n",
    "loss_fn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/500], loss:1.5481\n",
      "epoch [2/500], loss:1.8961\n",
      "epoch [3/500], loss:1.3744\n",
      "epoch [4/500], loss:1.4813\n",
      "epoch [5/500], loss:1.1083\n",
      "epoch [6/500], loss:1.2670\n",
      "epoch [7/500], loss:1.0930\n",
      "epoch [8/500], loss:1.1345\n",
      "epoch [9/500], loss:1.0744\n",
      "epoch [10/500], loss:0.9804\n",
      "epoch [11/500], loss:1.0118\n",
      "epoch [12/500], loss:1.0424\n",
      "epoch [13/500], loss:0.8997\n",
      "epoch [14/500], loss:1.0369\n",
      "epoch [15/500], loss:1.0362\n",
      "epoch [16/500], loss:1.0892\n",
      "epoch [17/500], loss:1.0274\n",
      "epoch [18/500], loss:0.8648\n",
      "epoch [19/500], loss:0.8517\n",
      "epoch [20/500], loss:0.9612\n",
      "epoch [21/500], loss:0.9658\n",
      "epoch [22/500], loss:0.9300\n",
      "epoch [23/500], loss:0.9222\n",
      "epoch [24/500], loss:0.9510\n",
      "epoch [25/500], loss:0.9712\n",
      "epoch [26/500], loss:0.9282\n",
      "epoch [27/500], loss:0.8033\n",
      "epoch [28/500], loss:0.8551\n",
      "epoch [29/500], loss:0.8404\n",
      "epoch [30/500], loss:0.8997\n",
      "epoch [31/500], loss:0.8047\n",
      "epoch [32/500], loss:0.8740\n",
      "epoch [33/500], loss:0.9786\n",
      "epoch [34/500], loss:0.8112\n",
      "epoch [35/500], loss:0.9154\n",
      "epoch [36/500], loss:0.9585\n",
      "epoch [37/500], loss:0.9044\n",
      "epoch [38/500], loss:0.8276\n",
      "epoch [39/500], loss:0.8785\n",
      "epoch [40/500], loss:0.8806\n",
      "epoch [41/500], loss:0.7215\n",
      "epoch [42/500], loss:0.9814\n",
      "epoch [43/500], loss:0.8541\n",
      "epoch [44/500], loss:0.8557\n",
      "epoch [45/500], loss:0.7924\n",
      "epoch [46/500], loss:0.8272\n",
      "epoch [47/500], loss:0.8333\n",
      "epoch [48/500], loss:0.8250\n",
      "epoch [49/500], loss:0.8596\n",
      "epoch [50/500], loss:0.8367\n",
      "epoch [51/500], loss:0.9245\n",
      "epoch [52/500], loss:0.7472\n",
      "epoch [53/500], loss:0.8510\n",
      "epoch [54/500], loss:0.8010\n",
      "epoch [55/500], loss:0.8988\n",
      "epoch [56/500], loss:0.8535\n",
      "epoch [57/500], loss:0.8489\n",
      "epoch [58/500], loss:0.7673\n",
      "epoch [59/500], loss:0.8144\n",
      "epoch [60/500], loss:0.8306\n",
      "epoch [61/500], loss:0.7420\n",
      "epoch [62/500], loss:0.7299\n",
      "epoch [63/500], loss:0.9289\n",
      "epoch [64/500], loss:0.8785\n",
      "epoch [65/500], loss:0.6850\n",
      "epoch [66/500], loss:0.8841\n",
      "epoch [67/500], loss:0.8929\n",
      "epoch [68/500], loss:0.9527\n",
      "epoch [69/500], loss:0.8025\n",
      "epoch [70/500], loss:0.8241\n",
      "epoch [71/500], loss:0.8263\n",
      "epoch [72/500], loss:0.8614\n",
      "epoch [73/500], loss:0.8454\n",
      "epoch [74/500], loss:0.8681\n",
      "epoch [75/500], loss:0.8159\n",
      "epoch [76/500], loss:0.8479\n",
      "epoch [77/500], loss:0.8919\n",
      "epoch [78/500], loss:0.9370\n",
      "epoch [79/500], loss:0.8045\n",
      "epoch [80/500], loss:0.7384\n",
      "epoch [81/500], loss:0.8182\n",
      "epoch [82/500], loss:0.8968\n",
      "epoch [83/500], loss:0.7902\n",
      "epoch [84/500], loss:0.8518\n",
      "epoch [85/500], loss:0.8174\n",
      "epoch [86/500], loss:0.7194\n",
      "epoch [87/500], loss:0.7866\n",
      "epoch [88/500], loss:0.8102\n",
      "epoch [89/500], loss:0.7840\n",
      "epoch [90/500], loss:0.8105\n",
      "epoch [91/500], loss:0.7835\n",
      "epoch [92/500], loss:0.7239\n",
      "epoch [93/500], loss:0.9584\n",
      "epoch [94/500], loss:0.9188\n",
      "epoch [95/500], loss:0.7656\n",
      "epoch [96/500], loss:0.8027\n",
      "epoch [97/500], loss:0.9024\n",
      "epoch [98/500], loss:0.7126\n",
      "epoch [99/500], loss:0.8326\n",
      "epoch [100/500], loss:0.8636\n",
      "epoch [101/500], loss:0.7510\n",
      "epoch [102/500], loss:0.8928\n",
      "epoch [103/500], loss:0.9058\n",
      "epoch [104/500], loss:0.8500\n",
      "epoch [105/500], loss:0.8834\n",
      "epoch [106/500], loss:0.8399\n",
      "epoch [107/500], loss:0.7215\n",
      "epoch [108/500], loss:0.8210\n",
      "epoch [109/500], loss:0.8246\n",
      "epoch [110/500], loss:0.8754\n",
      "epoch [111/500], loss:0.8102\n",
      "epoch [112/500], loss:0.7606\n",
      "epoch [113/500], loss:0.8526\n",
      "epoch [114/500], loss:0.8831\n",
      "epoch [115/500], loss:0.8344\n",
      "epoch [116/500], loss:0.8368\n",
      "epoch [117/500], loss:0.8136\n",
      "epoch [118/500], loss:0.8031\n",
      "epoch [119/500], loss:0.9954\n",
      "epoch [120/500], loss:0.8758\n",
      "epoch [121/500], loss:0.8583\n",
      "epoch [122/500], loss:0.9018\n",
      "epoch [123/500], loss:0.9289\n",
      "epoch [124/500], loss:0.8086\n",
      "epoch [125/500], loss:1.0150\n",
      "epoch [126/500], loss:0.8519\n",
      "epoch [127/500], loss:0.7928\n",
      "epoch [128/500], loss:0.8257\n",
      "epoch [129/500], loss:0.7528\n",
      "epoch [130/500], loss:0.8749\n",
      "epoch [131/500], loss:0.8180\n",
      "epoch [132/500], loss:0.8156\n",
      "epoch [133/500], loss:0.7311\n",
      "epoch [134/500], loss:0.7844\n",
      "epoch [135/500], loss:0.8334\n",
      "epoch [136/500], loss:0.8332\n",
      "epoch [137/500], loss:0.8263\n",
      "epoch [138/500], loss:0.7995\n",
      "epoch [139/500], loss:0.7510\n",
      "epoch [140/500], loss:0.7386\n",
      "epoch [141/500], loss:0.7503\n",
      "epoch [142/500], loss:0.9972\n",
      "epoch [143/500], loss:0.8352\n",
      "epoch [144/500], loss:0.7980\n",
      "epoch [145/500], loss:0.8011\n",
      "epoch [146/500], loss:0.7969\n",
      "epoch [147/500], loss:0.7237\n",
      "epoch [148/500], loss:0.9772\n",
      "epoch [149/500], loss:0.8269\n",
      "epoch [150/500], loss:0.7646\n",
      "epoch [151/500], loss:0.8441\n",
      "epoch [152/500], loss:0.7852\n",
      "epoch [153/500], loss:0.8554\n",
      "epoch [154/500], loss:0.8210\n",
      "epoch [155/500], loss:0.8404\n",
      "epoch [156/500], loss:0.8245\n",
      "epoch [157/500], loss:0.8302\n",
      "epoch [158/500], loss:0.6643\n",
      "epoch [159/500], loss:0.7273\n",
      "epoch [160/500], loss:0.8732\n",
      "epoch [161/500], loss:0.8997\n",
      "epoch [162/500], loss:0.8371\n",
      "epoch [163/500], loss:0.8978\n",
      "epoch [164/500], loss:0.8465\n",
      "epoch [165/500], loss:0.8625\n",
      "epoch [166/500], loss:0.8951\n",
      "epoch [167/500], loss:0.7467\n",
      "epoch [168/500], loss:0.8134\n",
      "epoch [169/500], loss:0.9028\n",
      "epoch [170/500], loss:0.9573\n",
      "epoch [171/500], loss:0.7600\n",
      "epoch [172/500], loss:0.8156\n",
      "epoch [173/500], loss:0.7655\n",
      "epoch [174/500], loss:0.7975\n",
      "epoch [175/500], loss:0.9290\n",
      "epoch [176/500], loss:0.8081\n",
      "epoch [177/500], loss:0.8223\n",
      "epoch [178/500], loss:0.9074\n",
      "epoch [179/500], loss:0.9667\n",
      "epoch [180/500], loss:0.7274\n",
      "epoch [181/500], loss:0.7401\n",
      "epoch [182/500], loss:0.8568\n",
      "epoch [183/500], loss:0.8558\n",
      "epoch [184/500], loss:0.7828\n",
      "epoch [185/500], loss:0.9542\n",
      "epoch [186/500], loss:0.9357\n",
      "epoch [187/500], loss:0.7911\n",
      "epoch [188/500], loss:0.8051\n",
      "epoch [189/500], loss:0.8475\n",
      "epoch [190/500], loss:0.7969\n",
      "epoch [191/500], loss:0.8784\n",
      "epoch [192/500], loss:0.7866\n",
      "epoch [193/500], loss:0.9445\n",
      "epoch [194/500], loss:0.9589\n",
      "epoch [195/500], loss:0.8126\n",
      "epoch [196/500], loss:0.7894\n",
      "epoch [197/500], loss:0.7102\n",
      "epoch [198/500], loss:0.7344\n",
      "epoch [199/500], loss:0.6748\n",
      "epoch [200/500], loss:0.7077\n",
      "epoch [201/500], loss:0.7854\n",
      "epoch [202/500], loss:0.9174\n",
      "epoch [203/500], loss:0.9949\n",
      "epoch [204/500], loss:0.8183\n",
      "epoch [205/500], loss:0.8412\n",
      "epoch [206/500], loss:0.7607\n",
      "epoch [207/500], loss:0.7900\n",
      "epoch [208/500], loss:0.8036\n",
      "epoch [209/500], loss:0.8410\n",
      "epoch [210/500], loss:0.9863\n",
      "epoch [211/500], loss:0.7963\n",
      "epoch [212/500], loss:0.8823\n",
      "epoch [213/500], loss:1.0226\n",
      "epoch [214/500], loss:0.7919\n",
      "epoch [215/500], loss:0.7675\n",
      "epoch [216/500], loss:0.9017\n",
      "epoch [217/500], loss:0.8440\n",
      "epoch [218/500], loss:0.7431\n",
      "epoch [219/500], loss:1.0492\n",
      "epoch [220/500], loss:0.8104\n",
      "epoch [221/500], loss:0.8856\n",
      "epoch [222/500], loss:0.8010\n",
      "epoch [223/500], loss:0.8678\n",
      "epoch [224/500], loss:0.8522\n",
      "epoch [225/500], loss:0.7864\n",
      "epoch [226/500], loss:0.8691\n",
      "epoch [227/500], loss:0.8166\n",
      "epoch [228/500], loss:0.7795\n",
      "epoch [229/500], loss:0.9048\n",
      "epoch [230/500], loss:0.8000\n",
      "epoch [231/500], loss:0.8192\n",
      "epoch [232/500], loss:0.9196\n",
      "epoch [233/500], loss:0.8048\n",
      "epoch [234/500], loss:0.8158\n",
      "epoch [235/500], loss:0.8201\n",
      "epoch [236/500], loss:0.8504\n",
      "epoch [237/500], loss:0.8235\n",
      "epoch [238/500], loss:0.8151\n",
      "epoch [239/500], loss:0.9306\n",
      "epoch [240/500], loss:0.8338\n",
      "epoch [241/500], loss:0.7944\n",
      "epoch [242/500], loss:0.8972\n",
      "epoch [243/500], loss:0.8413\n",
      "epoch [244/500], loss:0.8233\n",
      "epoch [245/500], loss:0.8473\n",
      "epoch [246/500], loss:0.8016\n",
      "epoch [247/500], loss:0.8672\n",
      "epoch [248/500], loss:0.7196\n",
      "epoch [249/500], loss:0.9474\n",
      "epoch [250/500], loss:0.7446\n",
      "epoch [251/500], loss:0.8460\n",
      "epoch [252/500], loss:0.7981\n",
      "epoch [253/500], loss:0.7900\n",
      "epoch [254/500], loss:0.8493\n",
      "epoch [255/500], loss:0.7877\n",
      "epoch [256/500], loss:0.8690\n",
      "epoch [257/500], loss:0.7476\n",
      "epoch [258/500], loss:0.8923\n",
      "epoch [259/500], loss:0.8307\n",
      "epoch [260/500], loss:0.8458\n",
      "epoch [261/500], loss:0.7530\n",
      "epoch [262/500], loss:0.8278\n",
      "epoch [263/500], loss:0.8689\n",
      "epoch [264/500], loss:0.8350\n",
      "epoch [265/500], loss:0.9303\n",
      "epoch [266/500], loss:0.9655\n",
      "epoch [267/500], loss:1.0166\n",
      "epoch [268/500], loss:0.8884\n",
      "epoch [269/500], loss:0.8899\n",
      "epoch [270/500], loss:0.7902\n",
      "epoch [271/500], loss:0.8133\n",
      "epoch [272/500], loss:0.8625\n",
      "epoch [273/500], loss:0.8836\n",
      "epoch [274/500], loss:0.8054\n",
      "epoch [275/500], loss:0.7521\n",
      "epoch [276/500], loss:0.9697\n",
      "epoch [277/500], loss:0.8742\n",
      "epoch [278/500], loss:0.8076\n",
      "epoch [279/500], loss:0.9290\n",
      "epoch [280/500], loss:0.9561\n",
      "epoch [281/500], loss:0.9297\n",
      "epoch [282/500], loss:0.7958\n",
      "epoch [283/500], loss:0.7906\n",
      "epoch [284/500], loss:0.8746\n",
      "epoch [285/500], loss:0.7208\n",
      "epoch [286/500], loss:0.8300\n",
      "epoch [287/500], loss:0.9021\n",
      "epoch [288/500], loss:0.9498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [289/500], loss:0.8815\n",
      "epoch [290/500], loss:0.7727\n",
      "epoch [291/500], loss:0.7610\n",
      "epoch [292/500], loss:0.8807\n",
      "epoch [293/500], loss:0.9077\n",
      "epoch [294/500], loss:0.7620\n",
      "epoch [295/500], loss:0.7830\n",
      "epoch [296/500], loss:0.9302\n",
      "epoch [297/500], loss:0.8890\n",
      "epoch [298/500], loss:0.9835\n",
      "epoch [299/500], loss:0.8785\n",
      "epoch [300/500], loss:0.8500\n",
      "epoch [301/500], loss:0.8841\n",
      "epoch [302/500], loss:0.7621\n",
      "epoch [303/500], loss:0.8084\n",
      "epoch [304/500], loss:0.7666\n",
      "epoch [305/500], loss:0.8162\n",
      "epoch [306/500], loss:0.8618\n",
      "epoch [307/500], loss:0.8400\n",
      "epoch [308/500], loss:0.8858\n",
      "epoch [309/500], loss:0.8187\n",
      "epoch [310/500], loss:0.9680\n",
      "epoch [311/500], loss:0.8485\n",
      "epoch [312/500], loss:0.9394\n",
      "epoch [313/500], loss:0.9382\n",
      "epoch [314/500], loss:0.9709\n",
      "epoch [315/500], loss:0.7890\n",
      "epoch [316/500], loss:0.8962\n",
      "epoch [317/500], loss:0.8996\n",
      "epoch [318/500], loss:0.7940\n",
      "epoch [319/500], loss:0.8729\n",
      "epoch [320/500], loss:0.8559\n",
      "epoch [321/500], loss:0.7952\n",
      "epoch [322/500], loss:0.8295\n",
      "epoch [323/500], loss:0.8854\n",
      "epoch [324/500], loss:0.8752\n",
      "epoch [325/500], loss:0.9537\n",
      "epoch [326/500], loss:0.7357\n",
      "epoch [327/500], loss:0.8373\n",
      "epoch [328/500], loss:0.7890\n",
      "epoch [329/500], loss:0.8556\n",
      "epoch [330/500], loss:0.7792\n",
      "epoch [331/500], loss:0.8586\n",
      "epoch [332/500], loss:0.7654\n",
      "epoch [333/500], loss:0.7423\n",
      "epoch [334/500], loss:0.8387\n",
      "epoch [335/500], loss:1.0923\n",
      "epoch [336/500], loss:0.7828\n",
      "epoch [337/500], loss:0.8766\n",
      "epoch [338/500], loss:1.0097\n",
      "epoch [339/500], loss:0.9635\n",
      "epoch [340/500], loss:0.8665\n",
      "epoch [341/500], loss:0.8586\n",
      "epoch [342/500], loss:0.7391\n",
      "epoch [343/500], loss:0.9343\n",
      "epoch [344/500], loss:0.8455\n",
      "epoch [345/500], loss:0.9073\n",
      "epoch [346/500], loss:0.8761\n",
      "epoch [347/500], loss:0.9253\n",
      "epoch [348/500], loss:0.8429\n",
      "epoch [349/500], loss:0.9176\n",
      "epoch [350/500], loss:0.8257\n",
      "epoch [351/500], loss:0.8657\n",
      "epoch [352/500], loss:0.8114\n",
      "epoch [353/500], loss:0.8564\n",
      "epoch [354/500], loss:0.7938\n",
      "epoch [355/500], loss:0.8206\n",
      "epoch [356/500], loss:0.9982\n",
      "epoch [357/500], loss:0.8776\n",
      "epoch [358/500], loss:0.8241\n",
      "epoch [359/500], loss:0.8525\n",
      "epoch [360/500], loss:0.9054\n",
      "epoch [361/500], loss:0.8034\n",
      "epoch [362/500], loss:0.8778\n",
      "epoch [363/500], loss:0.9328\n",
      "epoch [364/500], loss:1.0465\n",
      "epoch [365/500], loss:0.8210\n",
      "epoch [366/500], loss:0.8301\n",
      "epoch [367/500], loss:0.8478\n",
      "epoch [368/500], loss:0.9246\n",
      "epoch [369/500], loss:0.8551\n",
      "epoch [370/500], loss:0.7888\n",
      "epoch [371/500], loss:0.9006\n",
      "epoch [372/500], loss:0.8345\n",
      "epoch [373/500], loss:0.7868\n",
      "epoch [374/500], loss:0.9190\n",
      "epoch [375/500], loss:0.8133\n",
      "epoch [376/500], loss:0.8683\n",
      "epoch [377/500], loss:1.2694\n",
      "epoch [378/500], loss:0.8827\n",
      "epoch [379/500], loss:0.8636\n",
      "epoch [380/500], loss:0.9928\n",
      "epoch [381/500], loss:0.8616\n",
      "epoch [382/500], loss:0.7955\n",
      "epoch [383/500], loss:0.9571\n",
      "epoch [384/500], loss:0.8879\n",
      "epoch [385/500], loss:0.8755\n",
      "epoch [386/500], loss:0.9091\n",
      "epoch [387/500], loss:0.9019\n",
      "epoch [388/500], loss:0.9552\n",
      "epoch [389/500], loss:0.9486\n",
      "epoch [390/500], loss:0.8099\n",
      "epoch [391/500], loss:0.7866\n",
      "epoch [392/500], loss:0.9238\n",
      "epoch [393/500], loss:0.8882\n",
      "epoch [394/500], loss:0.8044\n",
      "epoch [395/500], loss:0.8649\n",
      "epoch [396/500], loss:0.8105\n",
      "epoch [397/500], loss:0.8227\n",
      "epoch [398/500], loss:0.9495\n",
      "epoch [399/500], loss:0.9147\n",
      "epoch [400/500], loss:0.8095\n",
      "epoch [401/500], loss:0.8281\n",
      "epoch [402/500], loss:0.7996\n",
      "epoch [403/500], loss:0.8985\n",
      "epoch [404/500], loss:0.9088\n",
      "epoch [405/500], loss:0.8939\n",
      "epoch [406/500], loss:0.9496\n",
      "epoch [407/500], loss:0.8882\n",
      "epoch [408/500], loss:0.7483\n",
      "epoch [409/500], loss:0.8332\n",
      "epoch [410/500], loss:0.9420\n",
      "epoch [411/500], loss:0.8597\n",
      "epoch [412/500], loss:0.8837\n",
      "epoch [413/500], loss:0.8148\n",
      "epoch [414/500], loss:0.7167\n",
      "epoch [415/500], loss:0.8429\n",
      "epoch [416/500], loss:0.8259\n",
      "epoch [417/500], loss:0.8953\n",
      "epoch [418/500], loss:0.8813\n",
      "epoch [419/500], loss:0.7839\n",
      "epoch [420/500], loss:1.0297\n",
      "epoch [421/500], loss:0.7902\n",
      "epoch [422/500], loss:0.7886\n",
      "epoch [423/500], loss:0.7766\n",
      "epoch [424/500], loss:0.9211\n",
      "epoch [425/500], loss:0.9069\n",
      "epoch [426/500], loss:0.8011\n",
      "epoch [427/500], loss:0.8087\n",
      "epoch [428/500], loss:0.8333\n",
      "epoch [429/500], loss:0.8727\n",
      "epoch [430/500], loss:0.7445\n",
      "epoch [431/500], loss:0.8813\n",
      "epoch [432/500], loss:0.7049\n",
      "epoch [433/500], loss:0.7508\n",
      "epoch [434/500], loss:0.8565\n",
      "epoch [435/500], loss:0.8563\n",
      "epoch [436/500], loss:0.8149\n",
      "epoch [437/500], loss:0.8739\n",
      "epoch [438/500], loss:0.7996\n",
      "epoch [439/500], loss:0.8257\n",
      "epoch [440/500], loss:0.7742\n",
      "epoch [441/500], loss:0.8786\n",
      "epoch [442/500], loss:0.8516\n",
      "epoch [443/500], loss:0.8545\n",
      "epoch [444/500], loss:0.8090\n",
      "epoch [445/500], loss:0.8691\n",
      "epoch [446/500], loss:0.8484\n",
      "epoch [447/500], loss:0.9230\n",
      "epoch [448/500], loss:0.8699\n",
      "epoch [449/500], loss:0.8725\n",
      "epoch [450/500], loss:0.8513\n",
      "epoch [451/500], loss:0.8060\n",
      "epoch [452/500], loss:0.9539\n",
      "epoch [453/500], loss:0.8467\n",
      "epoch [454/500], loss:1.0233\n",
      "epoch [455/500], loss:0.9126\n",
      "epoch [456/500], loss:0.8544\n",
      "epoch [457/500], loss:0.8701\n",
      "epoch [458/500], loss:0.8198\n",
      "epoch [459/500], loss:0.8846\n",
      "epoch [460/500], loss:0.7857\n",
      "epoch [461/500], loss:0.7653\n",
      "epoch [462/500], loss:0.8833\n",
      "epoch [463/500], loss:0.7060\n",
      "epoch [464/500], loss:0.8620\n",
      "epoch [465/500], loss:0.7419\n",
      "epoch [466/500], loss:0.9098\n",
      "epoch [467/500], loss:0.8035\n",
      "epoch [468/500], loss:0.9392\n",
      "epoch [469/500], loss:0.9402\n",
      "epoch [470/500], loss:0.7877\n",
      "epoch [471/500], loss:0.9453\n",
      "epoch [472/500], loss:0.9215\n",
      "epoch [473/500], loss:0.8766\n",
      "epoch [474/500], loss:0.8657\n",
      "epoch [475/500], loss:0.7880\n",
      "epoch [476/500], loss:0.8413\n",
      "epoch [477/500], loss:0.7864\n",
      "epoch [478/500], loss:0.9116\n",
      "epoch [479/500], loss:0.8098\n",
      "epoch [480/500], loss:0.8395\n",
      "epoch [481/500], loss:0.7915\n",
      "epoch [482/500], loss:0.8203\n",
      "epoch [483/500], loss:0.8329\n",
      "epoch [484/500], loss:0.9008\n",
      "epoch [485/500], loss:0.7453\n",
      "epoch [486/500], loss:0.8177\n",
      "epoch [487/500], loss:0.7522\n",
      "epoch [488/500], loss:0.8384\n",
      "epoch [489/500], loss:0.8456\n",
      "epoch [490/500], loss:0.8894\n",
      "epoch [491/500], loss:0.7989\n",
      "epoch [492/500], loss:0.8285\n",
      "epoch [493/500], loss:1.0225\n",
      "epoch [494/500], loss:0.8019\n",
      "epoch [495/500], loss:0.7299\n",
      "epoch [496/500], loss:0.7809\n",
      "epoch [497/500], loss:0.7659\n",
      "epoch [498/500], loss:0.7582\n",
      "epoch [499/500], loss:0.7412\n",
      "epoch [500/500], loss:0.8082\n"
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "    for b in range(0,X_train.shape[0],batch_size):\n",
    "        mlp.train()\n",
    "        batch_data = X_train[b:b+batch_size,:]\n",
    "        batch_label = y_train[b:b+batch_size]\n",
    "        output = mlp(torch.Tensor(batch_data).cuda())\n",
    "        batch_label = torch.LongTensor(batch_label).cuda()\n",
    "        loss = loss_fn(output,batch_label)\n",
    "        l2_norm = torch.norm(mlp.layers[-1].weight, p=2)\n",
    "        loss += l2_norm*0.09\n",
    "        l2_norm = torch.norm(mlp.layers[0].weight, p=2)\n",
    "        loss += l2_norm*0.03\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(e + 1, EPOCHS, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.eval()\n",
    "pred_mlp = torch.nn.Softmax(dim = 1)(mlp(torch.Tensor(X_test[:,:]).cuda())).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_mlp = process_prediction(pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>0.563645</td>\n",
       "      <td>0.291711</td>\n",
       "      <td>0.144644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>0.951462</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.021035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>0.047030</td>\n",
       "      <td>0.933527</td>\n",
       "      <td>0.019444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>0.093320</td>\n",
       "      <td>0.797859</td>\n",
       "      <td>0.108821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.978048</td>\n",
       "      <td>0.012578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID         A         B   NEITHER\n",
       "0  development-1  0.563645  0.291711  0.144644\n",
       "1  development-2  0.951462  0.027503  0.021035\n",
       "2  development-3  0.047030  0.933527  0.019444\n",
       "3  development-4  0.093320  0.797859  0.108821\n",
       "4  development-5  0.009374  0.978048  0.012578"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv(\"./test_and_submit/sample_submission_stage_1.csv\")\n",
    "sub_df.loc[:, ['A','B','NEITHER']] = pred_mlp\n",
    "sub_df.to_csv(\"./test_and_submit/submission+model+mlp@\"+str(datetime.datetime.now())+\".csv\", index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5614374279975891"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(sub_df,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM HERE ONLY DRAFT\n",
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let me try a very simple stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "train_pred_svm = svm.predict_proba(X_train)\n",
    "mlp.eval()\n",
    "train_pred_mlp = torch.nn.Softmax(dim = 1)(mlp(torch.Tensor(X_train[:,:]).cuda())).cpu().data.numpy()\n",
    "svm_stack = SVC(C = 7.0,verbose=True,probability = True,gamma = \"auto\",class_weight = \"balanced\").fit(np.concatenate([train_pred_svm,train_pred_mlp],axis = 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_stack = svm_stack.predict_proba(np.concatenate([pred_svm,pred_mlp],axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>0.979822</td>\n",
       "      <td>0.020139</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>0.944007</td>\n",
       "      <td>0.055887</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.987994</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.984560</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>0.031788</td>\n",
       "      <td>0.959913</td>\n",
       "      <td>0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>development-6</td>\n",
       "      <td>0.979069</td>\n",
       "      <td>0.020894</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>development-7</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.047262</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>development-8</td>\n",
       "      <td>0.023336</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>0.002160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>development-9</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.965080</td>\n",
       "      <td>0.002424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>development-10</td>\n",
       "      <td>0.927056</td>\n",
       "      <td>0.072810</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>development-11</td>\n",
       "      <td>0.048428</td>\n",
       "      <td>0.665123</td>\n",
       "      <td>0.286448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>development-12</td>\n",
       "      <td>0.977116</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>development-13</td>\n",
       "      <td>0.723466</td>\n",
       "      <td>0.276286</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>development-14</td>\n",
       "      <td>0.953058</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>development-15</td>\n",
       "      <td>0.019990</td>\n",
       "      <td>0.979858</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>development-16</td>\n",
       "      <td>0.078009</td>\n",
       "      <td>0.919410</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>development-17</td>\n",
       "      <td>0.976440</td>\n",
       "      <td>0.023521</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>development-18</td>\n",
       "      <td>0.995144</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>development-19</td>\n",
       "      <td>0.534220</td>\n",
       "      <td>0.342759</td>\n",
       "      <td>0.123021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>development-20</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.923330</td>\n",
       "      <td>0.008337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>development-21</td>\n",
       "      <td>0.023838</td>\n",
       "      <td>0.973464</td>\n",
       "      <td>0.002697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>development-22</td>\n",
       "      <td>0.975546</td>\n",
       "      <td>0.024410</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>development-23</td>\n",
       "      <td>0.975883</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>development-24</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>0.975437</td>\n",
       "      <td>0.001829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>development-25</td>\n",
       "      <td>0.979793</td>\n",
       "      <td>0.020168</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>development-26</td>\n",
       "      <td>0.028097</td>\n",
       "      <td>0.971122</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>development-27</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.987171</td>\n",
       "      <td>0.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>development-28</td>\n",
       "      <td>0.978630</td>\n",
       "      <td>0.021326</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>development-29</td>\n",
       "      <td>0.166239</td>\n",
       "      <td>0.832160</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>development-30</td>\n",
       "      <td>0.937709</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID         A         B   NEITHER\n",
       "0    development-1  0.979822  0.020139  0.000039\n",
       "1    development-2  0.944007  0.055887  0.000107\n",
       "2    development-3  0.011456  0.987994  0.000549\n",
       "3    development-4  0.014046  0.984560  0.001393\n",
       "4    development-5  0.031788  0.959913  0.008299\n",
       "5    development-6  0.979069  0.020894  0.000037\n",
       "6    development-7  0.951825  0.047262  0.000912\n",
       "7    development-8  0.023336  0.974504  0.002160\n",
       "8    development-9  0.032496  0.965080  0.002424\n",
       "9   development-10  0.927056  0.072810  0.000134\n",
       "10  development-11  0.048428  0.665123  0.286448\n",
       "11  development-12  0.977116  0.022839  0.000045\n",
       "12  development-13  0.723466  0.276286  0.000248\n",
       "13  development-14  0.953058  0.046851  0.000091\n",
       "14  development-15  0.019990  0.979858  0.000152\n",
       "15  development-16  0.078009  0.919410  0.002581\n",
       "16  development-17  0.976440  0.023521  0.000039\n",
       "17  development-18  0.995144  0.004822  0.000034\n",
       "18  development-19  0.534220  0.342759  0.123021\n",
       "19  development-20  0.068332  0.923330  0.008337\n",
       "20  development-21  0.023838  0.973464  0.002697\n",
       "21  development-22  0.975546  0.024410  0.000045\n",
       "22  development-23  0.975883  0.024069  0.000047\n",
       "23  development-24  0.022734  0.975437  0.001829\n",
       "24  development-25  0.979793  0.020168  0.000039\n",
       "25  development-26  0.028097  0.971122  0.000780\n",
       "26  development-27  0.012322  0.987171  0.000507\n",
       "27  development-28  0.978630  0.021326  0.000044\n",
       "28  development-29  0.166239  0.832160  0.001601\n",
       "29  development-30  0.937709  0.062203  0.000088"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv(\"./test_and_submit/sample_submission_stage_1.csv\")\n",
    "sub_df.loc[:, ['A','B','NEITHER']] = pred_stack\n",
    "sub_df.to_csv(\"./test_and_submit/submission+model+stack@\"+str(datetime.datetime.now())+\".csv\", index=False)\n",
    "sub_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7818620800971985"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(sub_df,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_dist</th>\n",
       "      <th>B_dist</th>\n",
       "      <th>A_pos</th>\n",
       "      <th>B_pos</th>\n",
       "      <th>pron_pos</th>\n",
       "      <th>A_vector</th>\n",
       "      <th>B_vector</th>\n",
       "      <th>pron_vector</th>\n",
       "      <th>product_vector_A</th>\n",
       "      <th>product_vector_B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A_dist  B_dist  A_pos  B_pos  pron_pos  A_vector  B_vector  \\\n",
       "label                                                               \n",
       "0         918     918    918    918       918       918       918   \n",
       "1         855     855    855    855       855       855       855   \n",
       "2         227     227    227    227       227       227       227   \n",
       "\n",
       "       pron_vector  product_vector_A  product_vector_B  \n",
       "label                                                   \n",
       "0              918               918               918  \n",
       "1              855               855               855  \n",
       "2              227               227               227  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>development-7</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.047262</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>development-16</td>\n",
       "      <td>0.078009</td>\n",
       "      <td>0.919410</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>development-18</td>\n",
       "      <td>0.995144</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>development-29</td>\n",
       "      <td>0.166239</td>\n",
       "      <td>0.832160</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>development-32</td>\n",
       "      <td>0.098341</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>0.893320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>development-34</td>\n",
       "      <td>0.065562</td>\n",
       "      <td>0.010992</td>\n",
       "      <td>0.923446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>development-46</td>\n",
       "      <td>0.863669</td>\n",
       "      <td>0.128468</td>\n",
       "      <td>0.007864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>development-47</td>\n",
       "      <td>0.704218</td>\n",
       "      <td>0.101825</td>\n",
       "      <td>0.193957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>development-50</td>\n",
       "      <td>0.091995</td>\n",
       "      <td>0.439014</td>\n",
       "      <td>0.468991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>development-56</td>\n",
       "      <td>0.028798</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.941472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>development-68</td>\n",
       "      <td>0.989734</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>0.000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>development-79</td>\n",
       "      <td>0.958800</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>development-81</td>\n",
       "      <td>0.377519</td>\n",
       "      <td>0.588115</td>\n",
       "      <td>0.034366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>development-89</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.989934</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>development-93</td>\n",
       "      <td>0.028357</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>0.964427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>development-98</td>\n",
       "      <td>0.213643</td>\n",
       "      <td>0.509867</td>\n",
       "      <td>0.276490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>development-100</td>\n",
       "      <td>0.145660</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.819757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>development-102</td>\n",
       "      <td>0.729733</td>\n",
       "      <td>0.247851</td>\n",
       "      <td>0.022416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>development-113</td>\n",
       "      <td>0.065315</td>\n",
       "      <td>0.046316</td>\n",
       "      <td>0.888369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>development-115</td>\n",
       "      <td>0.232432</td>\n",
       "      <td>0.722616</td>\n",
       "      <td>0.044952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>development-122</td>\n",
       "      <td>0.107224</td>\n",
       "      <td>0.106252</td>\n",
       "      <td>0.786524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>development-123</td>\n",
       "      <td>0.074191</td>\n",
       "      <td>0.914534</td>\n",
       "      <td>0.011275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>development-142</td>\n",
       "      <td>0.090096</td>\n",
       "      <td>0.907730</td>\n",
       "      <td>0.002174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>development-156</td>\n",
       "      <td>0.938070</td>\n",
       "      <td>0.061657</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>development-179</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.994391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>development-181</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.986257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>development-191</td>\n",
       "      <td>0.950267</td>\n",
       "      <td>0.049623</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>development-201</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.995871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>development-224</td>\n",
       "      <td>0.160079</td>\n",
       "      <td>0.839692</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>development-234</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.972690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>development-1730</td>\n",
       "      <td>0.983528</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>development-1745</td>\n",
       "      <td>0.461486</td>\n",
       "      <td>0.448851</td>\n",
       "      <td>0.089663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>development-1747</td>\n",
       "      <td>0.999058</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>development-1751</td>\n",
       "      <td>0.019244</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.967574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>development-1753</td>\n",
       "      <td>0.013355</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.984692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>development-1754</td>\n",
       "      <td>0.624456</td>\n",
       "      <td>0.309347</td>\n",
       "      <td>0.066197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>development-1756</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.994286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>development-1777</td>\n",
       "      <td>0.212065</td>\n",
       "      <td>0.786430</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>development-1811</td>\n",
       "      <td>0.532274</td>\n",
       "      <td>0.167209</td>\n",
       "      <td>0.300517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>development-1819</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.983729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>development-1829</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.982152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>development-1837</td>\n",
       "      <td>0.043093</td>\n",
       "      <td>0.956326</td>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>development-1841</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.911192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>development-1857</td>\n",
       "      <td>0.538343</td>\n",
       "      <td>0.461269</td>\n",
       "      <td>0.000389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>development-1863</td>\n",
       "      <td>0.937347</td>\n",
       "      <td>0.048266</td>\n",
       "      <td>0.014387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>development-1870</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.991305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>development-1912</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.039204</td>\n",
       "      <td>0.294796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>development-1920</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.017411</td>\n",
       "      <td>0.946638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>development-1922</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.912735</td>\n",
       "      <td>0.012267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>development-1926</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.982778</td>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>development-1932</td>\n",
       "      <td>0.020838</td>\n",
       "      <td>0.977726</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>development-1938</td>\n",
       "      <td>0.086612</td>\n",
       "      <td>0.904781</td>\n",
       "      <td>0.008607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>development-1949</td>\n",
       "      <td>0.974382</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>0.002788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>development-1950</td>\n",
       "      <td>0.380072</td>\n",
       "      <td>0.610717</td>\n",
       "      <td>0.009211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>development-1952</td>\n",
       "      <td>0.961099</td>\n",
       "      <td>0.038662</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>development-1962</td>\n",
       "      <td>0.045564</td>\n",
       "      <td>0.926373</td>\n",
       "      <td>0.028063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>development-1984</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.983940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>development-1986</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.977759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>development-1987</td>\n",
       "      <td>0.020425</td>\n",
       "      <td>0.978736</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>development-1991</td>\n",
       "      <td>0.087616</td>\n",
       "      <td>0.641808</td>\n",
       "      <td>0.270577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID         A         B   NEITHER\n",
       "6        development-7  0.951825  0.047262  0.000912\n",
       "15      development-16  0.078009  0.919410  0.002581\n",
       "17      development-18  0.995144  0.004822  0.000034\n",
       "28      development-29  0.166239  0.832160  0.001601\n",
       "31      development-32  0.098341  0.008339  0.893320\n",
       "33      development-34  0.065562  0.010992  0.923446\n",
       "45      development-46  0.863669  0.128468  0.007864\n",
       "46      development-47  0.704218  0.101825  0.193957\n",
       "49      development-50  0.091995  0.439014  0.468991\n",
       "55      development-56  0.028798  0.029730  0.941472\n",
       "67      development-68  0.989734  0.009753  0.000513\n",
       "78      development-79  0.958800  0.041143  0.000057\n",
       "80      development-81  0.377519  0.588115  0.034366\n",
       "88      development-89  0.009977  0.989934  0.000090\n",
       "92      development-93  0.028357  0.007217  0.964427\n",
       "97      development-98  0.213643  0.509867  0.276490\n",
       "99     development-100  0.145660  0.034583  0.819757\n",
       "101    development-102  0.729733  0.247851  0.022416\n",
       "112    development-113  0.065315  0.046316  0.888369\n",
       "114    development-115  0.232432  0.722616  0.044952\n",
       "121    development-122  0.107224  0.106252  0.786524\n",
       "122    development-123  0.074191  0.914534  0.011275\n",
       "141    development-142  0.090096  0.907730  0.002174\n",
       "155    development-156  0.938070  0.061657  0.000273\n",
       "178    development-179  0.004843  0.000766  0.994391\n",
       "180    development-181  0.011731  0.002012  0.986257\n",
       "190    development-191  0.950267  0.049623  0.000110\n",
       "200    development-201  0.003490  0.000639  0.995871\n",
       "223    development-224  0.160079  0.839692  0.000229\n",
       "233    development-234  0.021330  0.005980  0.972690\n",
       "...                ...       ...       ...       ...\n",
       "1729  development-1730  0.983528  0.016036  0.000436\n",
       "1744  development-1745  0.461486  0.448851  0.089663\n",
       "1746  development-1747  0.999058  0.000935  0.000007\n",
       "1750  development-1751  0.019244  0.013181  0.967574\n",
       "1752  development-1753  0.013355  0.001953  0.984692\n",
       "1753  development-1754  0.624456  0.309347  0.066197\n",
       "1755  development-1756  0.004540  0.001174  0.994286\n",
       "1776  development-1777  0.212065  0.786430  0.001505\n",
       "1810  development-1811  0.532274  0.167209  0.300517\n",
       "1818  development-1819  0.010755  0.005516  0.983729\n",
       "1828  development-1829  0.015930  0.001918  0.982152\n",
       "1836  development-1837  0.043093  0.956326  0.000582\n",
       "1840  development-1841  0.077716  0.011092  0.911192\n",
       "1856  development-1857  0.538343  0.461269  0.000389\n",
       "1862  development-1863  0.937347  0.048266  0.014387\n",
       "1869  development-1870  0.004800  0.003895  0.991305\n",
       "1911  development-1912  0.666000  0.039204  0.294796\n",
       "1919  development-1920  0.035951  0.017411  0.946638\n",
       "1921  development-1922  0.074998  0.912735  0.012267\n",
       "1925  development-1926  0.016014  0.982778  0.001208\n",
       "1931  development-1932  0.020838  0.977726  0.001436\n",
       "1937  development-1938  0.086612  0.904781  0.008607\n",
       "1948  development-1949  0.974382  0.022830  0.002788\n",
       "1949  development-1950  0.380072  0.610717  0.009211\n",
       "1951  development-1952  0.961099  0.038662  0.000238\n",
       "1961  development-1962  0.045564  0.926373  0.028063\n",
       "1983  development-1984  0.009920  0.006141  0.983940\n",
       "1985  development-1986  0.017188  0.005054  0.977759\n",
       "1986  development-1987  0.020425  0.978736  0.000839\n",
       "1990  development-1991  0.087616  0.641808  0.270577\n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[test_data.label == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
